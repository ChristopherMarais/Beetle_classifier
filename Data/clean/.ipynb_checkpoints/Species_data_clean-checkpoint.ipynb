{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "853cffee-6e2a-4ee7-a1ea-cd99ab6171fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T01:52:27.222607Z",
     "iopub.status.busy": "2023-06-07T01:52:27.222104Z",
     "iopub.status.idle": "2023-06-07T01:52:27.978106Z",
     "shell.execute_reply": "2023-06-07T01:52:27.977107Z",
     "shell.execute_reply.started": "2023-06-07T01:52:27.222607Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "770c9bf7-c4df-41f2-9736-b2e924a85f7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T01:52:27.980607Z",
     "iopub.status.busy": "2023-06-07T01:52:27.980105Z",
     "iopub.status.idle": "2023-06-07T01:52:27.994105Z",
     "shell.execute_reply": "2023-06-07T01:52:27.992604Z",
     "shell.execute_reply.started": "2023-06-07T01:52:27.980607Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this function only describes how much a singular value in al ist stands out.\n",
    "# if all values in the lsit are high or low this is 1\n",
    "# the smaller the proportiopn of number of disimilar vlaues are to other more similar values the lower this number\n",
    "# the larger the gap between the dissimilar numbers and the simialr number the smaller this number\n",
    "# only able to interpret probabilities or values between 0 and 1\n",
    "# this function outputs an estimate an inverse of the classification confidence based on the probabilities of all the classes.\n",
    "# the wedge threshold splits the data on a threshold with a magnitude of a positive int to force a ledge/peak in the data\n",
    "def unknown_prob_calc(probs, wedge_threshold=0.85, wedge_magnitude=1, wedge='strict'):\n",
    "    if wedge =='strict':\n",
    "        increase_var = (1/(wedge_magnitude))\n",
    "        decrease_var = (wedge_magnitude)\n",
    "    if wedge =='dynamic': # this allows pointsthat are furhter from the threshold ot be moved less and points clsoer to be moved more\n",
    "        increase_var = (1/(wedge_magnitude*((1-np.abs(probs-wedge_threshold)))))\n",
    "        decrease_var = (wedge_magnitude*((1-np.abs(probs-wedge_threshold))))\n",
    "    # else:\n",
    "    #     print(\"Error: use 'strict' (default) or 'dynamic' as options for the wedge parameter!\")\n",
    "    probs = np.where(probs>=wedge_threshold , probs**increase_var, probs)\n",
    "    probs = np.where(probs<=wedge_threshold , probs**decrease_var, probs)\n",
    "    diff_matrix = np.abs(probs[:, np.newaxis] - probs)\n",
    "    diff_matrix_sum = np.sum(diff_matrix)\n",
    "    probs_sum = np.sum(probs)\n",
    "    class_val = (diff_matrix_sum/probs_sum)\n",
    "    max_class_val = ((len(probs)-1)*2)\n",
    "    kown_prob = class_val/max_class_val\n",
    "    unknown_prob = 1-kown_prob\n",
    "    return(unknown_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99ed0d8d-548b-461c-85eb-924287eebfbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T01:52:27.995604Z",
     "iopub.status.busy": "2023-06-07T01:52:27.995104Z",
     "iopub.status.idle": "2023-06-07T01:52:28.458007Z",
     "shell.execute_reply": "2023-06-07T01:52:28.457505Z",
     "shell.execute_reply.started": "2023-06-07T01:52:27.995604Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>train_1</th>\n",
       "      <th>train_2</th>\n",
       "      <th>train_3</th>\n",
       "      <th>train_4</th>\n",
       "      <th>train_5</th>\n",
       "      <th>valid</th>\n",
       "      <th>valid_1</th>\n",
       "      <th>valid_2</th>\n",
       "      <th>valid_3</th>\n",
       "      <th>valid_4</th>\n",
       "      <th>valid_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Coccotypes_dactyliperda</th>\n",
       "      <td>615</td>\n",
       "      <td>3342</td>\n",
       "      <td>3280</td>\n",
       "      <td>3458</td>\n",
       "      <td>3454</td>\n",
       "      <td>3579</td>\n",
       "      <td>3641</td>\n",
       "      <td>1011</td>\n",
       "      <td>1073</td>\n",
       "      <td>895</td>\n",
       "      <td>899</td>\n",
       "      <td>774</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xyleborinus_saxesenii</th>\n",
       "      <td>380</td>\n",
       "      <td>1542</td>\n",
       "      <td>1625</td>\n",
       "      <td>1663</td>\n",
       "      <td>1833</td>\n",
       "      <td>1855</td>\n",
       "      <td>1716</td>\n",
       "      <td>631</td>\n",
       "      <td>548</td>\n",
       "      <td>510</td>\n",
       "      <td>340</td>\n",
       "      <td>318</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pityophthorus_juglandis</th>\n",
       "      <td>680</td>\n",
       "      <td>3194</td>\n",
       "      <td>3086</td>\n",
       "      <td>3107</td>\n",
       "      <td>3219</td>\n",
       "      <td>3203</td>\n",
       "      <td>3341</td>\n",
       "      <td>795</td>\n",
       "      <td>903</td>\n",
       "      <td>882</td>\n",
       "      <td>770</td>\n",
       "      <td>786</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monarthrum_fasciatum</th>\n",
       "      <td>133</td>\n",
       "      <td>846</td>\n",
       "      <td>827</td>\n",
       "      <td>818</td>\n",
       "      <td>828</td>\n",
       "      <td>976</td>\n",
       "      <td>1011</td>\n",
       "      <td>269</td>\n",
       "      <td>288</td>\n",
       "      <td>297</td>\n",
       "      <td>287</td>\n",
       "      <td>139</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pycnarthrum_hispidium</th>\n",
       "      <td>208</td>\n",
       "      <td>1192</td>\n",
       "      <td>1146</td>\n",
       "      <td>1123</td>\n",
       "      <td>1197</td>\n",
       "      <td>1337</td>\n",
       "      <td>1413</td>\n",
       "      <td>362</td>\n",
       "      <td>408</td>\n",
       "      <td>431</td>\n",
       "      <td>357</td>\n",
       "      <td>217</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xyleborus_affinis</th>\n",
       "      <td>456</td>\n",
       "      <td>3127</td>\n",
       "      <td>3191</td>\n",
       "      <td>3214</td>\n",
       "      <td>3121</td>\n",
       "      <td>3388</td>\n",
       "      <td>3654</td>\n",
       "      <td>1015</td>\n",
       "      <td>951</td>\n",
       "      <td>928</td>\n",
       "      <td>1021</td>\n",
       "      <td>754</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scolotodes_schwarzi</th>\n",
       "      <td>467</td>\n",
       "      <td>1678</td>\n",
       "      <td>1672</td>\n",
       "      <td>1601</td>\n",
       "      <td>1664</td>\n",
       "      <td>1746</td>\n",
       "      <td>1861</td>\n",
       "      <td>458</td>\n",
       "      <td>464</td>\n",
       "      <td>535</td>\n",
       "      <td>472</td>\n",
       "      <td>390</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xylosandrus_crassiusculus</th>\n",
       "      <td>326</td>\n",
       "      <td>2443</td>\n",
       "      <td>2848</td>\n",
       "      <td>2828</td>\n",
       "      <td>2552</td>\n",
       "      <td>2334</td>\n",
       "      <td>2278</td>\n",
       "      <td>767</td>\n",
       "      <td>362</td>\n",
       "      <td>382</td>\n",
       "      <td>658</td>\n",
       "      <td>876</td>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hylesinus_varius</th>\n",
       "      <td>216</td>\n",
       "      <td>1312</td>\n",
       "      <td>1309</td>\n",
       "      <td>1413</td>\n",
       "      <td>1396</td>\n",
       "      <td>1369</td>\n",
       "      <td>1413</td>\n",
       "      <td>413</td>\n",
       "      <td>416</td>\n",
       "      <td>312</td>\n",
       "      <td>329</td>\n",
       "      <td>356</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platypus_cylindrus</th>\n",
       "      <td>247</td>\n",
       "      <td>1337</td>\n",
       "      <td>1364</td>\n",
       "      <td>1345</td>\n",
       "      <td>1338</td>\n",
       "      <td>1326</td>\n",
       "      <td>1383</td>\n",
       "      <td>352</td>\n",
       "      <td>325</td>\n",
       "      <td>344</td>\n",
       "      <td>351</td>\n",
       "      <td>363</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xylosandrus_compactus</th>\n",
       "      <td>402</td>\n",
       "      <td>1749</td>\n",
       "      <td>1645</td>\n",
       "      <td>1705</td>\n",
       "      <td>2064</td>\n",
       "      <td>1953</td>\n",
       "      <td>1977</td>\n",
       "      <td>587</td>\n",
       "      <td>691</td>\n",
       "      <td>631</td>\n",
       "      <td>272</td>\n",
       "      <td>383</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phloeosinus_dentatus</th>\n",
       "      <td>480</td>\n",
       "      <td>3240</td>\n",
       "      <td>3125</td>\n",
       "      <td>3164</td>\n",
       "      <td>3205</td>\n",
       "      <td>3292</td>\n",
       "      <td>3402</td>\n",
       "      <td>807</td>\n",
       "      <td>922</td>\n",
       "      <td>883</td>\n",
       "      <td>842</td>\n",
       "      <td>755</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           test  train  train_1  train_2  train_3  train_4  \\\n",
       "Species                                                                      \n",
       "Coccotypes_dactyliperda     615   3342     3280     3458     3454     3579   \n",
       "Xyleborinus_saxesenii       380   1542     1625     1663     1833     1855   \n",
       "Pityophthorus_juglandis     680   3194     3086     3107     3219     3203   \n",
       "Monarthrum_fasciatum        133    846      827      818      828      976   \n",
       "Pycnarthrum_hispidium       208   1192     1146     1123     1197     1337   \n",
       "Xyleborus_affinis           456   3127     3191     3214     3121     3388   \n",
       "Scolotodes_schwarzi         467   1678     1672     1601     1664     1746   \n",
       "Xylosandrus_crassiusculus   326   2443     2848     2828     2552     2334   \n",
       "Hylesinus_varius            216   1312     1309     1413     1396     1369   \n",
       "Platypus_cylindrus          247   1337     1364     1345     1338     1326   \n",
       "Xylosandrus_compactus       402   1749     1645     1705     2064     1953   \n",
       "Phloeosinus_dentatus        480   3240     3125     3164     3205     3292   \n",
       "\n",
       "                           train_5  valid  valid_1  valid_2  valid_3  valid_4  \\\n",
       "Species                                                                         \n",
       "Coccotypes_dactyliperda       3641   1011     1073      895      899      774   \n",
       "Xyleborinus_saxesenii         1716    631      548      510      340      318   \n",
       "Pityophthorus_juglandis       3341    795      903      882      770      786   \n",
       "Monarthrum_fasciatum          1011    269      288      297      287      139   \n",
       "Pycnarthrum_hispidium         1413    362      408      431      357      217   \n",
       "Xyleborus_affinis             3654   1015      951      928     1021      754   \n",
       "Scolotodes_schwarzi           1861    458      464      535      472      390   \n",
       "Xylosandrus_crassiusculus     2278    767      362      382      658      876   \n",
       "Hylesinus_varius              1413    413      416      312      329      356   \n",
       "Platypus_cylindrus            1383    352      325      344      351      363   \n",
       "Xylosandrus_compactus         1977    587      691      631      272      383   \n",
       "Phloeosinus_dentatus          3402    807      922      883      842      755   \n",
       "\n",
       "                           valid_5  \n",
       "Species                             \n",
       "Coccotypes_dactyliperda        712  \n",
       "Xyleborinus_saxesenii          457  \n",
       "Pityophthorus_juglandis        648  \n",
       "Monarthrum_fasciatum           104  \n",
       "Pycnarthrum_hispidium          141  \n",
       "Xyleborus_affinis              488  \n",
       "Scolotodes_schwarzi            275  \n",
       "Xylosandrus_crassiusculus      932  \n",
       "Hylesinus_varius               312  \n",
       "Platypus_cylindrus             306  \n",
       "Xylosandrus_compactus          359  \n",
       "Phloeosinus_dentatus           645  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_lst = ['Coccotypes_dactyliperda', 'Hylesinus_varius', 'Monarthrum_fasciatum',\n",
    "                'Phloeosinus_dentatus', 'Pityophthorus_juglandis', 'Platypus_cylindrus',\n",
    "                'Pycnarthrum_hispidium', 'Scolotodes_schwarzi', 'Xyleborinus_saxesenii',\n",
    "                'Xyleborus_affinis', 'Xylosandrus_compactus',\n",
    "                'Xylosandrus_crassiusculus']\n",
    "\n",
    "# get working directory\n",
    "pwd = os.getcwd()\n",
    "raw = r\"E:\\GIT_REPOS\\Beetle_classifier\\Data\\raw\\\\\"\n",
    "data_dist = pd.read_csv(raw+\"Data_distribution.csv\", index_col=\"Species\")\n",
    "data_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa31cf-8b9a-4d43-a778-450952e28b47",
   "metadata": {},
   "source": [
    "# Species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3782b7eb-33ba-4f3d-908c-1fea840ee4f0",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28e3424e-4736-4833-9840-493235b6d452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T01:52:28.459506Z",
     "iopub.status.busy": "2023-06-07T01:52:28.459007Z",
     "iopub.status.idle": "2023-06-07T01:53:51.754900Z",
     "shell.execute_reply": "2023-06-07T01:53:51.753900Z",
     "shell.execute_reply.started": "2023-06-07T01:52:28.459506Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get dictionary of validation results\n",
    "valid_dict = {}\n",
    "for spcs_name in species_lst:\n",
    "    files_path=r\"E:\\GIT_REPOS\\Beetle_classifier\\Data\\raw\\Species\\csv\\valid\\\\\"\n",
    "    valid_or_test=\"Validation\"\n",
    "    folds = 5\n",
    "    unknown_type= 'strict'\n",
    "    wedge_magnitude=1\n",
    "    wedge_threshold=0.85\n",
    "    results_data_lst = []\n",
    "    for fold in range(1,folds+1):\n",
    "        results_data_df = pd.DataFrame()\n",
    "        # import data\n",
    "        df_known = pd.read_csv(files_path+\"\\\\known\\\\\"+spcs_name+\"_\"+valid_or_test+\"_prediction_probabilities_fold-\"+str(fold)+\".csv\").drop('Unnamed: 0', axis=1)\n",
    "        df_unknown = pd.read_csv(files_path+\"\\\\unknown\\\\\"+spcs_name+\"_Unknown_\"+valid_or_test+\"_prediction_probabilities_fold-\"+str(fold)+\".csv\").drop('Unnamed: 0', axis=1)\n",
    "        truth_df = pd.concat([df_known, df_unknown]).reset_index(drop=True)\n",
    "\n",
    "        # add unkown class\n",
    "        truth_df['Unknown'] = truth_df.apply(unknown_prob_calc, axis=1, args=(wedge_threshold, wedge_magnitude, unknown_type)) # strict, or dynamic\n",
    "\n",
    "        # calculate the max class\n",
    "        truth_df['pred'] = truth_df.idxmax(axis=1)\n",
    "\n",
    "        # get the truth values\n",
    "        if valid_or_test==\"Validation\":\n",
    "            valid_series = data_dist[\"valid_\"+str(fold)]\n",
    "            valid_series_reshuffle = valid_series.drop(index=spcs_name)\n",
    "            valid_series_reshuffle = pd.concat([valid_series_reshuffle, valid_series[[spcs_name]]])\n",
    "            truth_lst = []\n",
    "            for spcs, count in valid_series_reshuffle.to_dict().items():\n",
    "                truth_lst = truth_lst + list(np.repeat(spcs, count))\n",
    "            truth_df['truth'] = truth_lst\n",
    "        else:\n",
    "            valid_series = data_dist[\"test\"]\n",
    "            valid_series_reshuffle = valid_series.drop(index=spcs_name)\n",
    "            valid_series_reshuffle = pd.concat([valid_series_reshuffle, valid_series[[spcs_name]]])\n",
    "            truth_lst = []\n",
    "            for spcs, count in valid_series_reshuffle.to_dict().items():\n",
    "                truth_lst = truth_lst + list(np.repeat(spcs, count))\n",
    "            truth_df['truth'] = truth_lst\n",
    "        # change the truth untrianed species to unknown\n",
    "        truth_df.loc[truth_df['truth'] == spcs_name, 'truth'] = 'Unknown'\n",
    "        results_data_df['truth'] = truth_df['truth']\n",
    "        results_data_df['pred'] = truth_df['pred']\n",
    "        results_data_lst.append(results_data_df)\n",
    "        \n",
    "        # save each dataframe as a csv\n",
    "        results_data_df.to_csv(spcs_name+\"_unknown_valid_fold_\"+str(fold)+\".csv\")\n",
    "        \n",
    "    valid_dict[spcs_name] = results_data_lst\n",
    "\n",
    "# save dict as pickle file        \n",
    "with open('valid_dict_species.pkl', 'wb') as f:\n",
    "    pickle.dump(valid_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d26fa5f-09c6-4df2-b8ba-f2bf22848da7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:24:39.434882Z",
     "iopub.status.busy": "2023-06-07T03:24:39.434882Z",
     "iopub.status.idle": "2023-06-07T03:24:41.755193Z",
     "shell.execute_reply": "2023-06-07T03:24:41.754195Z",
     "shell.execute_reply.started": "2023-06-07T03:24:39.434882Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all_lst = []\n",
    "folds = 5\n",
    "files_path=r\"E:\\GIT_REPOS\\Beetle_classifier\\Data\\raw\\Species\\csv\\valid\\\\\"\n",
    "unknown_dict = {}\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1,folds+1):\n",
    "    # loop through species and add them to dataframe list\n",
    "    for spcs_name in species_lst:\n",
    "        df_unknown = pd.read_csv(files_path+\"\\\\unknown\\\\\"+spcs_name+\"_Unknown_Validation_prediction_probabilities_fold-\"+str(fold)+\".csv\").drop('Unnamed: 0', axis=1)\n",
    "        df_unknown.insert(0, 'unknown_species',spcs_name)\n",
    "        df_unknown = df_unknown.fillna(0)\n",
    "        df_unknown.insert(0, 'true',\"Unknown\")\n",
    "        df_all_lst.append(df_unknown)\n",
    "        df_known = pd.read_csv(files_path+\"\\\\known\\\\\"+spcs_name+\"_Validation_prediction_probabilities_fold-\"+str(fold)+\".csv\").drop('Unnamed: 0', axis=1)\n",
    "        df_known.insert(0, 'unknown_species',spcs_name)\n",
    "        df_known = df_known.fillna(0)\n",
    "        df_known.insert(0, 'true',\"Known\")\n",
    "        df_all_lst.append(df_known)\n",
    "    unknown_df_all = pd.concat(df_all_lst).reset_index(drop=True)\n",
    "    unknown_dict[\"fold_\"+str(fold)] = unknown_df_all\n",
    "    \n",
    "for fold in range(1,folds+1):\n",
    "    unknown_dict[\"fold_\"+str(fold)] = unknown_dict[\"fold_\"+str(fold)].fillna(0)\n",
    "    \n",
    "# save dict as pickle file        \n",
    "with open('valid_dict_species_unknown.pkl', 'wb') as f:\n",
    "    pickle.dump(unknown_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ebaed8-069b-4a7e-b8b0-40e0f6937c4a",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83dd944b-8d22-4851-bdde-807e4b416592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T01:53:52.189901Z",
     "iopub.status.busy": "2023-06-07T01:53:52.189400Z",
     "iopub.status.idle": "2023-06-07T01:54:52.203902Z",
     "shell.execute_reply": "2023-06-07T01:54:52.203399Z",
     "shell.execute_reply.started": "2023-06-07T01:53:52.189400Z"
    }
   },
   "outputs": [],
   "source": [
    "# get dictionary of validation results\n",
    "test_dict = {}\n",
    "for spcs_name in species_lst:\n",
    "    files_path=r\"E:\\GIT_REPOS\\Beetle_classifier\\Data\\raw\\Species\\csv\\test\\\\\"\n",
    "    valid_or_test=\"Testing\"\n",
    "    folds = 5\n",
    "    unknown_type= 'strict'\n",
    "    wedge_magnitude=1\n",
    "    wedge_threshold=0.85\n",
    "    results_data_lst = []\n",
    "    for fold in range(1,folds+1):\n",
    "        results_data_df = pd.DataFrame()\n",
    "        # import data\n",
    "        df_known = pd.read_csv(files_path+\"\\\\known\\\\\"+spcs_name+\"_\"+valid_or_test+\"_prediction_probabilities_fold-\"+str(fold)+\".csv\").drop('Unnamed: 0', axis=1)\n",
    "        df_unknown = pd.read_csv(files_path+\"\\\\unknown\\\\\"+spcs_name+\"_Unknown_\"+valid_or_test+\"_prediction_probabilities_fold-\"+str(fold)+\".csv\").drop('Unnamed: 0', axis=1)\n",
    "        truth_df = pd.concat([df_known, df_unknown]).reset_index(drop=True)\n",
    "\n",
    "        # add unkown class\n",
    "        truth_df['Unknown'] = truth_df.apply(unknown_prob_calc, axis=1, args=(wedge_threshold, wedge_magnitude, unknown_type)) # strict, or dynamic\n",
    "\n",
    "        # calculate the max class\n",
    "        truth_df['pred'] = truth_df.idxmax(axis=1)\n",
    "\n",
    "        # get the truth values\n",
    "        if valid_or_test==\"Validation\":\n",
    "            valid_series = data_dist[\"valid_\"+str(fold)]\n",
    "            valid_series_reshuffle = valid_series.drop(index=spcs_name)\n",
    "            valid_series_reshuffle = pd.concat([valid_series_reshuffle, valid_series[[spcs_name]]])\n",
    "            truth_lst = []\n",
    "            for spcs, count in valid_series_reshuffle.to_dict().items():\n",
    "                truth_lst = truth_lst + list(np.repeat(spcs, count))\n",
    "            truth_df['truth'] = truth_lst\n",
    "        else:\n",
    "            valid_series = data_dist[\"test\"]\n",
    "            valid_series_reshuffle = valid_series.drop(index=spcs_name)\n",
    "            valid_series_reshuffle = pd.concat([valid_series_reshuffle, valid_series[[spcs_name]]])\n",
    "            truth_lst = []\n",
    "            for spcs, count in valid_series_reshuffle.to_dict().items():\n",
    "                truth_lst = truth_lst + list(np.repeat(spcs, count))\n",
    "            truth_df['truth'] = truth_lst\n",
    "\n",
    "        # change the truth untrianed species to unknown\n",
    "        truth_df.loc[truth_df['truth'] == spcs_name, 'truth'] = 'Unknown'\n",
    "        results_data_df['truth'] = truth_df['truth']\n",
    "        results_data_df['pred'] = truth_df['pred']\n",
    "        results_data_lst.append(results_data_df)\n",
    "        \n",
    "        # save each dataframe as a csv\n",
    "        results_data_df.to_csv(spcs_name+\"_unknown_test_fold_\"+str(fold)+\".csv\")\n",
    "        \n",
    "    test_dict[spcs_name] = results_data_lst\n",
    "\n",
    "# save dict as pickle file        \n",
    "with open('test_dict_species.pkl', 'wb') as f:\n",
    "    pickle.dump(test_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a25edb02-53db-4e2b-b78e-8c3a833dda03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:24:44.175136Z",
     "iopub.status.busy": "2023-06-07T03:24:44.174636Z",
     "iopub.status.idle": "2023-06-07T03:24:45.824135Z",
     "shell.execute_reply": "2023-06-07T03:24:45.823635Z",
     "shell.execute_reply.started": "2023-06-07T03:24:44.175136Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all_lst = []\n",
    "folds = 5\n",
    "files_path=r\"E:\\GIT_REPOS\\Beetle_classifier\\Data\\raw\\Species\\csv\\test\\\\\"\n",
    "unknown_dict = {}\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1,folds+1):\n",
    "    # loop through species and add them to dataframe list\n",
    "    for spcs_name in species_lst:\n",
    "        df_unknown = pd.read_csv(files_path+\"\\\\unknown\\\\\"+spcs_name+\"_Unknown_Testing_prediction_probabilities_fold-\"+str(fold)+\".csv\").drop('Unnamed: 0', axis=1)\n",
    "        df_unknown.insert(0, 'unknown_species',spcs_name)\n",
    "        df_unknown = df_unknown.fillna(0)\n",
    "        df_unknown.insert(0, 'true',\"Unknown\")\n",
    "        df_all_lst.append(df_unknown)\n",
    "        df_known = pd.read_csv(files_path+\"\\\\known\\\\\"+spcs_name+\"_Testing_prediction_probabilities_fold-\"+str(fold)+\".csv\").drop('Unnamed: 0', axis=1)\n",
    "        df_known.insert(0, 'unknown_species',spcs_name)\n",
    "        df_known = df_known.fillna(0)\n",
    "        df_known.insert(0, 'true',\"Known\")\n",
    "        df_all_lst.append(df_known)\n",
    "    unknown_df_all = pd.concat(df_all_lst).reset_index(drop=True)\n",
    "    unknown_dict[\"fold_\"+str(fold)] = unknown_df_all\n",
    "    \n",
    "for fold in range(1,folds+1):\n",
    "    unknown_dict[\"fold_\"+str(fold)] = unknown_dict[\"fold_\"+str(fold)].fillna(0)\n",
    "    \n",
    "# save dict as pickle file        \n",
    "with open('test_dict_species_unknown.pkl', 'wb') as f:\n",
    "    pickle.dump(unknown_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2898e73-635a-48d8-ac9f-5d1c17af6d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
