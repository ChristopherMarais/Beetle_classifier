{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "853cffee-6e2a-4ee7-a1ea-cd99ab6171fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T19:38:45.296154Z",
     "iopub.status.busy": "2023-06-06T19:38:45.295652Z",
     "iopub.status.idle": "2023-06-06T19:38:46.608630Z",
     "shell.execute_reply": "2023-06-06T19:38:46.608130Z",
     "shell.execute_reply.started": "2023-06-06T19:38:45.296154Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "770c9bf7-c4df-41f2-9736-b2e924a85f7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T19:38:46.610628Z",
     "iopub.status.busy": "2023-06-06T19:38:46.610628Z",
     "iopub.status.idle": "2023-06-06T19:38:46.624629Z",
     "shell.execute_reply": "2023-06-06T19:38:46.623629Z",
     "shell.execute_reply.started": "2023-06-06T19:38:46.610628Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this function only describes how much a singular value in al ist stands out.\n",
    "# if all values in the lsit are high or low this is 1\n",
    "# the smaller the proportiopn of number of disimilar vlaues are to other more similar values the lower this number\n",
    "# the larger the gap between the dissimilar numbers and the simialr number the smaller this number\n",
    "# only able to interpret probabilities or values between 0 and 1\n",
    "# this function outputs an estimate an inverse of the classification confidence based on the probabilities of all the classes.\n",
    "# the wedge threshold splits the data on a threshold with a magnitude of a positive int to force a ledge/peak in the data\n",
    "def unknown_prob_calc(probs, wedge_threshold=0.85, wedge_magnitude=1, wedge='strict'):\n",
    "    if wedge =='strict':\n",
    "        increase_var = (1/(wedge_magnitude))\n",
    "        decrease_var = (wedge_magnitude)\n",
    "    if wedge =='dynamic': # this allows pointsthat are furhter from the threshold ot be moved less and points clsoer to be moved more\n",
    "        increase_var = (1/(wedge_magnitude*((1-np.abs(probs-wedge_threshold)))))\n",
    "        decrease_var = (wedge_magnitude*((1-np.abs(probs-wedge_threshold))))\n",
    "    # else:\n",
    "    #     print(\"Error: use 'strict' (default) or 'dynamic' as options for the wedge parameter!\")\n",
    "    probs = np.where(probs>=wedge_threshold , probs**increase_var, probs)\n",
    "    probs = np.where(probs<=wedge_threshold , probs**decrease_var, probs)\n",
    "    diff_matrix = np.abs(probs[:, np.newaxis] - probs)\n",
    "    diff_matrix_sum = np.sum(diff_matrix)\n",
    "    probs_sum = np.sum(probs)\n",
    "    class_val = (diff_matrix_sum/probs_sum)\n",
    "    max_class_val = ((len(probs)-1)*2)\n",
    "    kown_prob = class_val/max_class_val\n",
    "    unknown_prob = 1-kown_prob\n",
    "    return(unknown_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99ed0d8d-548b-461c-85eb-924287eebfbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T19:38:46.626629Z",
     "iopub.status.busy": "2023-06-06T19:38:46.626134Z",
     "iopub.status.idle": "2023-06-06T19:38:47.150543Z",
     "shell.execute_reply": "2023-06-06T19:38:47.149541Z",
     "shell.execute_reply.started": "2023-06-06T19:38:46.626629Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>train_1</th>\n",
       "      <th>train_2</th>\n",
       "      <th>train_3</th>\n",
       "      <th>train_4</th>\n",
       "      <th>train_5</th>\n",
       "      <th>valid</th>\n",
       "      <th>valid_1</th>\n",
       "      <th>valid_2</th>\n",
       "      <th>valid_3</th>\n",
       "      <th>valid_4</th>\n",
       "      <th>valid_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Coccotypes_dactyliperda</th>\n",
       "      <td>615</td>\n",
       "      <td>3342</td>\n",
       "      <td>3280</td>\n",
       "      <td>3458</td>\n",
       "      <td>3454</td>\n",
       "      <td>3579</td>\n",
       "      <td>3641</td>\n",
       "      <td>1011</td>\n",
       "      <td>1073</td>\n",
       "      <td>895</td>\n",
       "      <td>899</td>\n",
       "      <td>774</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xyleborinus_saxesenii</th>\n",
       "      <td>380</td>\n",
       "      <td>1542</td>\n",
       "      <td>1625</td>\n",
       "      <td>1663</td>\n",
       "      <td>1833</td>\n",
       "      <td>1855</td>\n",
       "      <td>1716</td>\n",
       "      <td>631</td>\n",
       "      <td>548</td>\n",
       "      <td>510</td>\n",
       "      <td>340</td>\n",
       "      <td>318</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pityophthorus_juglandis</th>\n",
       "      <td>680</td>\n",
       "      <td>3194</td>\n",
       "      <td>3086</td>\n",
       "      <td>3107</td>\n",
       "      <td>3219</td>\n",
       "      <td>3203</td>\n",
       "      <td>3341</td>\n",
       "      <td>795</td>\n",
       "      <td>903</td>\n",
       "      <td>882</td>\n",
       "      <td>770</td>\n",
       "      <td>786</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monarthrum_fasciatum</th>\n",
       "      <td>133</td>\n",
       "      <td>846</td>\n",
       "      <td>827</td>\n",
       "      <td>818</td>\n",
       "      <td>828</td>\n",
       "      <td>976</td>\n",
       "      <td>1011</td>\n",
       "      <td>269</td>\n",
       "      <td>288</td>\n",
       "      <td>297</td>\n",
       "      <td>287</td>\n",
       "      <td>139</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pycnarthrum_hispidium</th>\n",
       "      <td>208</td>\n",
       "      <td>1192</td>\n",
       "      <td>1146</td>\n",
       "      <td>1123</td>\n",
       "      <td>1197</td>\n",
       "      <td>1337</td>\n",
       "      <td>1413</td>\n",
       "      <td>362</td>\n",
       "      <td>408</td>\n",
       "      <td>431</td>\n",
       "      <td>357</td>\n",
       "      <td>217</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xyleborus_affinis</th>\n",
       "      <td>456</td>\n",
       "      <td>3127</td>\n",
       "      <td>3191</td>\n",
       "      <td>3214</td>\n",
       "      <td>3121</td>\n",
       "      <td>3388</td>\n",
       "      <td>3654</td>\n",
       "      <td>1015</td>\n",
       "      <td>951</td>\n",
       "      <td>928</td>\n",
       "      <td>1021</td>\n",
       "      <td>754</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scolotodes_schwarzi</th>\n",
       "      <td>467</td>\n",
       "      <td>1678</td>\n",
       "      <td>1672</td>\n",
       "      <td>1601</td>\n",
       "      <td>1664</td>\n",
       "      <td>1746</td>\n",
       "      <td>1861</td>\n",
       "      <td>458</td>\n",
       "      <td>464</td>\n",
       "      <td>535</td>\n",
       "      <td>472</td>\n",
       "      <td>390</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xylosandrus_crassiusculus</th>\n",
       "      <td>326</td>\n",
       "      <td>2443</td>\n",
       "      <td>2848</td>\n",
       "      <td>2828</td>\n",
       "      <td>2552</td>\n",
       "      <td>2334</td>\n",
       "      <td>2278</td>\n",
       "      <td>767</td>\n",
       "      <td>362</td>\n",
       "      <td>382</td>\n",
       "      <td>658</td>\n",
       "      <td>876</td>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hylesinus_varius</th>\n",
       "      <td>216</td>\n",
       "      <td>1312</td>\n",
       "      <td>1309</td>\n",
       "      <td>1413</td>\n",
       "      <td>1396</td>\n",
       "      <td>1369</td>\n",
       "      <td>1413</td>\n",
       "      <td>413</td>\n",
       "      <td>416</td>\n",
       "      <td>312</td>\n",
       "      <td>329</td>\n",
       "      <td>356</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platypus_cylindrus</th>\n",
       "      <td>247</td>\n",
       "      <td>1337</td>\n",
       "      <td>1364</td>\n",
       "      <td>1345</td>\n",
       "      <td>1338</td>\n",
       "      <td>1326</td>\n",
       "      <td>1383</td>\n",
       "      <td>352</td>\n",
       "      <td>325</td>\n",
       "      <td>344</td>\n",
       "      <td>351</td>\n",
       "      <td>363</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xylosandrus_compactus</th>\n",
       "      <td>402</td>\n",
       "      <td>1749</td>\n",
       "      <td>1645</td>\n",
       "      <td>1705</td>\n",
       "      <td>2064</td>\n",
       "      <td>1953</td>\n",
       "      <td>1977</td>\n",
       "      <td>587</td>\n",
       "      <td>691</td>\n",
       "      <td>631</td>\n",
       "      <td>272</td>\n",
       "      <td>383</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phloeosinus_dentatus</th>\n",
       "      <td>480</td>\n",
       "      <td>3240</td>\n",
       "      <td>3125</td>\n",
       "      <td>3164</td>\n",
       "      <td>3205</td>\n",
       "      <td>3292</td>\n",
       "      <td>3402</td>\n",
       "      <td>807</td>\n",
       "      <td>922</td>\n",
       "      <td>883</td>\n",
       "      <td>842</td>\n",
       "      <td>755</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           test  train  train_1  train_2  train_3  train_4  \\\n",
       "Species                                                                      \n",
       "Coccotypes_dactyliperda     615   3342     3280     3458     3454     3579   \n",
       "Xyleborinus_saxesenii       380   1542     1625     1663     1833     1855   \n",
       "Pityophthorus_juglandis     680   3194     3086     3107     3219     3203   \n",
       "Monarthrum_fasciatum        133    846      827      818      828      976   \n",
       "Pycnarthrum_hispidium       208   1192     1146     1123     1197     1337   \n",
       "Xyleborus_affinis           456   3127     3191     3214     3121     3388   \n",
       "Scolotodes_schwarzi         467   1678     1672     1601     1664     1746   \n",
       "Xylosandrus_crassiusculus   326   2443     2848     2828     2552     2334   \n",
       "Hylesinus_varius            216   1312     1309     1413     1396     1369   \n",
       "Platypus_cylindrus          247   1337     1364     1345     1338     1326   \n",
       "Xylosandrus_compactus       402   1749     1645     1705     2064     1953   \n",
       "Phloeosinus_dentatus        480   3240     3125     3164     3205     3292   \n",
       "\n",
       "                           train_5  valid  valid_1  valid_2  valid_3  valid_4  \\\n",
       "Species                                                                         \n",
       "Coccotypes_dactyliperda       3641   1011     1073      895      899      774   \n",
       "Xyleborinus_saxesenii         1716    631      548      510      340      318   \n",
       "Pityophthorus_juglandis       3341    795      903      882      770      786   \n",
       "Monarthrum_fasciatum          1011    269      288      297      287      139   \n",
       "Pycnarthrum_hispidium         1413    362      408      431      357      217   \n",
       "Xyleborus_affinis             3654   1015      951      928     1021      754   \n",
       "Scolotodes_schwarzi           1861    458      464      535      472      390   \n",
       "Xylosandrus_crassiusculus     2278    767      362      382      658      876   \n",
       "Hylesinus_varius              1413    413      416      312      329      356   \n",
       "Platypus_cylindrus            1383    352      325      344      351      363   \n",
       "Xylosandrus_compactus         1977    587      691      631      272      383   \n",
       "Phloeosinus_dentatus          3402    807      922      883      842      755   \n",
       "\n",
       "                           valid_5  \n",
       "Species                             \n",
       "Coccotypes_dactyliperda        712  \n",
       "Xyleborinus_saxesenii          457  \n",
       "Pityophthorus_juglandis        648  \n",
       "Monarthrum_fasciatum           104  \n",
       "Pycnarthrum_hispidium          141  \n",
       "Xyleborus_affinis              488  \n",
       "Scolotodes_schwarzi            275  \n",
       "Xylosandrus_crassiusculus      932  \n",
       "Hylesinus_varius               312  \n",
       "Platypus_cylindrus             306  \n",
       "Xylosandrus_compactus          359  \n",
       "Phloeosinus_dentatus           645  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get working directory\n",
    "pwd = os.getcwd()\n",
    "raw = r\"E:\\GIT_REPOS\\Beetle_classifier\\Data\\raw\\\\\"\n",
    "species_test_dir = r\"E:\\GIT_REPOS\\Beetle_classifier\\Data\\raw\\Species\\csv\\test\\\\\"\n",
    "species_valid_dir = r\"E:\\GIT_REPOS\\Beetle_classifier\\Data\\raw\\Species\\csv\\valid\\\\\"\n",
    "\n",
    "species_lst = ['Coccotypes_dactyliperda', 'Hylesinus_varius', 'Monarthrum_fasciatum',\n",
    "                'Phloeosinus_dentatus', 'Pityophthorus_juglandis', 'Platypus_cylindrus',\n",
    "                'Pycnarthrum_hispidium', 'Scolotodes_schwarzi', 'Xyleborinus_saxesenii',\n",
    "                'Xyleborus_affinis', 'Xylosandrus_compactus',\n",
    "                'Xylosandrus_crassiusculus']\n",
    "\n",
    "data_dist = pd.read_csv(raw+\"Data_distribution.csv\", index_col=\"Species\")\n",
    "data_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa31cf-8b9a-4d43-a778-450952e28b47",
   "metadata": {},
   "source": [
    "# Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc65306b-d8d9-44b2-8f3a-4b4b419e9543",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T19:38:47.152043Z",
     "iopub.status.busy": "2023-06-06T19:38:47.151544Z",
     "iopub.status.idle": "2023-06-06T19:38:48.057430Z",
     "shell.execute_reply": "2023-06-06T19:38:48.056929Z",
     "shell.execute_reply.started": "2023-06-06T19:38:47.152043Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # validation results calcualtion\n",
    "# def calc_results(spcs_name, files_path=species_valid_dir, valid_or_test=\"Validation\", folds = 5, unknown_type= 'strict', wedge_magnitude=1, wedge_threshold=0.85): \n",
    "#     Validation or Testing\n",
    "#     conf_mat_lst = []\n",
    "#     precision_recall_fscore_support_mat_lst = []\n",
    "#     classification_report_lst = []\n",
    "#     for fold in range(1,folds+1):\n",
    "#         # import data\n",
    "#         df_known = pd.read_csv(files_path+\"\\\\known\\\\\"+spcs_name+\"_\"+valid_or_test+\"_prediction_probabilities_fold-\"+str(fold)+\".csv\").drop('Unnamed: 0', axis=1)\n",
    "#         df_unknown = pd.read_csv(files_path+\"\\\\unknown\\\\\"+spcs_name+\"_Unknown_\"+valid_or_test+\"_prediction_probabilities_fold-\"+str(fold)+\".csv\").drop('Unnamed: 0', axis=1)\n",
    "#         truth_df = pd.concat([df_known, df_unknown]).reset_index(drop=True)\n",
    "\n",
    "#         # add unkown class\n",
    "#         truth_df['Unknown'] = truth_df.apply(unknown_prob_calc, axis=1, args=(wedge_threshold, wedge_magnitude, unknown_type)) # strict, or dynamic\n",
    "\n",
    "#         # calculate the max class\n",
    "#         truth_df['pred'] = truth_df.idxmax(axis=1)\n",
    "\n",
    "#         # get the truth values\n",
    "#         if valid_or_test==\"Validation\":\n",
    "#             valid_series = data_dist[\"valid_\"+str(fold)]\n",
    "#             valid_series_reshuffle = valid_series.drop(index=spcs_name)\n",
    "#             valid_series_reshuffle = pd.concat([valid_series_reshuffle, valid_series[[spcs_name]]])\n",
    "#             truth_lst = []\n",
    "#             for spcs, count in valid_series_reshuffle.to_dict().items():\n",
    "#                 truth_lst = truth_lst + list(np.repeat(spcs, count))\n",
    "#             truth_df['truth'] = truth_lst\n",
    "#         else:\n",
    "#             valid_series = data_dist[\"test\"]\n",
    "#             valid_series_reshuffle = valid_series.drop(index=spcs_name)\n",
    "#             valid_series_reshuffle = pd.concat([valid_series_reshuffle, valid_series[[spcs_name]]])\n",
    "#             truth_lst = []\n",
    "#             for spcs, count in valid_series_reshuffle.to_dict().items():\n",
    "#                 truth_lst = truth_lst + list(np.repeat(spcs, count))\n",
    "#             truth_df['truth'] = truth_lst\n",
    "\n",
    "#         # change the truth untrianed species to unknown\n",
    "#         truth_df.loc[truth_df['truth'] == spcs_name, 'truth'] = 'Unknown'\n",
    "\n",
    "#         # calculate the confusion matrix and metrics\n",
    "#         conf_mat = confusion_matrix(y_true=truth_df['truth'], y_pred=truth_df['pred'])\n",
    "#         conf_mat_lst.append(conf_mat)\n",
    "#         precision_recall_fscore_support_mat = precision_recall_fscore_support(y_true=truth_df['truth'], y_pred=truth_df['pred'])\n",
    "#         precision_recall_fscore_support_mat_lst.append(precision_recall_fscore_support_mat)\n",
    "#         classification_report_txt = classification_report(y_true=truth_df['truth'], y_pred=truth_df['pred'])\n",
    "#         classification_report_lst.append(classification_report_txt)\n",
    "#     if valid_or_test==\"Validation\":\n",
    "#         conf_mat_5_fold_df = pd.DataFrame(sum(conf_mat_lst), columns=truth_df.columns[:-2], index=truth_df.columns[:-2])\n",
    "#     else:\n",
    "#         conf_mat_5_fold_df = pd.DataFrame(sum(conf_mat_lst), columns=truth_df.columns[:-2], index=truth_df.columns[:-2])/folds\n",
    "        \n",
    "#     precision_recall_fscore_support_mat_df = pd.DataFrame(np.sum(precision_recall_fscore_support_mat_lst, axis=0), columns=truth_df.columns[:-2], index=[\"precision\",\"recall\",\"fbeta_score\",\"support\"])\n",
    "#     precision_recall_fscore_support_mat_df.iloc[:-1] = precision_recall_fscore_support_mat_df.iloc[:-1]/folds\n",
    "#     return(conf_mat_5_fold_df, precision_recall_fscore_support_mat_df, classification_report_lst)\n",
    "#     return(truth_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3782b7eb-33ba-4f3d-908c-1fea840ee4f0",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28e3424e-4736-4833-9840-493235b6d452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T20:03:42.122768Z",
     "iopub.status.busy": "2023-06-06T20:03:42.122768Z",
     "iopub.status.idle": "2023-06-06T20:05:00.280769Z",
     "shell.execute_reply": "2023-06-06T20:05:00.279768Z",
     "shell.execute_reply.started": "2023-06-06T20:03:42.122768Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get dictionary of validation results\n",
    "valid_dict = {}\n",
    "for spcs_name in species_lst:\n",
    "    files_path=r\"E:\\GIT_REPOS\\Beetle_classifier\\Data\\raw\\Species\\csv\\valid\\\\\"\n",
    "    valid_or_test=\"Validation\"\n",
    "    folds = 5\n",
    "    unknown_type= 'strict'\n",
    "    wedge_magnitude=1\n",
    "    wedge_threshold=0.85\n",
    "    results_data_lst = []\n",
    "    for fold in range(1,folds+1):\n",
    "        results_data_df = pd.DataFrame()\n",
    "        # import data\n",
    "        df_known = pd.read_csv(files_path+\"\\\\known\\\\\"+spcs_name+\"_\"+valid_or_test+\"_prediction_probabilities_fold-\"+str(fold)+\".csv\").drop('Unnamed: 0', axis=1)\n",
    "        df_unknown = pd.read_csv(files_path+\"\\\\unknown\\\\\"+spcs_name+\"_Unknown_\"+valid_or_test+\"_prediction_probabilities_fold-\"+str(fold)+\".csv\").drop('Unnamed: 0', axis=1)\n",
    "        truth_df = pd.concat([df_known, df_unknown]).reset_index(drop=True)\n",
    "\n",
    "        # add unkown class\n",
    "        truth_df['Unknown'] = truth_df.apply(unknown_prob_calc, axis=1, args=(wedge_threshold, wedge_magnitude, unknown_type)) # strict, or dynamic\n",
    "\n",
    "        # calculate the max class\n",
    "        truth_df['pred'] = truth_df.idxmax(axis=1)\n",
    "\n",
    "        # get the truth values\n",
    "        if valid_or_test==\"Validation\":\n",
    "            valid_series = data_dist[\"valid_\"+str(fold)]\n",
    "            valid_series_reshuffle = valid_series.drop(index=spcs_name)\n",
    "            valid_series_reshuffle = pd.concat([valid_series_reshuffle, valid_series[[spcs_name]]])\n",
    "            truth_lst = []\n",
    "            for spcs, count in valid_series_reshuffle.to_dict().items():\n",
    "                truth_lst = truth_lst + list(np.repeat(spcs, count))\n",
    "            truth_df['truth'] = truth_lst\n",
    "        else:\n",
    "            valid_series = data_dist[\"test\"]\n",
    "            valid_series_reshuffle = valid_series.drop(index=spcs_name)\n",
    "            valid_series_reshuffle = pd.concat([valid_series_reshuffle, valid_series[[spcs_name]]])\n",
    "            truth_lst = []\n",
    "            for spcs, count in valid_series_reshuffle.to_dict().items():\n",
    "                truth_lst = truth_lst + list(np.repeat(spcs, count))\n",
    "            truth_df['truth'] = truth_lst\n",
    "\n",
    "        # change the truth untrianed species to unknown\n",
    "        truth_df.loc[truth_df['truth'] == spcs_name, 'truth'] = 'Unknown'\n",
    "        results_data_df['truth'] = truth_df['truth']\n",
    "        results_data_df['pred'] = truth_df['pred']\n",
    "        results_data_lst.append(results_data_df)\n",
    "        \n",
    "        # save each dataframe as a csv\n",
    "        results_data_df.to_csv(spcs_name+\"_unknown_valid_fold_\"+str(fold)+\".csv\")\n",
    "        \n",
    "    valid_dict[spcs_name] = results_data_lst\n",
    "\n",
    "# save dict as pickle file        \n",
    "with open('valid_dict_species.pkl', 'wb') as f:\n",
    "    pickle.dump(valid_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7471e076-a5ca-4afd-ab3d-313e7595319f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T19:38:48.058431Z",
     "iopub.status.busy": "2023-06-06T19:38:48.057929Z",
     "iopub.status.idle": "2023-06-06T19:40:18.467432Z",
     "shell.execute_reply": "2023-06-06T19:40:18.466425Z",
     "shell.execute_reply.started": "2023-06-06T19:38:48.058431Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # get dictionary of validation results\n",
    "# valid_dict = {}\n",
    "# for spcs_name in species_lst:\n",
    "#     valid_dict[spcs_name] = calc_results(spcs_name=spcs_name, files_path=species_valid_dir, valid_or_test=\"Validation\")\n",
    "    \n",
    "# # save dictionary to disk\n",
    "# with open('valid_dict_species.pkl', 'wb') as f:\n",
    "#     pickle.dump(valid_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ebaed8-069b-4a7e-b8b0-40e0f6937c4a",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dd944b-8d22-4851-bdde-807e4b416592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dictionary of validation results\n",
    "test_dict = {}\n",
    "for spcs_name in species_lst:\n",
    "    files_path=r\"E:\\GIT_REPOS\\Beetle_classifier\\Data\\raw\\Species\\csv\\test\\\\\"\n",
    "    valid_or_test=\"Testing\"\n",
    "    folds = 5\n",
    "    unknown_type= 'strict'\n",
    "    wedge_magnitude=1\n",
    "    wedge_threshold=0.85\n",
    "    results_data_lst = []\n",
    "    for fold in range(1,folds+1):\n",
    "        results_data_df = pd.DataFrame()\n",
    "        # import data\n",
    "        df_known = pd.read_csv(files_path+\"\\\\known\\\\\"+spcs_name+\"_\"+valid_or_test+\"_prediction_probabilities_fold-\"+str(fold)+\".csv\").drop('Unnamed: 0', axis=1)\n",
    "        df_unknown = pd.read_csv(files_path+\"\\\\unknown\\\\\"+spcs_name+\"_Unknown_\"+valid_or_test+\"_prediction_probabilities_fold-\"+str(fold)+\".csv\").drop('Unnamed: 0', axis=1)\n",
    "        truth_df = pd.concat([df_known, df_unknown]).reset_index(drop=True)\n",
    "\n",
    "        # add unkown class\n",
    "        truth_df['Unknown'] = truth_df.apply(unknown_prob_calc, axis=1, args=(wedge_threshold, wedge_magnitude, unknown_type)) # strict, or dynamic\n",
    "\n",
    "        # calculate the max class\n",
    "        truth_df['pred'] = truth_df.idxmax(axis=1)\n",
    "\n",
    "        # get the truth values\n",
    "        if valid_or_test==\"Validation\":\n",
    "            valid_series = data_dist[\"valid_\"+str(fold)]\n",
    "            valid_series_reshuffle = valid_series.drop(index=spcs_name)\n",
    "            valid_series_reshuffle = pd.concat([valid_series_reshuffle, valid_series[[spcs_name]]])\n",
    "            truth_lst = []\n",
    "            for spcs, count in valid_series_reshuffle.to_dict().items():\n",
    "                truth_lst = truth_lst + list(np.repeat(spcs, count))\n",
    "            truth_df['truth'] = truth_lst\n",
    "        else:\n",
    "            valid_series = data_dist[\"test\"]\n",
    "            valid_series_reshuffle = valid_series.drop(index=spcs_name)\n",
    "            valid_series_reshuffle = pd.concat([valid_series_reshuffle, valid_series[[spcs_name]]])\n",
    "            truth_lst = []\n",
    "            for spcs, count in valid_series_reshuffle.to_dict().items():\n",
    "                truth_lst = truth_lst + list(np.repeat(spcs, count))\n",
    "            truth_df['truth'] = truth_lst\n",
    "\n",
    "        # change the truth untrianed species to unknown\n",
    "        truth_df.loc[truth_df['truth'] == spcs_name, 'truth'] = 'Unknown'\n",
    "        results_data_df['truth'] = truth_df['truth']\n",
    "        results_data_df['pred'] = truth_df['pred']\n",
    "        results_data_lst.append(results_data_df)\n",
    "        \n",
    "        # save each dataframe as a csv\n",
    "        results_data_df.to_csv(spcs_name+\"_unknown_test_fold_\"+str(fold)+\".csv\")\n",
    "        \n",
    "    test_dict[spcs_name] = results_data_lst\n",
    "\n",
    "# save dict as pickle file        \n",
    "with open('test_dict_species.pkl', 'wb') as f:\n",
    "    pickle.dump(test_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37f06c2d-f132-48b4-bdea-28ddc75d731c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T19:40:18.468428Z",
     "iopub.status.busy": "2023-06-06T19:40:18.468428Z",
     "iopub.status.idle": "2023-06-06T19:41:22.730041Z",
     "shell.execute_reply": "2023-06-06T19:41:22.729541Z",
     "shell.execute_reply.started": "2023-06-06T19:40:18.468428Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # get dictionary of validation results\n",
    "# test_dict = {}\n",
    "# for spcs_name in species_lst:\n",
    "#     test_dict[spcs_name] = calc_results(spcs_name=spcs_name, files_path=species_test_dir, valid_or_test=\"Testing\")\n",
    "    \n",
    "# # save dictionary to disk\n",
    "# with open('test_dict_species.pkl', 'wb') as f:\n",
    "#     pickle.dump(test_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06163a9-fb45-4568-a255-866b7656ddb5",
   "metadata": {},
   "source": [
    "# Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "073cf25b-95b9-4ab2-9606-ebdc2815bf72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T19:41:22.733545Z",
     "iopub.status.busy": "2023-06-06T19:41:22.733044Z",
     "iopub.status.idle": "2023-06-06T19:41:22.762043Z",
     "shell.execute_reply": "2023-06-06T19:41:22.760542Z",
     "shell.execute_reply.started": "2023-06-06T19:41:22.733545Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold-1_image_number</th>\n",
       "      <th>fold-2_image_number</th>\n",
       "      <th>fold-3_image_number</th>\n",
       "      <th>fold-4_image_number</th>\n",
       "      <th>fold-5_image_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>219</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>393</td>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "      <td>440</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>609</td>\n",
       "      <td>610</td>\n",
       "      <td>550</td>\n",
       "      <td>579</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>793</td>\n",
       "      <td>847</td>\n",
       "      <td>787</td>\n",
       "      <td>761</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975</td>\n",
       "      <td>1029</td>\n",
       "      <td>971</td>\n",
       "      <td>962</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1175</td>\n",
       "      <td>1184</td>\n",
       "      <td>1126</td>\n",
       "      <td>1134</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1336</td>\n",
       "      <td>1345</td>\n",
       "      <td>1298</td>\n",
       "      <td>1354</td>\n",
       "      <td>1311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1492</td>\n",
       "      <td>1529</td>\n",
       "      <td>1498</td>\n",
       "      <td>1533</td>\n",
       "      <td>1485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1668</td>\n",
       "      <td>1726</td>\n",
       "      <td>1695</td>\n",
       "      <td>1770</td>\n",
       "      <td>1706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1840</td>\n",
       "      <td>1898</td>\n",
       "      <td>1834</td>\n",
       "      <td>1970</td>\n",
       "      <td>1913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014</td>\n",
       "      <td>2072</td>\n",
       "      <td>2013</td>\n",
       "      <td>2142</td>\n",
       "      <td>2295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2189</td>\n",
       "      <td>2248</td>\n",
       "      <td>2189</td>\n",
       "      <td>2342</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2396</td>\n",
       "      <td>2455</td>\n",
       "      <td>2405</td>\n",
       "      <td>2724</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2535</td>\n",
       "      <td>2627</td>\n",
       "      <td>2626</td>\n",
       "      <td>2879</td>\n",
       "      <td>2905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2736</td>\n",
       "      <td>2828</td>\n",
       "      <td>2827</td>\n",
       "      <td>3040</td>\n",
       "      <td>3066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2891</td>\n",
       "      <td>3048</td>\n",
       "      <td>3047</td>\n",
       "      <td>3214</td>\n",
       "      <td>3282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3070</td>\n",
       "      <td>3248</td>\n",
       "      <td>3247</td>\n",
       "      <td>3370</td>\n",
       "      <td>3438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3452</td>\n",
       "      <td>3630</td>\n",
       "      <td>3454</td>\n",
       "      <td>3554</td>\n",
       "      <td>3638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3452</td>\n",
       "      <td>3630</td>\n",
       "      <td>3454</td>\n",
       "      <td>3751</td>\n",
       "      <td>3813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fold-1_image_number  fold-2_image_number  fold-3_image_number  \\\n",
       "0                   172                  175                  175   \n",
       "1                   393                  394                  394   \n",
       "2                   609                  610                  550   \n",
       "3                   793                  847                  787   \n",
       "4                   975                 1029                  971   \n",
       "5                  1175                 1184                 1126   \n",
       "6                  1336                 1345                 1298   \n",
       "7                  1492                 1529                 1498   \n",
       "8                  1668                 1726                 1695   \n",
       "9                  1840                 1898                 1834   \n",
       "10                 2014                 2072                 2013   \n",
       "11                 2189                 2248                 2189   \n",
       "12                 2396                 2455                 2405   \n",
       "13                 2535                 2627                 2626   \n",
       "14                 2736                 2828                 2827   \n",
       "15                 2891                 3048                 3047   \n",
       "16                 3070                 3248                 3247   \n",
       "17                 3452                 3630                 3454   \n",
       "18                 3452                 3630                 3454   \n",
       "\n",
       "    fold-4_image_number  fold-5_image_number  \n",
       "0                   219                  172  \n",
       "1                   440                  391  \n",
       "2                   579                  530  \n",
       "3                   761                  712  \n",
       "4                   962                  891  \n",
       "5                  1134                 1091  \n",
       "6                  1354                 1311  \n",
       "7                  1533                 1485  \n",
       "8                  1770                 1706  \n",
       "9                  1970                 1913  \n",
       "10                 2142                 2295  \n",
       "11                 2342                 2492  \n",
       "12                 2724                 2729  \n",
       "13                 2879                 2905  \n",
       "14                 3040                 3066  \n",
       "15                 3214                 3282  \n",
       "16                 3370                 3438  \n",
       "17                 3554                 3638  \n",
       "18                 3751                 3813  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_size_df = pd.read_csv(r\"E:\\GIT_REPOS\\Beetle_classifier\\Data\\raw\\Size\\csv\\data_size_results.csv\")\n",
    "data_size_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1d66c3-56c7-434d-986b-d1ee87b9107b",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "083f326e-34c6-4dc5-b25a-4e6c4bdd712f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T19:48:04.851743Z",
     "iopub.status.busy": "2023-06-06T19:48:04.851243Z",
     "iopub.status.idle": "2023-06-06T19:48:11.842746Z",
     "shell.execute_reply": "2023-06-06T19:48:11.842243Z",
     "shell.execute_reply.started": "2023-06-06T19:48:04.851743Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_dir = r\"E:\\GIT_REPOS\\Beetle_classifier\\Data\\raw\\Size\\csv\\valid\\\\\"\n",
    "folds = 5\n",
    "size_num = 19\n",
    "\n",
    "# get all different sized results from data\n",
    "valid_dict = {}\n",
    "for fold in range(1,folds+1):\n",
    "    size_results_df = pd.DataFrame()\n",
    "    data_size_summary_df = pd.DataFrame()\n",
    "    data_size_summary_df['valid'] = data_dist[\"valid_\"+str(fold)]\n",
    "    for size in range(1,size_num+1):\n",
    "        truth_df = pd.read_csv(valid_dir+str(size)+\"_Validation_prediction_probabilities_fold-\"+str(fold)+\".csv\").drop('Unnamed: 0', axis=1)\n",
    "        # calculate the max class\n",
    "        truth_df['pred'] = truth_df.idxmax(axis=1)\n",
    "\n",
    "        # add truth value\n",
    "        valid_series = data_dist[\"valid_\"+str(fold)]\n",
    "        truth_lst = []\n",
    "        for spcs, count in valid_series.to_dict().items():\n",
    "            truth_lst = truth_lst + list(np.repeat(spcs, count))\n",
    "        truth_df['truth'] = truth_lst\n",
    "\n",
    "        # get truth and pred valeus for all sizes\n",
    "        size_results_df['truth_'+str(size)] = truth_df['truth']\n",
    "        size_results_df['pred_'+str(size)] = truth_df['pred']\n",
    "        \n",
    "        \n",
    "        # get the training data size df\n",
    "        train_series = data_dist[\"train_\"+str(fold)]\n",
    "        train_series['Coccotypes_dactyliperda']=data_size_df[\"fold-\"+str(fold)+\"_image_number\"].loc[size-1]\n",
    "        data_size_summary_df['train_'+str(size)] = train_series\n",
    "    \n",
    "    # save each dataframe as a csv\n",
    "    data_size_summary_df.to_csv(\"valid_data_size_summary_fold_\"+str(fold)+\".csv\")\n",
    "    size_results_df.to_csv(\"valid_size_results_fold_\"+str(fold)+\".csv\")\n",
    "    \n",
    "    # save all data to dictionary\n",
    "    valid_dict[\"fold_\"+str(fold)] = [data_size_summary_df, size_results_df]\n",
    "    \n",
    "# save dictionary to disk\n",
    "with open('valid_dict_size.pkl', 'wb') as f:\n",
    "    pickle.dump(valid_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0644535-9d2e-4b17-babf-1d50424f45bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fed3e99b-dfcb-4970-838a-97b01fd40eb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T19:48:11.844243Z",
     "iopub.status.busy": "2023-06-06T19:48:11.843743Z",
     "iopub.status.idle": "2023-06-06T19:48:16.988745Z",
     "shell.execute_reply": "2023-06-06T19:48:16.988243Z",
     "shell.execute_reply.started": "2023-06-06T19:48:11.844243Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dir = r\"E:\\GIT_REPOS\\Beetle_classifier\\Data\\raw\\Size\\csv\\test\\\\\"\n",
    "folds = 5\n",
    "size_num = 19\n",
    "\n",
    "# get all different sized results from data\n",
    "test_dict = {}\n",
    "for fold in range(1,folds+1):\n",
    "    size_results_df = pd.DataFrame()\n",
    "    data_size_summary_df = pd.DataFrame()\n",
    "    data_size_summary_df['test'] = data_dist[\"test\"]\n",
    "    for size in range(1,size_num+1):\n",
    "        truth_df = pd.read_csv(test_dir+str(size)+\"_Testing_prediction_probabilities_fold-\"+str(fold)+\".csv\").drop('Unnamed: 0', axis=1)\n",
    "        # calculate the max class\n",
    "        truth_df['pred'] = truth_df.idxmax(axis=1)\n",
    "\n",
    "        # add truth value\n",
    "        test_series = data_dist[\"test\"]\n",
    "        truth_lst = []\n",
    "        for spcs, count in test_series.to_dict().items():\n",
    "            truth_lst = truth_lst + list(np.repeat(spcs, count))\n",
    "        truth_df['truth'] = truth_lst\n",
    "\n",
    "        # get truth and pred valeus for all sizes\n",
    "        size_results_df['truth_'+str(size)] = truth_df['truth']\n",
    "        size_results_df['pred_'+str(size)] = truth_df['pred']\n",
    "        \n",
    "        \n",
    "        # get the training data size df\n",
    "        train_series = data_dist[\"train_\"+str(fold)]\n",
    "        train_series['Coccotypes_dactyliperda']=data_size_df[\"fold-\"+str(fold)+\"_image_number\"].loc[size-1]\n",
    "        data_size_summary_df['train_'+str(size)] = train_series\n",
    "    \n",
    "    # save each dataframe as a csv\n",
    "    data_size_summary_df.to_csv(\"test_data_size_summary_fold_\"+str(fold)+\".csv\")\n",
    "    size_results_df.to_csv(\"test_size_results_fold_\"+str(fold)+\".csv\")\n",
    "    \n",
    "    # save all data to dictionary\n",
    "    test_dict[\"fold_\"+str(fold)] = [data_size_summary_df, size_results_df]\n",
    "    \n",
    "# save dictionary to disk\n",
    "with open('test_dict_size.pkl', 'wb') as f:\n",
    "    pickle.dump(test_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47515246-54ae-47b2-82f0-5ab9ad980769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T19:16:55.076535Z",
     "iopub.status.busy": "2023-06-06T19:16:55.076038Z",
     "iopub.status.idle": "2023-06-06T19:16:55.093539Z",
     "shell.execute_reply": "2023-06-06T19:16:55.092537Z",
     "shell.execute_reply.started": "2023-06-06T19:16:55.076535Z"
    },
    "tags": []
   },
   "source": [
    "# Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5aee85-5cb0-4c09-b8c0-881248351af0",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd51a8f-07e7-4438-af85-898942583fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42f792d8-63c2-47b5-b78f-d0feffd526b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f906c0fb-5dd0-4968-929c-33f5aeceb562",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
