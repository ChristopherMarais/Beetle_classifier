{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "612c7c6a-a285-4d0a-a2c2-7ad14aef8ea6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T20:38:21.345093Z",
     "iopub.status.busy": "2023-06-06T20:38:21.344596Z",
     "iopub.status.idle": "2023-06-06T20:38:21.830094Z",
     "shell.execute_reply": "2023-06-06T20:38:21.829102Z",
     "shell.execute_reply.started": "2023-06-06T20:38:21.345093Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8c781c3-5125-444e-b7d4-0e9b5440680f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T20:39:02.665658Z",
     "iopub.status.busy": "2023-06-06T20:39:02.665158Z",
     "iopub.status.idle": "2023-06-06T20:39:02.682662Z",
     "shell.execute_reply": "2023-06-06T20:39:02.682159Z",
     "shell.execute_reply.started": "2023-06-06T20:39:02.665658Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "species_lst = ['Coccotypes_dactyliperda', 'Hylesinus_varius', 'Monarthrum_fasciatum',\n",
    "                'Phloeosinus_dentatus', 'Pityophthorus_juglandis', 'Platypus_cylindrus',\n",
    "                'Pycnarthrum_hispidium', 'Scolotodes_schwarzi', 'Xyleborinus_saxesenii',\n",
    "                'Xyleborus_affinis', 'Xylosandrus_compactus',\n",
    "                'Xylosandrus_crassiusculus']\n",
    "\n",
    "# get working directory\n",
    "pwd = os.getcwd()\n",
    "raw = r\"E:\\GIT_REPOS\\Beetle_classifier\\Data\\raw\\\\\"\n",
    "data_dist = pd.read_csv(raw+\"Data_distribution.csv\", index_col=\"Species\")\n",
    "data_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027f282d-d751-4115-9493-f2b98a09a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WAIT FOR SIZE TO RERUN AND RERUN THIS\n",
    "# VIZUALISE THE DATA FOR NOW\n",
    "# LINE CHARTS ONE FOR EACH FOLD X AXIS IS THE DAT SIZE AND Y AXIS IS PERFORMANCE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf274ca-5f78-426f-a67e-2f07873b620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function only describes how much a singular value in al ist stands out.\n",
    "# if all values in the lsit are high or low this is 1\n",
    "# the smaller the proportiopn of number of disimilar vlaues are to other more similar values the lower this number\n",
    "# the larger the gap between the dissimilar numbers and the simialr number the smaller this number\n",
    "# only able to interpret probabilities or values between 0 and 1\n",
    "# this function outputs an estimate an inverse of the classification confidence based on the probabilities of all the classes.\n",
    "# the wedge threshold splits the data on a threshold with a magnitude of a positive int to force a ledge/peak in the data\n",
    "def unknown_prob_calc(probs, wedge_threshold=0.85, wedge_magnitude=1, wedge='strict'):\n",
    "    if wedge =='strict':\n",
    "        increase_var = (1/(wedge_magnitude))\n",
    "        decrease_var = (wedge_magnitude)\n",
    "    if wedge =='dynamic': # this allows pointsthat are furhter from the threshold ot be moved less and points clsoer to be moved more\n",
    "        increase_var = (1/(wedge_magnitude*((1-np.abs(probs-wedge_threshold)))))\n",
    "        decrease_var = (wedge_magnitude*((1-np.abs(probs-wedge_threshold))))\n",
    "    # else:\n",
    "    #     print(\"Error: use 'strict' (default) or 'dynamic' as options for the wedge parameter!\")\n",
    "    probs = np.where(probs>=wedge_threshold , probs**increase_var, probs)\n",
    "    probs = np.where(probs<=wedge_threshold , probs**decrease_var, probs)\n",
    "    diff_matrix = np.abs(probs[:, np.newaxis] - probs)\n",
    "    diff_matrix_sum = np.sum(diff_matrix)\n",
    "    probs_sum = np.sum(probs)\n",
    "    class_val = (diff_matrix_sum/probs_sum)\n",
    "    max_class_val = ((len(probs)-1)*2)\n",
    "    kown_prob = class_val/max_class_val\n",
    "    unknown_prob = 1-kown_prob\n",
    "    return(unknown_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "073cf25b-95b9-4ab2-9606-ebdc2815bf72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T00:56:58.976081Z",
     "iopub.status.busy": "2023-06-07T00:56:58.976081Z",
     "iopub.status.idle": "2023-06-07T00:56:58.990088Z",
     "shell.execute_reply": "2023-06-07T00:56:58.989582Z",
     "shell.execute_reply.started": "2023-06-07T00:56:58.976081Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold-1_image_number</th>\n",
       "      <th>fold-2_image_number</th>\n",
       "      <th>fold-3_image_number</th>\n",
       "      <th>fold-4_image_number</th>\n",
       "      <th>fold-5_image_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>200</td>\n",
       "      <td>184</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>313</td>\n",
       "      <td>411</td>\n",
       "      <td>407</td>\n",
       "      <td>363</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>497</td>\n",
       "      <td>583</td>\n",
       "      <td>562</td>\n",
       "      <td>563</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>718</td>\n",
       "      <td>803</td>\n",
       "      <td>799</td>\n",
       "      <td>800</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>890</td>\n",
       "      <td>964</td>\n",
       "      <td>983</td>\n",
       "      <td>1001</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1072</td>\n",
       "      <td>1146</td>\n",
       "      <td>1183</td>\n",
       "      <td>1222</td>\n",
       "      <td>1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1247</td>\n",
       "      <td>1321</td>\n",
       "      <td>1358</td>\n",
       "      <td>1361</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1408</td>\n",
       "      <td>1521</td>\n",
       "      <td>1530</td>\n",
       "      <td>1516</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1615</td>\n",
       "      <td>1740</td>\n",
       "      <td>1751</td>\n",
       "      <td>1698</td>\n",
       "      <td>1742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1791</td>\n",
       "      <td>1916</td>\n",
       "      <td>1927</td>\n",
       "      <td>1917</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1970</td>\n",
       "      <td>2132</td>\n",
       "      <td>2106</td>\n",
       "      <td>2127</td>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2170</td>\n",
       "      <td>2339</td>\n",
       "      <td>2325</td>\n",
       "      <td>2288</td>\n",
       "      <td>2285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2386</td>\n",
       "      <td>2494</td>\n",
       "      <td>2522</td>\n",
       "      <td>2485</td>\n",
       "      <td>2482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2596</td>\n",
       "      <td>2704</td>\n",
       "      <td>2661</td>\n",
       "      <td>2685</td>\n",
       "      <td>2682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2797</td>\n",
       "      <td>2905</td>\n",
       "      <td>2862</td>\n",
       "      <td>2859</td>\n",
       "      <td>2856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2969</td>\n",
       "      <td>3077</td>\n",
       "      <td>3082</td>\n",
       "      <td>3031</td>\n",
       "      <td>3076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3125</td>\n",
       "      <td>3274</td>\n",
       "      <td>3238</td>\n",
       "      <td>3251</td>\n",
       "      <td>3313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3280</td>\n",
       "      <td>3458</td>\n",
       "      <td>3454</td>\n",
       "      <td>3407</td>\n",
       "      <td>3469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3280</td>\n",
       "      <td>3458</td>\n",
       "      <td>3454</td>\n",
       "      <td>3579</td>\n",
       "      <td>3641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fold-1_image_number  fold-2_image_number  fold-3_image_number  \\\n",
       "0                   174                  174                  200   \n",
       "1                   313                  411                  407   \n",
       "2                   497                  583                  562   \n",
       "3                   718                  803                  799   \n",
       "4                   890                  964                  983   \n",
       "5                  1072                 1146                 1183   \n",
       "6                  1247                 1321                 1358   \n",
       "7                  1408                 1521                 1530   \n",
       "8                  1615                 1740                 1751   \n",
       "9                  1791                 1916                 1927   \n",
       "10                 1970                 2132                 2106   \n",
       "11                 2170                 2339                 2325   \n",
       "12                 2386                 2494                 2522   \n",
       "13                 2596                 2704                 2661   \n",
       "14                 2797                 2905                 2862   \n",
       "15                 2969                 3077                 3082   \n",
       "16                 3125                 3274                 3238   \n",
       "17                 3280                 3458                 3454   \n",
       "18                 3280                 3458                 3454   \n",
       "\n",
       "    fold-4_image_number  fold-5_image_number  \n",
       "0                   184                  221  \n",
       "1                   363                  400  \n",
       "2                   563                  600  \n",
       "3                   800                  810  \n",
       "4                  1001                  986  \n",
       "5                  1222                 1205  \n",
       "6                  1361                 1344  \n",
       "7                  1516                 1560  \n",
       "8                  1698                 1742  \n",
       "9                  1917                 1949  \n",
       "10                 2127                 2124  \n",
       "11                 2288                 2285  \n",
       "12                 2485                 2482  \n",
       "13                 2685                 2682  \n",
       "14                 2859                 2856  \n",
       "15                 3031                 3076  \n",
       "16                 3251                 3313  \n",
       "17                 3407                 3469  \n",
       "18                 3579                 3641  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_size_df = pd.read_csv(r\"E:\\GIT_REPOS\\Beetle_classifier\\Data\\raw\\Size\\csv\\data_size_results.csv\")\n",
    "data_size_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d54452d-b5f0-4cf7-8612-79ad42ad2373",
   "metadata": {},
   "source": [
    "# Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3feb3e49-4309-463f-9a47-6c66637cebef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T00:56:58.993082Z",
     "iopub.status.busy": "2023-06-07T00:56:58.992583Z",
     "iopub.status.idle": "2023-06-07T00:57:07.606734Z",
     "shell.execute_reply": "2023-06-07T00:57:07.606236Z",
     "shell.execute_reply.started": "2023-06-07T00:56:58.993082Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_dir = r\"E:\\GIT_REPOS\\Beetle_classifier\\Data\\raw\\Size\\csv\\valid\\\\\"\n",
    "folds = 5\n",
    "size_num = 19\n",
    "\n",
    "# get all different sized results from data\n",
    "valid_dict = {}\n",
    "for fold in range(1,folds+1):\n",
    "    size_results_df = pd.DataFrame()\n",
    "    data_size_summary_df = pd.DataFrame()\n",
    "    data_size_summary_df['valid'] = data_dist[\"valid_\"+str(fold)]\n",
    "    for size in range(1,size_num+1):\n",
    "        truth_df = pd.read_csv(valid_dir+str(size)+\"_Validation_prediction_probabilities_fold-\"+str(fold)+\".csv\").drop('Unnamed: 0', axis=1)\n",
    "        # calculate the max class\n",
    "        truth_df['pred'] = truth_df.idxmax(axis=1)\n",
    "\n",
    "        # add truth value\n",
    "        valid_series = data_dist[\"valid_\"+str(fold)]\n",
    "        truth_lst = []\n",
    "        for spcs, count in valid_series.to_dict().items():\n",
    "            truth_lst = truth_lst + list(np.repeat(spcs, count))\n",
    "        truth_df['truth'] = truth_lst\n",
    "\n",
    "        # get truth and pred valeus for all sizes\n",
    "        size_results_df['truth_'+str(size)] = truth_df['truth']\n",
    "        size_results_df['pred_'+str(size)] = truth_df['pred']\n",
    "        \n",
    "        \n",
    "        # get the training data size df\n",
    "        train_series = data_dist[\"train_\"+str(fold)].copy()\n",
    "        train_series['Coccotypes_dactyliperda']=data_size_df[\"fold-\"+str(fold)+\"_image_number\"].loc[size-1]\n",
    "        data_size_summary_df['train_'+str(size)] = train_series\n",
    "    \n",
    "    # save each dataframe as a csv\n",
    "    data_size_summary_df.to_csv(\"valid_data_size_summary_fold_\"+str(fold)+\".csv\")\n",
    "    size_results_df.to_csv(\"valid_size_results_fold_\"+str(fold)+\".csv\")\n",
    "    \n",
    "    # save all data to dictionary\n",
    "    valid_dict[\"fold_\"+str(fold)] = [data_size_summary_df, size_results_df]\n",
    "    \n",
    "# save dictionary to disk\n",
    "with open('valid_dict_size.pkl', 'wb') as f:\n",
    "    pickle.dump(valid_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632622fe-de95-4011-8d19-32cebf17af40",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "207b563d-a75f-4d09-9436-088fc5492c06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T00:57:07.608235Z",
     "iopub.status.busy": "2023-06-07T00:57:07.607735Z",
     "iopub.status.idle": "2023-06-07T00:57:13.389235Z",
     "shell.execute_reply": "2023-06-07T00:57:13.387733Z",
     "shell.execute_reply.started": "2023-06-07T00:57:07.608235Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dir = r\"E:\\GIT_REPOS\\Beetle_classifier\\Data\\raw\\Size\\csv\\test\\\\\"\n",
    "folds = 5\n",
    "size_num = 19\n",
    "\n",
    "# get all different sized results from data\n",
    "test_dict = {}\n",
    "for fold in range(1,folds+1):\n",
    "    size_results_df = pd.DataFrame()\n",
    "    data_size_summary_df = pd.DataFrame()\n",
    "    data_size_summary_df['test'] = data_dist[\"test\"]\n",
    "    for size in range(1,size_num+1):\n",
    "        truth_df = pd.read_csv(test_dir+str(size)+\"_Testing_prediction_probabilities_fold-\"+str(fold)+\".csv\").drop('Unnamed: 0', axis=1)\n",
    "        # calculate the max class\n",
    "        truth_df['pred'] = truth_df.idxmax(axis=1)\n",
    "\n",
    "        # add truth value\n",
    "        test_series = data_dist[\"test\"]\n",
    "        truth_lst = []\n",
    "        for spcs, count in test_series.to_dict().items():\n",
    "            truth_lst = truth_lst + list(np.repeat(spcs, count))\n",
    "        truth_df['truth'] = truth_lst\n",
    "\n",
    "        # get truth and pred valeus for all sizes\n",
    "        size_results_df['truth_'+str(size)] = truth_df['truth']\n",
    "        size_results_df['pred_'+str(size)] = truth_df['pred']\n",
    "        \n",
    "        \n",
    "        # get the training data size df\n",
    "        train_series = data_dist[\"train_\"+str(fold)].copy()\n",
    "        train_series['Coccotypes_dactyliperda']=data_size_df[\"fold-\"+str(fold)+\"_image_number\"].loc[size-1]\n",
    "        data_size_summary_df['train_'+str(size)] = train_series\n",
    "    \n",
    "    # save each dataframe as a csv\n",
    "    data_size_summary_df.to_csv(\"test_data_size_summary_fold_\"+str(fold)+\".csv\")\n",
    "    size_results_df.to_csv(\"test_size_results_fold_\"+str(fold)+\".csv\")\n",
    "    \n",
    "    # save all data to dictionary\n",
    "    test_dict[\"fold_\"+str(fold)] = [data_size_summary_df, size_results_df]\n",
    "    \n",
    "# save dictionary to disk\n",
    "with open('test_dict_size.pkl', 'wb') as f:\n",
    "    pickle.dump(test_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
