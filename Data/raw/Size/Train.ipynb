{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c403f8d-3cfd-48f5-8a4a-500a03fff3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import wandb\n",
    "import fastai\n",
    "import dill\n",
    "import re\n",
    "import random\n",
    "import PIL\n",
    "import numpy as np\n",
    "from fastai.vision.augment import cutout_gaussian\n",
    "from fastai.callback.wandb import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.core import *\n",
    "from fastai.text.core import RegexLabeller\n",
    "from fastai.vision.utils import get_image_files\n",
    "from fastai.data.block import DataBlock\n",
    "from fastai.data.core import *\n",
    "from fastai.tabular.all import *\n",
    "from fastcore.foundation import L\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import notebook_login, push_to_hub_fastai, from_pretrained_fastai\n",
    "from torchvision.transforms import GaussianBlur\n",
    "# os.environ['WANDB_WATCH'] = 'false'\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'Train.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a2baae5-bf1c-4f7a-bae0-98bb038d313f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = SimpleNamespace(\n",
    "    batch_size=64,  #16, #256,\n",
    "    epochs=5,\n",
    "    lr=3e-3,\n",
    "    img_size=224, # 224, 256 for small model on huggingface\n",
    "    seed=42,\n",
    "    pretrained=True,\n",
    "    top_k_losses=5,\n",
    "    model_name=\"maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k\",# \"maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k\",# maxvit_nano_rw_256.sw_in1k for HF spaces\n",
    "    wandb_project=\"Beetle_classifier\", \n",
    "    wandb_group=\"ambrosia_symbiosis\",\n",
    "    job_type=\"training_cv_5fold_ooc\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4e633d2-718e-4940-9e6e-94ea772337e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a custom transform for Gaussian blur\n",
    "def gaussian_blur(x, p=0.5, kernel_size_min=3, kernel_size_max=20, sigma_min=0.1, sigma_max=3):\n",
    "    if x.ndim == 4:\n",
    "        for i in range(x.shape[0]):\n",
    "            if random.random() < p:\n",
    "                kernel_size = random.randrange(kernel_size_min, kernel_size_max + 1, 2)\n",
    "                sigma = random.uniform(sigma_min, sigma_max)\n",
    "                x[i] = GaussianBlur(kernel_size=kernel_size, sigma=sigma)(x[i])\n",
    "    return x\n",
    "\n",
    "# def custom_parent_label(fname, known_categories):\n",
    "#     category = parent_label(fname)\n",
    "#     if category not in known_categories:\n",
    "#         return \"Unknown\"\n",
    "#     else:\n",
    "#         return category\n",
    "\n",
    "# def get_categories(fnames):\n",
    "#     categories = []\n",
    "#     for fname in fnames:\n",
    "#         category = parent_label(fname)\n",
    "#         if category not in categories:\n",
    "#             categories.append(category)\n",
    "#     return categories\n",
    "\n",
    "def get_image_files_exclude(path, folders=('train','valid'), exclude_folder=None):\n",
    "    files = get_image_files(path=path, recurse=True, folders=folders)\n",
    "    if exclude_folder:\n",
    "            files = L([f for f in files if (exclude_folder not in str(f))])\n",
    "    return files\n",
    "    \n",
    "\n",
    "def get_images(dataset_path, batch_size, img_size, seed, subfolders=('train','valid'), exclude_folder=None):\n",
    "    \"The beetles dataset\"\n",
    "    files = get_image_files_exclude(path=dataset_path, folders=subfolders, exclude_folder=exclude_folder)\n",
    "    # files = get_image_files(path=dataset_path, recurse=True, folders=subfolders)\n",
    "    transforms = aug_transforms(    # transformatiosn that are only applied ot training and not inference\n",
    "                           batch=False,\n",
    "                           pad_mode='zeros',\n",
    "                           size=img_size,\n",
    "                           p_affine=0.8,\n",
    "                           p_lighting=0.8,\n",
    "                           max_rotate=360.0,\n",
    "                           mult=1.0, \n",
    "                           do_flip=True, \n",
    "                           flip_vert=False,\n",
    "                           min_zoom=1.0,\n",
    "                           max_zoom=1.1, \n",
    "                           max_lighting=0.75,\n",
    "                           max_warp=0.2, \n",
    "                           mode='bilinear', \n",
    "                           align_corners=True,\n",
    "                           min_scale=1.0,\n",
    "                           xtra_tfms=[RandomErasing(p=0.8, max_count=5, sh=0.25)]) # this adds random erasing to entire batches\n",
    "    transforms.append(partial(gaussian_blur, p=0.8))\n",
    "    transforms.append(Normalize.from_stats(*imagenet_stats))\n",
    "    # categories = get_categories(files)\n",
    "    dblock = DataBlock(blocks = (ImageBlock, CategoryBlock),#(vocab=categories+[\"Unknown\"])),\n",
    "                       get_items = partial(get_image_files_exclude, \n",
    "                                           folders=subfolders, \n",
    "                                           exclude_folder=exclude_folder),\n",
    "                       # get_items = get_image_files,\n",
    "                       splitter = GrandparentSplitter(train_name=subfolders[0], valid_name=subfolders[1]),\n",
    "                       get_y = parent_label, # partial(custom_parent_label, known_categories=categories),\n",
    "                       item_tfms = Resize(img_size, ResizeMethod.Pad, pad_mode='zeros'), # resize trasnformation is applied during inference too                                    \n",
    "                       batch_tfms = transforms)\n",
    "    dls = dblock.dataloaders(dataset_path, bs = batch_size, num_workers=4)\n",
    "    return dls\n",
    "\n",
    "def train(config, dataset_path, subfolders=('train','valid'), exclude_folder=None):\n",
    "    \"Train the model using the supplied config\"\n",
    "    dls = get_images(dataset_path=dataset_path, \n",
    "                     batch_size=config.batch_size, \n",
    "                     img_size=config.img_size, \n",
    "                     seed=config.seed, \n",
    "                     subfolders=subfolders, \n",
    "                     exclude_folder=exclude_folder)\n",
    "    labels = np.array([re.split(r'/|\\\\', str(x))[-2] for x in dls.items])\n",
    "    classes = np.unique(labels)# for label in labels if label != \"Unknown\"])\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=labels)\n",
    "    class_weights = {c: w for c, w in zip(classes, weights)}\n",
    "    weights = tensor([class_weights[c] for c in dls.vocab]).to(dls.device)\n",
    "    # wandb.init(project=config.wandb_project, group=config.wandb_group, job_type=config.job_type, config=config) # it is a good idea to keep these functions out of the training function due to some exporting issues\n",
    "    cbs = [MixedPrecision(), ShowGraphCallback(), SaveModelCallback(), WandbCallback(log='gradients')] # (all, parameters, gradients or None) parameters and all does nto work currently wandb needs to be updated\n",
    "    learn = vision_learner(dls, \n",
    "                           config.model_name, \n",
    "                           loss_func=LabelSmoothingCrossEntropy(weight=weights), # this fucntion is used for class imbalance it is a regularization technique # LabelSmoothingCrossEntropyFlat is used for multi dimensional data\n",
    "                           metrics=[error_rate, \n",
    "                                    accuracy, \n",
    "                                    top_k_accuracy], \n",
    "                           cbs=cbs, \n",
    "                           pretrained=config.pretrained)\n",
    "    learn.fine_tune(config.epochs, base_lr=config.lr)\n",
    "    interp = ClassificationInterpretation.from_learner(learn)\n",
    "    interp.plot_confusion_matrix()\n",
    "    interp.plot_top_losses(config.top_k_losses, nrows=config.top_k_losses)\n",
    "    # wandb.finish() # it is a good idea to keep these functions out of the training function due to some exporting issues\n",
    "    return learn\n",
    "\n",
    "# this function only describes how much a singular value in al ist stands out.\n",
    "# if all values in the lsit are high or low this is 1\n",
    "# the smaller the proportiopn of number of disimilar vlaues are to other more similar values the lower this number\n",
    "# the larger the gap between the dissimilar numbers and the simialr number the smaller this number\n",
    "# only able to interpret probabilities or values between 0 and 1\n",
    "# this function outputs an estimate an inverse of the classification confidence based on the probabilities of all the classes.\n",
    "# the wedge threshold splits the data on a threshold with a magnitude of a positive int to force a ledge/peak in the data\n",
    "def unknown_prob_calc(probs, wedge_threshold, wedge_magnitude=1, wedge='strict'):\n",
    "    if wedge =='strict':\n",
    "        increase_var = (1/(wedge_magnitude))\n",
    "        decrease_var = (wedge_magnitude)\n",
    "    if wedge =='dynamic': # this allows pointsthat are furhter from the threshold ot be moved less and points clsoer to be moved more\n",
    "        increase_var = (1/(wedge_magnitude*((1-np.abs(probs-wedge_threshold)))))\n",
    "        decrease_var = (wedge_magnitude*((1-np.abs(probs-wedge_threshold))))\n",
    "    # else:\n",
    "    #     print(\"Error: use 'strict' (default) or 'dynamic' as options for the wedge parameter!\")\n",
    "    probs = np.where(probs>=wedge_threshold , probs**increase_var, probs)\n",
    "    probs = np.where(probs<=wedge_threshold , probs**decrease_var, probs)\n",
    "    diff_matrix = np.abs(probs[:, np.newaxis] - probs)\n",
    "    diff_matrix_sum = np.sum(diff_matrix)\n",
    "    probs_sum = np.sum(probs)\n",
    "    class_val = (diff_matrix_sum/probs_sum)\n",
    "    max_class_val = ((len(probs)-1)*2)\n",
    "    kown_prob = class_val/max_class_val\n",
    "    unknown_prob = 1-kown_prob\n",
    "    return(unknown_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483b892f-2dcc-41eb-b738-6bd176e5fd98",
   "metadata": {},
   "source": [
    "# Out of class evaluation with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1503afc-2ee6-46b9-8725-e0acb9007874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# species_lst = [\n",
    "#     \"Coccotypes_dactyliperda\",\n",
    "#     \"Hylesinus_varius\",\n",
    "#     \"Monarthrum_fasciatum\",\n",
    "#     \"Phloeosinus_dentatus\",\n",
    "#     \"Pityophthorus_juglandis\",\n",
    "#     \"Platypus_cylindrus\",\n",
    "#     \"Pycnarthrum_hispidium\",\n",
    "#     \"Scolotodes_schwarzi\",\n",
    "#     \"Xyleborinus_saxesenii\",\n",
    "#     \"Xyleborus_affinis\",\n",
    "#     \"Xylosandrus_compactus\",\n",
    "#     \"Xylosandrus_crassiusculus\",\n",
    "#     None\n",
    "# ]\n",
    "\n",
    "# loop_lst = []\n",
    "# for species in species_lst:\n",
    "#     test_file_loop_name = str(species)+\"_Testing_5-fold_CV_classification_results.csv\"\n",
    "#     for i in range(1, 6):\n",
    "#         eval_file_loop_name = str(species)+\"_Unknown_Testing_prediction_probabilities_fold-\"+str(i)+\".csv\"\n",
    "#         loop_dict = {\"species\": species ,\n",
    "#                     \"test_file_loop_name\": test_file_loop_name,\n",
    "#                     \"fold\": i,\n",
    "#                     \"eval_file_loop_name\": eval_file_loop_name,}\n",
    "#         loop_lst.append(loop_dict)\n",
    "        \n",
    "        \n",
    "# loop_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10684e6d-c57a-4973-8af2-3d67ec604608",
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_lst = [\n",
    "    {'species': 'Coccotypes_dactyliperda',\n",
    "     'test_file_loop_name': 'Coccotypes_dactyliperda_Testing_5-fold_CV_classification_results.csv',\n",
    "      'fold': 1,\n",
    "      'eval_file_loop_name': 'Coccotypes_dactyliperda_Unknown_Testing_prediction_probabilities_fold-1.csv'},\n",
    " {'species': 'Coccotypes_dactyliperda',\n",
    "  'test_file_loop_name': 'Coccotypes_dactyliperda_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 2,\n",
    "  'eval_file_loop_name': 'Coccotypes_dactyliperda_Unknown_Testing_prediction_probabilities_fold-2.csv'},\n",
    " {'species': 'Coccotypes_dactyliperda',\n",
    "  'test_file_loop_name': 'Coccotypes_dactyliperda_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 3,\n",
    "  'eval_file_loop_name': 'Coccotypes_dactyliperda_Unknown_Testing_prediction_probabilities_fold-3.csv'},\n",
    " {'species': 'Coccotypes_dactyliperda',\n",
    "  'test_file_loop_name': 'Coccotypes_dactyliperda_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 4,\n",
    "  'eval_file_loop_name': 'Coccotypes_dactyliperda_Unknown_Testing_prediction_probabilities_fold-4.csv'},\n",
    " {'species': 'Coccotypes_dactyliperda',\n",
    "  'test_file_loop_name': 'Coccotypes_dactyliperda_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 5,\n",
    "  'eval_file_loop_name': 'Coccotypes_dactyliperda_Unknown_Testing_prediction_probabilities_fold-5.csv'},\n",
    " {'species': 'Hylesinus_varius',\n",
    "  'test_file_loop_name': 'Hylesinus_varius_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 1,\n",
    "  'eval_file_loop_name': 'Hylesinus_varius_Unknown_Testing_prediction_probabilities_fold-1.csv'},\n",
    " {'species': 'Hylesinus_varius',\n",
    "  'test_file_loop_name': 'Hylesinus_varius_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 2,\n",
    "  'eval_file_loop_name': 'Hylesinus_varius_Unknown_Testing_prediction_probabilities_fold-2.csv'},\n",
    " {'species': 'Hylesinus_varius',\n",
    "  'test_file_loop_name': 'Hylesinus_varius_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 3,\n",
    "  'eval_file_loop_name': 'Hylesinus_varius_Unknown_Testing_prediction_probabilities_fold-3.csv'},\n",
    " {'species': 'Hylesinus_varius',\n",
    "  'test_file_loop_name': 'Hylesinus_varius_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 4,\n",
    "  'eval_file_loop_name': 'Hylesinus_varius_Unknown_Testing_prediction_probabilities_fold-4.csv'},\n",
    " {'species': 'Hylesinus_varius',\n",
    "  'test_file_loop_name': 'Hylesinus_varius_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 5,\n",
    "  'eval_file_loop_name': 'Hylesinus_varius_Unknown_Testing_prediction_probabilities_fold-5.csv'},\n",
    " {'species': 'Monarthrum_fasciatum',\n",
    "  'test_file_loop_name': 'Monarthrum_fasciatum_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 1,\n",
    "  'eval_file_loop_name': 'Monarthrum_fasciatum_Unknown_Testing_prediction_probabilities_fold-1.csv'},\n",
    " {'species': 'Monarthrum_fasciatum',\n",
    "  'test_file_loop_name': 'Monarthrum_fasciatum_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 2,\n",
    "  'eval_file_loop_name': 'Monarthrum_fasciatum_Unknown_Testing_prediction_probabilities_fold-2.csv'},\n",
    " {'species': 'Monarthrum_fasciatum',\n",
    "  'test_file_loop_name': 'Monarthrum_fasciatum_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 3,\n",
    "  'eval_file_loop_name': 'Monarthrum_fasciatum_Unknown_Testing_prediction_probabilities_fold-3.csv'},\n",
    " {'species': 'Monarthrum_fasciatum',\n",
    "  'test_file_loop_name': 'Monarthrum_fasciatum_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 4,\n",
    "  'eval_file_loop_name': 'Monarthrum_fasciatum_Unknown_Testing_prediction_probabilities_fold-4.csv'},\n",
    " {'species': 'Monarthrum_fasciatum',\n",
    "  'test_file_loop_name': 'Monarthrum_fasciatum_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 5,\n",
    "  'eval_file_loop_name': 'Monarthrum_fasciatum_Unknown_Testing_prediction_probabilities_fold-5.csv'},\n",
    " {'species': 'Phloeosinus_dentatus',\n",
    "  'test_file_loop_name': 'Phloeosinus_dentatus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 1,\n",
    "  'eval_file_loop_name': 'Phloeosinus_dentatus_Unknown_Testing_prediction_probabilities_fold-1.csv'},\n",
    " {'species': 'Phloeosinus_dentatus',\n",
    "  'test_file_loop_name': 'Phloeosinus_dentatus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 2,\n",
    "  'eval_file_loop_name': 'Phloeosinus_dentatus_Unknown_Testing_prediction_probabilities_fold-2.csv'},\n",
    " {'species': 'Phloeosinus_dentatus',\n",
    "  'test_file_loop_name': 'Phloeosinus_dentatus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 3,\n",
    "  'eval_file_loop_name': 'Phloeosinus_dentatus_Unknown_Testing_prediction_probabilities_fold-3.csv'},\n",
    " {'species': 'Phloeosinus_dentatus',\n",
    "  'test_file_loop_name': 'Phloeosinus_dentatus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 4,\n",
    "  'eval_file_loop_name': 'Phloeosinus_dentatus_Unknown_Testing_prediction_probabilities_fold-4.csv'},\n",
    " {'species': 'Phloeosinus_dentatus',\n",
    "  'test_file_loop_name': 'Phloeosinus_dentatus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 5,\n",
    "  'eval_file_loop_name': 'Phloeosinus_dentatus_Unknown_Testing_prediction_probabilities_fold-5.csv'},\n",
    " {'species': 'Pityophthorus_juglandis',\n",
    "  'test_file_loop_name': 'Pityophthorus_juglandis_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 1,\n",
    "  'eval_file_loop_name': 'Pityophthorus_juglandis_Unknown_Testing_prediction_probabilities_fold-1.csv'},\n",
    " {'species': 'Pityophthorus_juglandis',\n",
    "  'test_file_loop_name': 'Pityophthorus_juglandis_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 2,\n",
    "  'eval_file_loop_name': 'Pityophthorus_juglandis_Unknown_Testing_prediction_probabilities_fold-2.csv'},\n",
    " {'species': 'Pityophthorus_juglandis',\n",
    "  'test_file_loop_name': 'Pityophthorus_juglandis_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 3,\n",
    "  'eval_file_loop_name': 'Pityophthorus_juglandis_Unknown_Testing_prediction_probabilities_fold-3.csv'},\n",
    " {'species': 'Pityophthorus_juglandis',\n",
    "  'test_file_loop_name': 'Pityophthorus_juglandis_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 4,\n",
    "  'eval_file_loop_name': 'Pityophthorus_juglandis_Unknown_Testing_prediction_probabilities_fold-4.csv'},\n",
    " {'species': 'Pityophthorus_juglandis',\n",
    "  'test_file_loop_name': 'Pityophthorus_juglandis_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 5,\n",
    "  'eval_file_loop_name': 'Pityophthorus_juglandis_Unknown_Testing_prediction_probabilities_fold-5.csv'},\n",
    " {'species': 'Platypus_cylindrus',\n",
    "  'test_file_loop_name': 'Platypus_cylindrus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 1,\n",
    "  'eval_file_loop_name': 'Platypus_cylindrus_Unknown_Testing_prediction_probabilities_fold-1.csv'},\n",
    " {'species': 'Platypus_cylindrus',\n",
    "  'test_file_loop_name': 'Platypus_cylindrus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 2,\n",
    "  'eval_file_loop_name': 'Platypus_cylindrus_Unknown_Testing_prediction_probabilities_fold-2.csv'},\n",
    " {'species': 'Platypus_cylindrus',\n",
    "  'test_file_loop_name': 'Platypus_cylindrus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 3,\n",
    "  'eval_file_loop_name': 'Platypus_cylindrus_Unknown_Testing_prediction_probabilities_fold-3.csv'},\n",
    " {'species': 'Platypus_cylindrus',\n",
    "  'test_file_loop_name': 'Platypus_cylindrus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 4,\n",
    "  'eval_file_loop_name': 'Platypus_cylindrus_Unknown_Testing_prediction_probabilities_fold-4.csv'},\n",
    " {'species': 'Platypus_cylindrus',\n",
    "  'test_file_loop_name': 'Platypus_cylindrus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 5,\n",
    "  'eval_file_loop_name': 'Platypus_cylindrus_Unknown_Testing_prediction_probabilities_fold-5.csv'},\n",
    " {'species': 'Pycnarthrum_hispidium',\n",
    "  'test_file_loop_name': 'Pycnarthrum_hispidium_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 1,\n",
    "  'eval_file_loop_name': 'Pycnarthrum_hispidium_Unknown_Testing_prediction_probabilities_fold-1.csv'},\n",
    " {'species': 'Pycnarthrum_hispidium',\n",
    "  'test_file_loop_name': 'Pycnarthrum_hispidium_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 2,\n",
    "  'eval_file_loop_name': 'Pycnarthrum_hispidium_Unknown_Testing_prediction_probabilities_fold-2.csv'},\n",
    " {'species': 'Pycnarthrum_hispidium',\n",
    "  'test_file_loop_name': 'Pycnarthrum_hispidium_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 3,\n",
    "  'eval_file_loop_name': 'Pycnarthrum_hispidium_Unknown_Testing_prediction_probabilities_fold-3.csv'},\n",
    " {'species': 'Pycnarthrum_hispidium',\n",
    "  'test_file_loop_name': 'Pycnarthrum_hispidium_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 4,\n",
    "  'eval_file_loop_name': 'Pycnarthrum_hispidium_Unknown_Testing_prediction_probabilities_fold-4.csv'},\n",
    " {'species': 'Pycnarthrum_hispidium',\n",
    "  'test_file_loop_name': 'Pycnarthrum_hispidium_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 5,\n",
    "  'eval_file_loop_name': 'Pycnarthrum_hispidium_Unknown_Testing_prediction_probabilities_fold-5.csv'},\n",
    " {'species': 'Scolotodes_schwarzi',\n",
    "  'test_file_loop_name': 'Scolotodes_schwarzi_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 1,\n",
    "  'eval_file_loop_name': 'Scolotodes_schwarzi_Unknown_Testing_prediction_probabilities_fold-1.csv'},\n",
    " {'species': 'Scolotodes_schwarzi',\n",
    "  'test_file_loop_name': 'Scolotodes_schwarzi_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 2,\n",
    "  'eval_file_loop_name': 'Scolotodes_schwarzi_Unknown_Testing_prediction_probabilities_fold-2.csv'},\n",
    " {'species': 'Scolotodes_schwarzi',\n",
    "  'test_file_loop_name': 'Scolotodes_schwarzi_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 3,\n",
    "  'eval_file_loop_name': 'Scolotodes_schwarzi_Unknown_Testing_prediction_probabilities_fold-3.csv'},\n",
    " {'species': 'Scolotodes_schwarzi',\n",
    "  'test_file_loop_name': 'Scolotodes_schwarzi_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 4,\n",
    "  'eval_file_loop_name': 'Scolotodes_schwarzi_Unknown_Testing_prediction_probabilities_fold-4.csv'},\n",
    " {'species': 'Scolotodes_schwarzi',\n",
    "  'test_file_loop_name': 'Scolotodes_schwarzi_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 5,\n",
    "  'eval_file_loop_name': 'Scolotodes_schwarzi_Unknown_Testing_prediction_probabilities_fold-5.csv'},\n",
    " {'species': 'Xyleborinus_saxesenii',\n",
    "  'test_file_loop_name': 'Xyleborinus_saxesenii_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 1,\n",
    "  'eval_file_loop_name': 'Xyleborinus_saxesenii_Unknown_Testing_prediction_probabilities_fold-1.csv'},\n",
    " {'species': 'Xyleborinus_saxesenii',\n",
    "  'test_file_loop_name': 'Xyleborinus_saxesenii_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 2,\n",
    "  'eval_file_loop_name': 'Xyleborinus_saxesenii_Unknown_Testing_prediction_probabilities_fold-2.csv'},\n",
    " {'species': 'Xyleborinus_saxesenii',\n",
    "  'test_file_loop_name': 'Xyleborinus_saxesenii_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 3,\n",
    "  'eval_file_loop_name': 'Xyleborinus_saxesenii_Unknown_Testing_prediction_probabilities_fold-3.csv'},\n",
    " {'species': 'Xyleborinus_saxesenii',\n",
    "  'test_file_loop_name': 'Xyleborinus_saxesenii_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 4,\n",
    "  'eval_file_loop_name': 'Xyleborinus_saxesenii_Unknown_Testing_prediction_probabilities_fold-4.csv'},\n",
    " {'species': 'Xyleborinus_saxesenii',\n",
    "  'test_file_loop_name': 'Xyleborinus_saxesenii_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 5,\n",
    "  'eval_file_loop_name': 'Xyleborinus_saxesenii_Unknown_Testing_prediction_probabilities_fold-5.csv'},\n",
    " {'species': 'Xyleborus_affinis',\n",
    "  'test_file_loop_name': 'Xyleborus_affinis_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 1,\n",
    "  'eval_file_loop_name': 'Xyleborus_affinis_Unknown_Testing_prediction_probabilities_fold-1.csv'},\n",
    " {'species': 'Xyleborus_affinis',\n",
    "  'test_file_loop_name': 'Xyleborus_affinis_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 2,\n",
    "  'eval_file_loop_name': 'Xyleborus_affinis_Unknown_Testing_prediction_probabilities_fold-2.csv'},\n",
    " {'species': 'Xyleborus_affinis',\n",
    "  'test_file_loop_name': 'Xyleborus_affinis_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 3,\n",
    "  'eval_file_loop_name': 'Xyleborus_affinis_Unknown_Testing_prediction_probabilities_fold-3.csv'},\n",
    " {'species': 'Xyleborus_affinis',\n",
    "  'test_file_loop_name': 'Xyleborus_affinis_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 4,\n",
    "  'eval_file_loop_name': 'Xyleborus_affinis_Unknown_Testing_prediction_probabilities_fold-4.csv'},\n",
    " {'species': 'Xyleborus_affinis',\n",
    "  'test_file_loop_name': 'Xyleborus_affinis_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 5,\n",
    "  'eval_file_loop_name': 'Xyleborus_affinis_Unknown_Testing_prediction_probabilities_fold-5.csv'},\n",
    " {'species': 'Xylosandrus_compactus',\n",
    "  'test_file_loop_name': 'Xylosandrus_compactus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 1,\n",
    "  'eval_file_loop_name': 'Xylosandrus_compactus_Unknown_Testing_prediction_probabilities_fold-1.csv'},\n",
    " {'species': 'Xylosandrus_compactus',\n",
    "  'test_file_loop_name': 'Xylosandrus_compactus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 2,\n",
    "  'eval_file_loop_name': 'Xylosandrus_compactus_Unknown_Testing_prediction_probabilities_fold-2.csv'},\n",
    " {'species': 'Xylosandrus_compactus',\n",
    "  'test_file_loop_name': 'Xylosandrus_compactus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 3,\n",
    "  'eval_file_loop_name': 'Xylosandrus_compactus_Unknown_Testing_prediction_probabilities_fold-3.csv'},\n",
    " {'species': 'Xylosandrus_compactus',\n",
    "  'test_file_loop_name': 'Xylosandrus_compactus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 4,\n",
    "  'eval_file_loop_name': 'Xylosandrus_compactus_Unknown_Testing_prediction_probabilities_fold-4.csv'},\n",
    " {'species': 'Xylosandrus_compactus',\n",
    "  'test_file_loop_name': 'Xylosandrus_compactus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 5,\n",
    "  'eval_file_loop_name': 'Xylosandrus_compactus_Unknown_Testing_prediction_probabilities_fold-5.csv'},\n",
    " {'species': 'Xylosandrus_crassiusculus',\n",
    "  'test_file_loop_name': 'Xylosandrus_crassiusculus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 1,\n",
    "  'eval_file_loop_name': 'Xylosandrus_crassiusculus_Unknown_Testing_prediction_probabilities_fold-1.csv'},\n",
    " {'species': 'Xylosandrus_crassiusculus',\n",
    "  'test_file_loop_name': 'Xylosandrus_crassiusculus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 2,\n",
    "  'eval_file_loop_name': 'Xylosandrus_crassiusculus_Unknown_Testing_prediction_probabilities_fold-2.csv'},\n",
    " {'species': 'Xylosandrus_crassiusculus',\n",
    "  'test_file_loop_name': 'Xylosandrus_crassiusculus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 3,\n",
    "  'eval_file_loop_name': 'Xylosandrus_crassiusculus_Unknown_Testing_prediction_probabilities_fold-3.csv'},\n",
    " {'species': 'Xylosandrus_crassiusculus',\n",
    "  'test_file_loop_name': 'Xylosandrus_crassiusculus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 4,\n",
    "  'eval_file_loop_name': 'Xylosandrus_crassiusculus_Unknown_Testing_prediction_probabilities_fold-4.csv'},\n",
    " {'species': 'Xylosandrus_crassiusculus',\n",
    "  'test_file_loop_name': 'Xylosandrus_crassiusculus_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 5,\n",
    "  'eval_file_loop_name': 'Xylosandrus_crassiusculus_Unknown_Testing_prediction_probabilities_fold-5.csv'},\n",
    " {'species': None,\n",
    "  'test_file_loop_name': 'None_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 1,\n",
    "  'eval_file_loop_name': 'None_Unknown_Testing_prediction_probabilities_fold-1.csv'},\n",
    " {'species': None,\n",
    "  'test_file_loop_name': 'None_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 2,\n",
    "  'eval_file_loop_name': 'None_Unknown_Testing_prediction_probabilities_fold-2.csv'},\n",
    " {'species': None,\n",
    "  'test_file_loop_name': 'None_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 3,\n",
    "  'eval_file_loop_name': 'None_Unknown_Testing_prediction_probabilities_fold-3.csv'},\n",
    " {'species': None,\n",
    "  'test_file_loop_name': 'None_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 4,\n",
    "  'eval_file_loop_name': 'None_Unknown_Testing_prediction_probabilities_fold-4.csv'},\n",
    " {'species': None,\n",
    "  'test_file_loop_name': 'None_Testing_5-fold_CV_classification_results.csv',\n",
    "  'fold': 5,\n",
    "  'eval_file_loop_name': 'None_Unknown_Testing_prediction_probabilities_fold-5.csv'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19285693-9ea1-4c3c-9443-d1e97e4311cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristopher-marais\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/blue/hulcr/gmarais/Beetle_classifier/Train/wandb/run-20230512_174640-0n5c2l5t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/christopher-marais/Beetle_classifier/runs/0n5c2l5t' target=\"_blank\">peach-jazz-152</a></strong> to <a href='https://wandb.ai/christopher-marais/Beetle_classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/christopher-marais/Beetle_classifier' target=\"_blank\">https://wandb.ai/christopher-marais/Beetle_classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/christopher-marais/Beetle_classifier/runs/0n5c2l5t' target=\"_blank\">https://wandb.ai/christopher-marais/Beetle_classifier/runs/0n5c2l5t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>top_k_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/372 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# dataset_path = r\"F:\\Beetle_data\\kfold_images\\train_data\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mwandb_project, group\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mwandb_group, job_type\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mjob_type, config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[0;32m---> 21\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m              \u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m              \u001b[49m\u001b[43msubfolders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m             \u001b[49m\u001b[43mexclude_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspecies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# get predicstions and labels\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 93\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config, dataset_path, subfolders, exclude_folder)\u001b[0m\n\u001b[1;32m     84\u001b[0m cbs \u001b[38;5;241m=\u001b[39m [MixedPrecision(), ShowGraphCallback(), SaveModelCallback(), WandbCallback(log\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgradients\u001b[39m\u001b[38;5;124m'\u001b[39m)] \u001b[38;5;66;03m# (all, parameters, gradients or None) parameters and all does nto work currently wandb needs to be updated\u001b[39;00m\n\u001b[1;32m     85\u001b[0m learn \u001b[38;5;241m=\u001b[39m vision_learner(dls, \n\u001b[1;32m     86\u001b[0m                        config\u001b[38;5;241m.\u001b[39mmodel_name, \n\u001b[1;32m     87\u001b[0m                        loss_func\u001b[38;5;241m=\u001b[39mLabelSmoothingCrossEntropy(weight\u001b[38;5;241m=\u001b[39mweights), \u001b[38;5;66;03m# this fucntion is used for class imbalance it is a regularization technique # LabelSmoothingCrossEntropyFlat is used for multi dimensional data\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m                        cbs\u001b[38;5;241m=\u001b[39mcbs, \n\u001b[1;32m     92\u001b[0m                        pretrained\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretrained)\n\u001b[0;32m---> 93\u001b[0m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m interp \u001b[38;5;241m=\u001b[39m ClassificationInterpretation\u001b[38;5;241m.\u001b[39mfrom_learner(learn)\n\u001b[1;32m     95\u001b[0m interp\u001b[38;5;241m.\u001b[39mplot_confusion_matrix()\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/fastai/callback/schedule.py:165\u001b[0m, in \u001b[0;36mfine_tune\u001b[0;34m(self, epochs, base_lr, freeze_epochs, lr_mult, pct_start, div, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFine tune with `Learner.freeze` for `freeze_epochs`, then with `Learner.unfreeze` for `epochs`, using discriminative LR.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreeze()\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_one_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfreeze_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbase_lr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpct_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.99\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m base_lr \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munfreeze()\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/fastai/callback/schedule.py:119\u001b[0m, in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    116\u001b[0m lr_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([h[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mhypers])\n\u001b[1;32m    117\u001b[0m scheds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, lr_max\u001b[38;5;241m/\u001b[39mdiv, lr_max, lr_max\u001b[38;5;241m/\u001b[39mdiv_final),\n\u001b[1;32m    118\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmom\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, \u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoms \u001b[38;5;28;01mif\u001b[39;00m moms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m moms))}\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mParamScheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscheds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_opt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/fastai/learner.py:264\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mset_hypers(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch \u001b[38;5;241m=\u001b[39m n_epoch\n\u001b[0;32m--> 264\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelFitException\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_cleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/fastai/learner.py:253\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch):\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelEpochException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/fastai/learner.py:247\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/fastai/learner.py:239\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelTrainException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/fastai/learner.py:205\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_batches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl)\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/fastai/learner.py:235\u001b[0m, in \u001b[0;36mLearner.one_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    233\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_device(b)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(b)\n\u001b[0;32m--> 235\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_one_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelBatchException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/fastai/learner.py:216\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_one_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_pred\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myb):\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/fastai/vision/learner.py:177\u001b[0m, in \u001b[0;36mTimmBody.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_pool \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/timm/models/maxxvit.py:1256\u001b[0m, in \u001b[0;36mMaxxVit.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m-> 1256\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1257\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages(x)\n\u001b[1;32m   1258\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/timm/models/maxxvit.py:1099\u001b[0m, in \u001b[0;36mStem.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m   1098\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m-> 1099\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/timm/layers/norm_act.py:101\u001b[0m, in \u001b[0;36mBatchNormAct2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     94\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(x)\n\u001b[1;32m    113\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x)\n",
      "File \u001b[0;32m/blue/hulcr/gmarais/conda/envs/BC_310/lib/python3.10/site-packages/torch/nn/functional.py:2438\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2436\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2439\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2440\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(loop_lst)):\n",
    "    loop_dict = loop_lst[i]\n",
    "    species_lst = [loop_dict['species']]\n",
    "    fold_lst = [loop_dict['fold']]\n",
    "    if not os.path.isfile(loop_dict['test_file_loop_name']):\n",
    "        for species in species_lst:\n",
    "            # CV training\n",
    "            valid_targets = []\n",
    "            valid_preds = []\n",
    "            valid_class = []\n",
    "            test_targets = []\n",
    "            test_preds = []\n",
    "            test_class = []\n",
    "            if not os.path.isfile(loop_dict['eval_file_loop_name']):\n",
    "                for i in fold_lst:\n",
    "                    # Train Model\n",
    "                    print(\"Training: \", str(i))\n",
    "                    dataset_path = r\"/blue/hulcr/gmarais/Beetle_data/kfold_images/train_data\"\n",
    "                    # dataset_path = r\"F:\\Beetle_data\\kfold_images\\train_data\"\n",
    "                    wandb.init(project=config.wandb_project, group=config.wandb_group, job_type=config.job_type, config=config)\n",
    "                    learn = train(config=config, \n",
    "                                  dataset_path=dataset_path, \n",
    "                                  subfolders=('train_'+str(i),'valid_'+str(i)),\n",
    "                                 exclude_folder=species)\n",
    "                    wandb.finish()\n",
    "\n",
    "                    # get predicstions and labels\n",
    "                    print(\"Testing: \", str(i))\n",
    "                    learn.remove_cb(WandbCallback)\n",
    "                    # Get validation labels and predictions\n",
    "                    files = get_image_files_exclude(path=dataset_path, folders=('valid_'+str(i)), exclude_folder=species) # get files from directory\n",
    "                    test_dl = learn.dls.test_dl(files, with_labels=True) # load data as a dataloader\n",
    "                    preds, targets = learn.get_preds(dl=test_dl)\n",
    "                    valid_targets.append(targets.cpu().numpy())\n",
    "                    max_probs, max_classes = preds.max(dim=1)\n",
    "                    valid_class.append(max_classes.cpu().numpy())\n",
    "                    valid_preds.append(max_probs.cpu().numpy())\n",
    "                    pred_df = pd.DataFrame(preds.cpu().numpy(), columns=learn.dls.vocab)\n",
    "                    pred_df.to_csv(str(species)+\"_Validation_prediction_probabilities_fold-\"+str(i)+\".csv\")\n",
    "                    # unknown validation\n",
    "                    files = get_image_files_exclude(path=dataset_path+'/valid_'+str(i), folders=(str(species)), exclude_folder=None) # get files from directory\n",
    "                    test_dl = learn.dls.test_dl(files, with_labels=False) # load data as a dataloader\n",
    "                    preds, targets = learn.get_preds(dl=test_dl)\n",
    "                    pred_df = pd.DataFrame(preds.cpu().numpy(), columns=learn.dls.vocab)\n",
    "                    pred_df.to_csv(str(species)+\"_Unknown_Validation_prediction_probabilities_fold-\"+str(i)+\".csv\")\n",
    "\n",
    "                    # testing data\n",
    "                    test_dataset_path = r\"/blue/hulcr/gmarais/Beetle_data/kfold_images\"\n",
    "                    files = get_image_files_exclude(path=test_dataset_path, folders=('test_data'), exclude_folder=species) # get files from directory\n",
    "                    test_dl = learn.dls.test_dl(files, with_labels=True) # load data as a dataloader\n",
    "                    preds, targets = learn.get_preds(dl=test_dl)\n",
    "                    test_targets.append(targets.cpu().numpy())\n",
    "                    max_probs, max_classes = preds.max(dim=1)\n",
    "                    test_class.append(max_classes.cpu().numpy())\n",
    "                    test_preds.append(max_probs.cpu().numpy())\n",
    "                    pred_df = pd.DataFrame(preds.cpu().numpy(), columns=learn.dls.vocab)\n",
    "                    pred_df.to_csv(str(species)+\"_Testing_prediction_probabilities_fold-\"+str(i)+\".csv\")\n",
    "                    # unknown testing \n",
    "                    files = get_image_files_exclude(path=test_dataset_path+'/test_data', folders=(str(species)), exclude_folder=None) # get files from directory\n",
    "                    test_dl = learn.dls.test_dl(files, with_labels=False) # load data as a dataloader\n",
    "                    preds, targets = learn.get_preds(dl=test_dl)\n",
    "                    pred_df = pd.DataFrame(preds.cpu().numpy(), columns=learn.dls.vocab)\n",
    "                    pred_df.to_csv(str(species)+\"_Unknown_Testing_prediction_probabilities_fold-\"+str(i)+\".csv\")\n",
    "\n",
    "            # save results to a csv\n",
    "            class_df = pd.DataFrame(valid_class).T\n",
    "            class_df.columns = [str(col)+'_class' for col in class_df.columns] \n",
    "            target_df = pd.DataFrame(valid_targets).T\n",
    "            target_df.columns = [str(col)+'_target' for col in target_df.columns] \n",
    "            result_df = pd.concat([class_df, target_df], axis=1)\n",
    "            result_df.to_csv(str(species)+\"_Validation_5-fold_CV_classification_results.csv\")\n",
    "\n",
    "            class_df = pd.DataFrame(test_class).T\n",
    "            class_df.columns = [str(col)+'_class' for col in class_df.columns] \n",
    "            target_df = pd.DataFrame(test_targets).T\n",
    "            target_df.columns = [str(col)+'_target' for col in target_df.columns] \n",
    "            result_df = pd.concat([class_df, target_df], axis=1)\n",
    "            result_df.to_csv(str(species)+\"_Testing_5-fold_CV_classification_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e097977-78eb-43fe-96d0-e07e3ba62585",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3315339d-95ed-4403-9c2e-b7500cda7242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "species_lst = [\n",
    "    \"Coccotypes_dactyliperda\",\n",
    "    \"Hylesinus_varius\",\n",
    "    \"Monarthrum_fasciatum\",\n",
    "    \"Phloeosinus_dentatus\",\n",
    "    \"Pityophthorus_juglandis\",\n",
    "    \"Platypus_cylindrus\",\n",
    "    \"Pycnarthrum_hispidium\",\n",
    "    \"Scolotodes_schwarzi\",\n",
    "    \"Xyleborinus_saxesenii\",\n",
    "    \"Xyleborus_affinis\",\n",
    "    \"Xylosandrus_compactus\",\n",
    "    \"Xylosandrus_crassiusculus\",\n",
    "    None\n",
    "]\n",
    "\n",
    "for species in species_lst:\n",
    "    # CV training\n",
    "    valid_targets = []\n",
    "    valid_preds = []\n",
    "    valid_class = []\n",
    "    test_targets = []\n",
    "    test_preds = []\n",
    "    test_class = []\n",
    "    for i in range(1, 6):\n",
    "        # Train Model\n",
    "        print(\"Training: \", str(i))\n",
    "        dataset_path = r\"/blue/hulcr/gmarais/Beetle_data/kfold_images/train_data\"\n",
    "        # dataset_path = r\"F:\\Beetle_data\\kfold_images\\train_data\"\n",
    "        wandb.init(project=config.wandb_project, group=config.wandb_group, job_type=config.job_type, config=config)\n",
    "        learn = train(config=config, \n",
    "                      dataset_path=dataset_path, \n",
    "                      subfolders=('train_'+str(i),'valid_'+str(i)),\n",
    "                     exclude_folder=species)\n",
    "        wandb.finish()\n",
    "\n",
    "        # get predicstions and labels\n",
    "        print(\"Testing: \", str(i))\n",
    "        learn.remove_cb(WandbCallback)\n",
    "        # Get validation labels and predictions\n",
    "        files = get_image_files_exclude(path=dataset_path, folders=('valid_'+str(i)), exclude_folder=species) # get files from directory\n",
    "        test_dl = learn.dls.test_dl(files, with_labels=True) # load data as a dataloader\n",
    "        preds, targets = learn.get_preds(dl=test_dl)\n",
    "        valid_targets.append(targets.cpu().numpy())\n",
    "        max_probs, max_classes = preds.max(dim=1)\n",
    "        valid_class.append(max_classes.cpu().numpy())\n",
    "        valid_preds.append(max_probs.cpu().numpy())\n",
    "        pred_df = pd.DataFrame(preds.cpu().numpy(), columns=learn.dls.vocab)\n",
    "        pred_df.to_csv(str(species)+\"_Validation_prediction_probabilities_fold-\"+str(i)+\".csv\")\n",
    "        # unknown validation\n",
    "        files = get_image_files_exclude(path=dataset_path+'/valid_'+str(i), folders=(str(species)), exclude_folder=None) # get files from directory\n",
    "        test_dl = learn.dls.test_dl(files, with_labels=False) # load data as a dataloader\n",
    "        preds, targets = learn.get_preds(dl=test_dl)\n",
    "        pred_df = pd.DataFrame(preds.cpu().numpy(), columns=learn.dls.vocab)\n",
    "        pred_df.to_csv(str(species)+\"_Unknown_Validation_prediction_probabilities_fold-\"+str(i)+\".csv\")\n",
    "\n",
    "        # testing data\n",
    "        test_dataset_path = r\"/blue/hulcr/gmarais/Beetle_data/kfold_images\"\n",
    "        files = get_image_files_exclude(path=test_dataset_path, folders=('test_data'), exclude_folder=species) # get files from directory\n",
    "        test_dl = learn.dls.test_dl(files, with_labels=True) # load data as a dataloader\n",
    "        preds, targets = learn.get_preds(dl=test_dl)\n",
    "        test_targets.append(targets.cpu().numpy())\n",
    "        max_probs, max_classes = preds.max(dim=1)\n",
    "        test_class.append(max_classes.cpu().numpy())\n",
    "        test_preds.append(max_probs.cpu().numpy())\n",
    "        pred_df = pd.DataFrame(preds.cpu().numpy(), columns=learn.dls.vocab)\n",
    "        pred_df.to_csv(str(species)+\"_Testing_prediction_probabilities_fold-\"+str(i)+\".csv\")\n",
    "        # unknown testing \n",
    "        files = get_image_files_exclude(path=test_dataset_path+'/test_data', folders=(str(species)), exclude_folder=None) # get files from directory\n",
    "        test_dl = learn.dls.test_dl(files, with_labels=False) # load data as a dataloader\n",
    "        preds, targets = learn.get_preds(dl=test_dl)\n",
    "        pred_df = pd.DataFrame(preds.cpu().numpy(), columns=learn.dls.vocab)\n",
    "        pred_df.to_csv(str(species)+\"_Unknown_Testing_prediction_probabilities_fold-\"+str(i)+\".csv\")\n",
    "\n",
    "    # save results to a csv\n",
    "    class_df = pd.DataFrame(valid_class).T\n",
    "    class_df.columns = [str(col)+'_class' for col in class_df.columns] \n",
    "    target_df = pd.DataFrame(valid_targets).T\n",
    "    target_df.columns = [str(col)+'_target' for col in target_df.columns] \n",
    "    result_df = pd.concat([class_df, target_df], axis=1)\n",
    "    result_df.to_csv(str(species)+\"_Validation_5-fold_CV_classification_results.csv\")\n",
    "\n",
    "    class_df = pd.DataFrame(test_class).T\n",
    "    class_df.columns = [str(col)+'_class' for col in class_df.columns] \n",
    "    target_df = pd.DataFrame(test_targets).T\n",
    "    target_df.columns = [str(col)+'_target' for col in target_df.columns] \n",
    "    result_df = pd.concat([class_df, target_df], axis=1)\n",
    "    result_df.to_csv(str(species)+\"_Testing_5-fold_CV_classification_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952588fe-bcd3-47a8-9349-ae93352c6c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277e4569-8ee9-4992-8fab-3c4a7f01c4ae",
   "metadata": {},
   "source": [
    "# 5-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fb477d-1dc2-4319-88d0-39f6e7ac4b66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CV training\n",
    "valid_targets = []\n",
    "valid_preds = []\n",
    "valid_class = []\n",
    "test_targets = []\n",
    "test_preds = []\n",
    "test_class = []\n",
    "for i in range(1, 6):\n",
    "    # Train Model\n",
    "    print(\"Training: \", str(i))\n",
    "    dataset_path = r\"/blue/hulcr/gmarais/Beetle_data/kfold_images/train_data\"\n",
    "    # dataset_path = r\"F:\\Beetle_data\\kfold_images\\train_data\"\n",
    "    wandb.init(project=config.wandb_project, group=config.wandb_group, job_type=config.job_type, config=config)\n",
    "    learn = train(config=config, \n",
    "                  dataset_path=dataset_path, \n",
    "                  subfolders=('train_'+str(i),'valid_'+str(i)),\n",
    "                 exclude_folder=None)\n",
    "    wandb.finish()\n",
    "    \n",
    "    # get predicstions and labels\n",
    "    print(\"Testing: \", str(i))\n",
    "    learn.remove_cb(WandbCallback)\n",
    "    # Get validation labels and predictions\n",
    "    files = get_image_files_exclude(path=dataset_path, folders=('valid_'+str(i)), exclude_folder=None) # get files from directory\n",
    "    test_dl = learn.dls.test_dl(files, with_labels=True) # load data as a dataloader\n",
    "    preds, targets = learn.get_preds(dl=test_dl)\n",
    "    valid_targets.append(targets.cpu().numpy())\n",
    "    max_probs, max_classes = preds.max(dim=1)\n",
    "    valid_class.append(max_classes.cpu().numpy())\n",
    "    valid_preds.append(max_probs.cpu().numpy())\n",
    "    pred_df = pd.DataFrame(preds.cpu().numpy(), columns=learn.dls.vocab)\n",
    "    pred_df.to_csv(\"Validation_prediction_probabilities_fold_\"+str(i)+\".csv\")\n",
    "    \n",
    "    # testing data\n",
    "    files = get_image_files_exclude(path=dataset_path, folders=('valid_'+str(i)), exclude_folder=None) # get files from directory\n",
    "    test_dl = learn.dls.test_dl(files, with_labels=True) # load data as a dataloader\n",
    "    preds, targets = learn.get_preds(dl=test_dl)\n",
    "    test_targets.append(targets.cpu().numpy())\n",
    "    max_probs, max_classes = preds.max(dim=1)\n",
    "    test_class.append(max_classes.cpu().numpy())\n",
    "    test_preds.append(max_probs.cpu().numpy())\n",
    "    pred_df = pd.DataFrame(preds.cpu().numpy(), columns=learn.dls.vocab)\n",
    "    pred_df.to_csv(\"Testing_prediction_probabilities_fold-\"+str(i)+\".csv\")\n",
    "    \n",
    "# save results to a csv\n",
    "class_df = pd.DataFrame(valid_class).T\n",
    "class_df.columns = [str(col)+'_class' for col in class_df.columns] \n",
    "target_df = pd.DataFrame(valid_targets).T\n",
    "target_df.columns = [str(col)+'_target' for col in target_df.columns] \n",
    "result_df = pd.concat([class_df, target_df], axis=1)\n",
    "result_df.to_csv(\"Validation_5-fold_CV_classification_results.csv\")\n",
    "\n",
    "class_df = pd.DataFrame(test_class).T\n",
    "class_df.columns = [str(col)+'_class' for col in class_df.columns] \n",
    "target_df = pd.DataFrame(test_targets).T\n",
    "target_df.columns = [str(col)+'_target' for col in target_df.columns] \n",
    "result_df = pd.concat([class_df, target_df], axis=1)\n",
    "result_df.to_csv(\"Testing_5-fold_CV_classification_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26f127d-ce29-44cb-8f02-19e5454ef5cb",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d677984-84cd-4344-8929-6deb33e8aac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train Model\n",
    "dataset_path = r\"/blue/hulcr/gmarais/Beetle_data/kfold_images/train_data\"\n",
    "# dataset_path = r\"F:\\Beetle_data\\kfold_images\\train_data\"\n",
    "wandb.init(project=config.wandb_project, group=config.wandb_group, job_type=config.job_type, config=config)\n",
    "learn = train(config=config, dataset_path=dataset_path, exclude_folder=None)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ba4082-af8d-432d-9c55-372a77332a69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn.remove_cb(WandbCallback)\n",
    "lrs = learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))\n",
    "plt.savefig('Learning_rate_find.png', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e450bc27-0910-4b5e-b6df-95cc93085dea",
   "metadata": {},
   "source": [
    "Training images: 32.469 (~25000 training and ~7500 validation [80/20 split])\n",
    "Testing Images: 4610"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045802a9-049d-4be7-9c10-105e30a7c5ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save Model Locally and to Huggingface Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec139e7c-a844-49fe-b507-c77931492ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save model to disk for inference\n",
    "learn.path = Path(\"/blue/hulcr/gmarais/Beetle_classifier/Models\")\n",
    "# learn.path = Path(\"F:\\Beetle_data\\Models\")\n",
    "learn.remove_cb(WandbCallback) # remove WandbCallbacks to allow prediction model to be applied without wandb\n",
    "# wandb.unwatch(learn.model)\n",
    "learn.export('beetle_classifier.pkl')#, pickle_module=dill) # use learn.save to save model and continue training later\n",
    "\n",
    "# load to huggingface hub\n",
    "repo_id=\"ChristopherMarais/beetle-model\"\n",
    "push_to_hub_fastai(learner=learn, repo_id=repo_id, token=\"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6928116-f083-4831-8120-5995715ef049",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd667977-042e-4100-a8bf-922e12c202d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from huggingface Hub\n",
    "repo_id=\"ChristopherMarais/beetle-model\"\n",
    "learn = from_pretrained_fastai(repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e80506-d4f8-428f-94e4-563865cfdbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import testing data\n",
    "dataset_path=r\"/blue/hulcr/gmarais/Beetle_data/kfold_images\"\n",
    "# dataset_path=r\"F:\\Beetle_data\\kfold_images\"\n",
    "files = get_image_files(path=dataset_path, recurse=True, folders=('test_data')) # get files from directory\n",
    "test_dl = learn.dls.test_dl(files, with_labels=True) # load data as a dataloader\n",
    "preds, targets = learn.get_preds(dl=test_dl)\n",
    "\n",
    "# get names of classes\n",
    "class_lst = list(learn.dls.vocab)\n",
    "class_lst.append(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093f948b-a7ed-4d75-96d7-efb760771d9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate ROC curve for classifier\n",
    "threshold_resolution = 0.001\n",
    "wedge_magnitude=2\n",
    "fpr_lst = []\n",
    "tpr_lst = []\n",
    "threshold_arr = np.arange(0,1+threshold_resolution,threshold_resolution)\n",
    "for i in threshold_arr:\n",
    "    # add unknown class probability\n",
    "    unknown_preds = np.apply_along_axis(unknown_prob_calc, axis=1, arr=np.array(preds), wedge_threshold=i, wedge_magnitude=wedge_magnitude) # calculate unknown class probability\n",
    "    full_preds = torch.from_numpy(np.concatenate((np.array(preds), unknown_preds[:, np.newaxis]), axis=1)) # add probability to estimates\n",
    "    preds_probs, preds_class = torch.max(full_preds, axis=1)\n",
    "    cnf_matrix = confusion_matrix(y_true=np.array(targets), y_pred=np.array(preds_class))\n",
    "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)\n",
    "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "    TP = np.diag(cnf_matrix)\n",
    "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "    FPR = FP/(FP+TN)\n",
    "    fpr_lst.append(FPR)\n",
    "    TPR = TP/(TP+FN + 1e-6) # add 1e-6 to avoid the Nan value that happends when class not in targets\n",
    "    tpr_lst.append(TPR)\n",
    "\n",
    "# create dataframe with information in it\n",
    "# get column names for each dataframe\n",
    "FPR_class_lst = [x + \"_FPR\" for x in class_lst]\n",
    "TPR_class_lst = [x + \"_TPR\" for x in class_lst]\n",
    "df_fpr = pd.DataFrame(fpr_lst, columns=FPR_class_lst)\n",
    "df_tpr = pd.DataFrame(tpr_lst, columns=TPR_class_lst)\n",
    "df_ROC = pd.concat([df_tpr, df_fpr], axis=1) # get all data in one df\n",
    "df_ROC['threshold'] = threshold_arr # add threshold column\n",
    "ROC_lst = FPR_class_lst + TPR_class_lst\n",
    "df_ROC = df_ROC.drop_duplicates(subset=ROC_lst) # get rid of all unecessary duplicates\n",
    "df_ROC = df_ROC.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bea8da-6ab3-4981-b256-0388dadded23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f100c53b-702b-4f53-8585-cfcb84b065eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize ROC curve\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# Create an empty figure, and iteratively add new lines\n",
    "# every time we compute a new class\n",
    "fig = go.Figure()\n",
    "fig.add_shape(\n",
    "    type='line', line=dict(dash='dash'),\n",
    "    x0=0, x1=1, y0=0, y1=1\n",
    ")\n",
    "\n",
    "\n",
    "for i in class_lst:\n",
    "    # get data from dataframe\n",
    "    fpr = df_ROC[i+\"_FPR\"].tolist()\n",
    "    fpr.insert(0, 0)\n",
    "    fpr.insert(-1, 1)\n",
    "    fpr.sort()\n",
    "    tpr = df_ROC[i+\"_TPR\"].tolist()\n",
    "    tpr.insert(0, 0)\n",
    "    tpr.insert(-1, 1)\n",
    "    tpr.sort()\n",
    "    \n",
    "    auc_score = auc(fpr, tpr)\n",
    "\n",
    "    name = f\"{i} (AUC={auc_score:.2f})\"\n",
    "    fig.add_trace(go.Scatter(x=fpr, y=tpr, name=i, mode='lines'))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='False Positive Rate',\n",
    "    yaxis_title='True Positive Rate',\n",
    "    yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    "    xaxis=dict(constrain='domain'),\n",
    "    width=1000, height=1000\n",
    ")\n",
    "fig.show()\n",
    "# Save the figure as an HTML file\n",
    "pyo.plot(fig, filename='ROC_curve.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4c44a7-5730-4116-9444-969c16a5a5e6",
   "metadata": {},
   "source": [
    "selecting a threshold is practically irrelevant but os far the bst one is at ~0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ee2f2-e70a-46f0-8c65-13504865dc0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import model again to test\n",
    "# learn = load_learner(Path(\"/blue/hulcr/gmarais/Beetle_classifier/Models\") / 'beetle_classifier.pkl', cpu=False, pickle_module=dill)\n",
    "# print(learn.dls.vocab) # print all possible classes of model\n",
    "\n",
    "# import testing data\n",
    "dataset_path=r\"/blue/hulcr/gmarais/Beetle_data/kfold_images\"\n",
    "# dataset_path=r\"F:\\Beetle_data\\kfold_images\"\n",
    "files = get_image_files(path=dataset_path, recurse=True, folders=('test_data')) # get files from directory\n",
    "test_dl = learn.dls.test_dl(files, with_labels=True) # load data as a dataloader\n",
    "\n",
    "preds, targets = learn.get_preds(dl=test_dl)\n",
    "val_out = learn.validate(dl=test_dl)\n",
    "print(\" Loss: \"+str(val_out[0])+\"\\n\",\n",
    "      \"Error Rate: \"+str(val_out[1])+\"\\n\",\n",
    "      \"Accuracy: \"+str(val_out[2])+\"\\n\",\n",
    "      \"Top k(5) Accuracy: \"+str(val_out[3])+\"\\n\")\n",
    "\n",
    "# add unknown class probability\n",
    "unknown_preds = np.apply_along_axis(unknown_prob_calc, axis=1, arr=np.array(preds), wedge_threshold=0.5) # calculate unknown class probability\n",
    "full_preds = torch.from_numpy(np.concatenate((np.array(preds), unknown_preds[:, np.newaxis]), axis=1)) # add probability to estimates\n",
    "preds_probs, preds_class = torch.max(full_preds, axis=1)\n",
    "\n",
    "\n",
    "# plot confusion matrix\n",
    "arr_cm = confusion_matrix(y_true=np.array(targets), y_pred=np.array(preds_class))\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(arr_cm, cmap='Blues')\n",
    "ax.set_xticks(range(0,11))\n",
    "ax.set_xticklabels(class_lst)\n",
    "ax.set_yticks(range(0,11))\n",
    "ax.set_yticklabels(class_lst)\n",
    "# Get the colormap colors\n",
    "my_cmap = im.cmap(im.norm(arr_cm))\n",
    "for i in range(arr_cm.shape[0]):\n",
    "    for j in range(arr_cm.shape[1]):\n",
    "        # Get the RGB color of the cell\n",
    "        rgba = my_cmap[i, j]\n",
    "        # If the cell is dark, use white text; otherwise, use black text\n",
    "        text_color = 'w' if rgba[:3].mean() < 0.5 else 'k'\n",
    "        ax.text(j, i, arr_cm[i, j], ha='center', va='center', color=text_color)\n",
    "plt.title(\"Test Confusion Matrix\")        \n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BC_310",
   "language": "python",
   "name": "bc_310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
