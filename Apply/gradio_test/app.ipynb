{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d07df97e-617d-4ceb-912a-debb77f5ad8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T18:19:41.262644Z",
     "iopub.status.busy": "2023-03-29T18:19:41.261644Z",
     "iopub.status.idle": "2023-03-29T18:19:47.396495Z",
     "shell.execute_reply": "2023-03-29T18:19:47.395493Z",
     "shell.execute_reply.started": "2023-03-29T18:19:41.262644Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dill\n",
    "import timm\n",
    "import numpy as np\n",
    "from fastai.tabular.all import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.utils import get_image_files\n",
    "from Ambrosia import pre_process_image\n",
    "from huggingface_hub import from_pretrained_fastai, push_to_hub_fastai\n",
    "import gradio as gr\n",
    "###########\n",
    "# use this to laod on windows\n",
    "import pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e1ca7cd-a19f-4d08-a5df-594b3832a9a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T18:19:47.397493Z",
     "iopub.status.busy": "2023-03-29T18:19:47.397493Z",
     "iopub.status.idle": "2023-03-29T18:19:47.412601Z",
     "shell.execute_reply": "2023-03-29T18:19:47.411616Z",
     "shell.execute_reply.started": "2023-03-29T18:19:47.397493Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load local model and push to hugging_face_Hub\n",
    "# learn = load_learner(\"E:\\\\GIT_REPOS\\\\Beetle_classifier\\\\Models\\\\beetle_classifier.pkl\", cpu=False)\n",
    "\n",
    "# # repo_id = \"YOUR_USERNAME/YOUR_LEARNER_NAME\"\n",
    "# repo_id = \"ChristopherMarais/Andrew_Alpha_model\"\n",
    "# push_to_hub_fastai(learner=learn, repo_id=repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01815caf-d8a3-4de5-814e-aa956f472878",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T18:19:47.415600Z",
     "iopub.status.busy": "2023-03-29T18:19:47.414598Z",
     "iopub.status.idle": "2023-03-29T18:19:48.952031Z",
     "shell.execute_reply": "2023-03-29T18:19:48.951020Z",
     "shell.execute_reply.started": "2023-03-29T18:19:47.415600Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this function only describes how much a singular value in al ist stands out.\n",
    "# if all values in the lsit are high or low this is 1\n",
    "# the smaller the proportiopn of number of disimilar vlaues are to other more similar values the lower this number\n",
    "# the larger the gap between the dissimilar numbers and the simialr number the smaller this number\n",
    "# only able to interpret probabilities or values between 0 and 1\n",
    "# this function outputs an estimate an inverse of the classification confidence based on the probabilities of all the classes.\n",
    "# the wedge threshold splits the data on a threshold with a magnitude of a positive int to force a ledge/peak in the data\n",
    "def unkown_prob_calc(probs, wedge_threshold, wedge_magnitude=1, wedge='strict'):\n",
    "    if wedge =='strict':\n",
    "        increase_var = (1/(wedge_magnitude))\n",
    "        decrease_var = (wedge_magnitude)\n",
    "    if wedge =='dynamic': # this allows pointsthat are furhter from the threshold ot be moved less and points clsoer to be moved more\n",
    "        increase_var = (1/(wedge_magnitude*((1-np.abs(probs-wedge_threshold)))))\n",
    "        decrease_var = (wedge_magnitude*((1-np.abs(probs-wedge_threshold))))\n",
    "    else:\n",
    "        print(\"Error: use 'strict' (default) or 'dynamic' as options for the wedge parameter!\")\n",
    "    probs = np.where(probs>=wedge_threshold , probs**increase_var, probs)\n",
    "    probs = np.where(probs<=wedge_threshold , probs**decrease_var, probs)\n",
    "    diff_matrix = np.abs(probs[:, np.newaxis] - probs)\n",
    "    diff_matrix_sum = np.sum(diff_matrix)\n",
    "    probs_sum = np.sum(probs)\n",
    "    class_val = (diff_matrix_sum/probs_sum)\n",
    "    max_class_val = ((len(probs)-1)*2)\n",
    "    kown_prob = class_val/max_class_val\n",
    "    unknown_prob = 1-kown_prob\n",
    "    return(unknown_prob)\n",
    "\n",
    "# load model\n",
    "# learn = load_learner(\"E:\\\\GIT_REPOS\\\\Beetle_classifier\\\\Models\\\\beetle_classifier.pkl\", cpu=False)\n",
    "learn = load_learner(r\"C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\LAB\\Beetle_classifier\\Models\\beetle_classifier.pkl\", cpu=False)\n",
    "# get class names\n",
    "labels = np.append(np.array(learn.dls.vocab), \"Unknown\")\n",
    "\n",
    "def predict(img):\n",
    "    # Segment image into smaller images\n",
    "    pre_process = pre_process_image(manual_thresh_buffer=0.15, image = img) # use image_dir if directory of image used\n",
    "    pre_process.segment(cluster_num=2, \n",
    "                        image_edge_buffer=50)\n",
    "    # get predictions for all segments\n",
    "    conf_dict_lst = []\n",
    "    output_lst = []\n",
    "    img_cnt = len(pre_process.col_image_lst)\n",
    "    for i in range(0,img_cnt):\n",
    "        prob_ar = np.array(learn.predict(pre_process.col_image_lst[i])[2])\n",
    "        unkown_prob = unkown_prob_calc(probs=prob_ar, wedge_threshold=0.85, wedge_magnitude=5, wedge='dynamic')\n",
    "        prob_ar = np.append(prob_ar, unkown_prob)\n",
    "        prob_ar = np.around(prob_ar*100, decimals=1)\n",
    "        \n",
    "        conf_dict = {labels[i]: float(prob_ar[i]) for i in range(len(prob_ar))}\n",
    "        conf_dict = dict(sorted(conf_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "        conf_dict_lst.append(str(conf_dict))\n",
    "        result = list(zip(pre_process.col_image_lst, conf_dict_lst))\n",
    "                \n",
    "    return(result)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "67af10ab-b893-4bea-bd34-86445ffd45c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T21:04:55.545754Z",
     "iopub.status.busy": "2023-03-29T21:04:55.545754Z",
     "iopub.status.idle": "2023-03-29T21:05:00.208557Z",
     "shell.execute_reply": "2023-03-29T21:05:00.207554Z",
     "shell.execute_reply.started": "2023-03-29T21:04:55.545754Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://51125efea8cba09401.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://51125efea8cba09401.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Column(variant=\"panel\"):\n",
    "        with gr.Row(variant=\"compact\"):\n",
    "            inputs = gr.Image()\n",
    "            btn = gr.Button(\"Classify\").style(full_width=False)\n",
    "\n",
    "        gallery = gr.Gallery(\n",
    "            label=\"Show images\", show_label=True, elem_id=\"gallery\"\n",
    "        ).style(grid=[8], height=\"auto\")\n",
    "\n",
    "    btn.click(predict, inputs, gallery)\n",
    "    demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac9ac87-2996-4374-bc2c-2fde90cc1094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T18:19:49.298488Z",
     "iopub.status.busy": "2023-03-29T18:19:49.298488Z",
     "iopub.status.idle": "2023-03-29T18:19:49.327696Z",
     "shell.execute_reply": "2023-03-29T18:19:49.326681Z",
     "shell.execute_reply.started": "2023-03-29T18:19:49.298488Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf478df8798f4728b4bbb06567b81b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1f77851c-94de-4382-b67b-6ea7c5ece39d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T21:03:23.499098Z",
     "iopub.status.busy": "2023-03-29T21:03:23.498097Z",
     "iopub.status.idle": "2023-03-29T21:03:23.516226Z",
     "shell.execute_reply": "2023-03-29T21:03:23.514215Z",
     "shell.execute_reply.started": "2023-03-29T21:03:23.499098Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = r\"C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\LAB\\Beetle_classifier\\Models\\beetle_classifier.pkl\"\n",
    "hf_repo = 'ChristopherMarais/Andrew_Alpha_model'\n",
    "model_name=\"maxvit_rmlp_small_rw_224.sw_in1k\"\n",
    "model_name = \"beetle-model\"\n",
    "auth_token='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "353bb298-af25-49b6-9266-656b9614ac42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T21:03:32.234895Z",
     "iopub.status.busy": "2023-03-29T21:03:32.234895Z",
     "iopub.status.idle": "2023-03-29T21:03:32.484380Z",
     "shell.execute_reply": "2023-03-29T21:03:32.483327Z",
     "shell.execute_reply.started": "2023-03-29T21:03:32.234895Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HfApi' object has no attribute 'push_to_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[139], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m api \u001b[38;5;241m=\u001b[39m HfApi()\n\u001b[0;32m      5\u001b[0m learner \u001b[38;5;241m=\u001b[39m load_learner(model_path)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m(model_id\u001b[38;5;241m=\u001b[39mmodel_name, model\u001b[38;5;241m=\u001b[39mlearner)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HfApi' object has no attribute 'push_to_hub'"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from fastai.learner import load_learner\n",
    "\n",
    "api = HfApi()\n",
    "learner = load_learner(model_path)\n",
    "api.push_to_hub(model_id=model_name, model=learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0db46bd6-9c23-4c6f-8771-141d929b760c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T20:58:45.665559Z",
     "iopub.status.busy": "2023-03-29T20:58:45.665559Z",
     "iopub.status.idle": "2023-03-29T20:58:45.701157Z",
     "shell.execute_reply": "2023-03-29T20:58:45.700140Z",
     "shell.execute_reply.started": "2023-03-29T20:58:45.665559Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ModelHub' from 'huggingface_hub' (C:\\Users\\gcmar\\.conda\\envs\\BC_310\\lib\\site-packages\\huggingface_hub\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[136], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlearner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_learner\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelHub\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load your fastai learner\u001b[39;00m\n\u001b[0;32m      5\u001b[0m learn \u001b[38;5;241m=\u001b[39m load_learner(model_path)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ModelHub' from 'huggingface_hub' (C:\\Users\\gcmar\\.conda\\envs\\BC_310\\lib\\site-packages\\huggingface_hub\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from fastai.learner import load_learner\n",
    "from huggingface_hub import ModelHub\n",
    "\n",
    "# Load your fastai learner\n",
    "learn = load_learner(model_path)\n",
    "\n",
    "# Save the learner object to a file\n",
    "# learn.export('my_export.pkl')\n",
    "\n",
    "# Create a ModelHub instance\n",
    "model_hub = ModelHub()\n",
    "\n",
    "# Push the exported model file to the Hub\n",
    "model_hub.push(model_path, hf_repo)\n",
    "\n",
    "# Publish the model to make it available for download\n",
    "model_hub.publish(hf_repo, '1.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "eb4a7c9d-57bd-42bd-962f-9b92e4a88848",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T20:44:07.259484Z",
     "iopub.status.busy": "2023-03-29T20:44:07.258473Z",
     "iopub.status.idle": "2023-03-29T20:44:07.393141Z",
     "shell.execute_reply": "2023-03-29T20:44:07.392144Z",
     "shell.execute_reply.started": "2023-03-29T20:44:07.259484Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'TorchHistory.add_log_parameters_hook.<locals>.<lambda>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[128], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load your fine-tuned maxVit model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mhuggingface_hub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_pretrained_fastai\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mgcmar\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mGIT_REPOS\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mLAB\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mBeetle_classifier\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mModels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\huggingface_hub\\fastai_utils.py:286\u001b[0m, in \u001b[0;36m_save_pretrained_fastai\u001b[1;34m(learner, save_directory, config)\u001b[0m\n\u001b[0;32m    284\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(save_directory, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 286\u001b[0m     \u001b[43mlearner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEFAULT_PROTOCOL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PicklingError:\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are using a lambda function, i.e., an anonymous function. `pickle`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m cannot pickle function objects and requires that all functions have\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m names. One possible solution is to name the function.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    295\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\fastai\\learner.py:436\u001b[0m, in \u001b[0;36mexport\u001b[1;34m(self, fname, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;66;03m#To avoid the warning that come from PyTorch about model not being checked\u001b[39;00m\n\u001b[0;32m    435\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 436\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_opt()\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mload_state_dict(state)\n",
      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\torch\\serialization.py:423\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m--> 423\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\torch\\serialization.py:635\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    633\u001b[0m pickler \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mPickler(data_buf, protocol\u001b[38;5;241m=\u001b[39mpickle_protocol)\n\u001b[0;32m    634\u001b[0m pickler\u001b[38;5;241m.\u001b[39mpersistent_id \u001b[38;5;241m=\u001b[39m persistent_id\n\u001b[1;32m--> 635\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    636\u001b[0m data_value \u001b[38;5;241m=\u001b[39m data_buf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    637\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mwrite_record(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, data_value, \u001b[38;5;28mlen\u001b[39m(data_value))\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'TorchHistory.add_log_parameters_hook.<locals>.<lambda>'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import huggingface_hub\n",
    "\n",
    "# Load your fine-tuned maxVit model\n",
    "huggingface_hub._save_pretrained_fastai(\n",
    "    learner=learn,\n",
    "    save_directory=r'C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\LAB\\Beetle_classifier\\Models',\n",
    "    config=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8d8c97-664e-467a-9f4a-f0cec3cfadb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7510633-849e-428c-ad1c-e6b495c684dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318b92a2-2087-44b8-b910-0ef4aea832f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99da152-a9d4-4373-8a6c-461644aa1a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1a4bdcdd-3791-40db-a766-8bad294689f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T20:40:42.971526Z",
     "iopub.status.busy": "2023-03-29T20:40:42.970528Z",
     "iopub.status.idle": "2023-03-29T20:40:45.649603Z",
     "shell.execute_reply": "2023-03-29T20:40:45.648597Z",
     "shell.execute_reply.started": "2023-03-29T20:40:42.971526Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # convert fastai modle to timm/pytorch model\n",
    "# from fastai.callback.wandb import *\n",
    "# # Remove the WandbCallback.\n",
    "# learn.remove_cbs(WandbCallback)\n",
    "\n",
    "# # Save the state dictionary of the PyTorch model.\n",
    "# state_dict = learn.model.state_dict()\n",
    "# torch.save(state_dict, r'C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\LAB\\Beetle_classifier\\Apply\\gradio_test\\my-model.pth')\n",
    "\n",
    "# # Load the state dictionary.\n",
    "# state_dict = torch.load(r'C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\LAB\\Beetle_classifier\\Apply\\gradio_test\\my-model.pth')\n",
    "# # modify state_dict to be of the correct format\n",
    "# remove_text = '0.model.'\n",
    "# if list(state_dict.keys())[0].startswith(remove_text):\n",
    "#     state_dict = {k[len(remove_text):]: v for k, v in state_dict.items()}\n",
    "    \n",
    "# # Create a new instance of the timm model.\n",
    "# model = timm.create_model('maxvit_rmlp_small_rw_224.sw_in1k', pretrained=False, num_classes=len(learn.dls.vocab))\n",
    "# model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "# torch.save(model.state_dict(),r\"C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\LAB\\Beetle_classifier\\Apply\\gradio_test\\clean_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
