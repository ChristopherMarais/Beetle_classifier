{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d07df97e-617d-4ceb-912a-debb77f5ad8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T18:19:41.262644Z",
     "iopub.status.busy": "2023-03-29T18:19:41.261644Z",
     "iopub.status.idle": "2023-03-29T18:19:47.396495Z",
     "shell.execute_reply": "2023-03-29T18:19:47.395493Z",
     "shell.execute_reply.started": "2023-03-29T18:19:41.262644Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dill\n",
    "import timm\n",
    "import numpy as np\n",
    "from fastai.tabular.all import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.utils import get_image_files\n",
    "from Ambrosia import pre_process_image\n",
    "from huggingface_hub import from_pretrained_fastai, push_to_hub_fastai\n",
    "import gradio as gr\n",
    "###########\n",
    "# use this to laod on windows\n",
    "import pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e1ca7cd-a19f-4d08-a5df-594b3832a9a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T18:19:47.397493Z",
     "iopub.status.busy": "2023-03-29T18:19:47.397493Z",
     "iopub.status.idle": "2023-03-29T18:19:47.412601Z",
     "shell.execute_reply": "2023-03-29T18:19:47.411616Z",
     "shell.execute_reply.started": "2023-03-29T18:19:47.397493Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load local model and push to hugging_face_Hub\n",
    "# learn = load_learner(\"E:\\\\GIT_REPOS\\\\Beetle_classifier\\\\Models\\\\beetle_classifier.pkl\", cpu=False)\n",
    "\n",
    "# # repo_id = \"YOUR_USERNAME/YOUR_LEARNER_NAME\"\n",
    "# repo_id = \"ChristopherMarais/Andrew_Alpha_model\"\n",
    "# push_to_hub_fastai(learner=learn, repo_id=repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01815caf-d8a3-4de5-814e-aa956f472878",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T18:19:47.415600Z",
     "iopub.status.busy": "2023-03-29T18:19:47.414598Z",
     "iopub.status.idle": "2023-03-29T18:19:48.952031Z",
     "shell.execute_reply": "2023-03-29T18:19:48.951020Z",
     "shell.execute_reply.started": "2023-03-29T18:19:47.415600Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this function only describes how much a singular value in al ist stands out.\n",
    "# if all values in the lsit are high or low this is 1\n",
    "# the smaller the proportiopn of number of disimilar vlaues are to other more similar values the lower this number\n",
    "# the larger the gap between the dissimilar numbers and the simialr number the smaller this number\n",
    "# only able to interpret probabilities or values between 0 and 1\n",
    "# this function outputs an estimate an inverse of the classification confidence based on the probabilities of all the classes.\n",
    "# the wedge threshold splits the data on a threshold with a magnitude of a positive int to force a ledge/peak in the data\n",
    "def unkown_prob_calc(probs, wedge_threshold, wedge_magnitude=1, wedge='strict'):\n",
    "    if wedge =='strict':\n",
    "        increase_var = (1/(wedge_magnitude))\n",
    "        decrease_var = (wedge_magnitude)\n",
    "    if wedge =='dynamic': # this allows pointsthat are furhter from the threshold ot be moved less and points clsoer to be moved more\n",
    "        increase_var = (1/(wedge_magnitude*((1-np.abs(probs-wedge_threshold)))))\n",
    "        decrease_var = (wedge_magnitude*((1-np.abs(probs-wedge_threshold))))\n",
    "    else:\n",
    "        print(\"Error: use 'strict' (default) or 'dynamic' as options for the wedge parameter!\")\n",
    "    probs = np.where(probs>=wedge_threshold , probs**increase_var, probs)\n",
    "    probs = np.where(probs<=wedge_threshold , probs**decrease_var, probs)\n",
    "    diff_matrix = np.abs(probs[:, np.newaxis] - probs)\n",
    "    diff_matrix_sum = np.sum(diff_matrix)\n",
    "    probs_sum = np.sum(probs)\n",
    "    class_val = (diff_matrix_sum/probs_sum)\n",
    "    max_class_val = ((len(probs)-1)*2)\n",
    "    kown_prob = class_val/max_class_val\n",
    "    unknown_prob = 1-kown_prob\n",
    "    return(unknown_prob)\n",
    "\n",
    "# load model\n",
    "# learn = load_learner(\"E:\\\\GIT_REPOS\\\\Beetle_classifier\\\\Models\\\\beetle_classifier.pkl\", cpu=False)\n",
    "learn = load_learner(r\"C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\LAB\\Beetle_classifier\\Models\\beetle_classifier.pkl\", cpu=False)\n",
    "# get class names\n",
    "labels = np.append(np.array(learn.dls.vocab), \"Unknown\")\n",
    "\n",
    "def predict(img):\n",
    "    # Segment image into smaller images\n",
    "    pre_process = pre_process_image(manual_thresh_buffer=0.15, image = img) # use image_dir if directory of image used\n",
    "    pre_process.segment(cluster_num=2, \n",
    "                        image_edge_buffer=50)\n",
    "    # get predictions for all segments\n",
    "    conf_dict_lst = []\n",
    "    output_lst = []\n",
    "    img_cnt = len(pre_process.col_image_lst)\n",
    "    for i in range(0,img_cnt):\n",
    "        prob_ar = np.array(learn.predict(pre_process.col_image_lst[i])[2])\n",
    "        unkown_prob = unkown_prob_calc(probs=prob_ar, wedge_threshold=0.85, wedge_magnitude=5, wedge='dynamic')\n",
    "        prob_ar = np.append(prob_ar, unkown_prob)\n",
    "        prob_ar = np.around(prob_ar*100, decimals=1)\n",
    "        \n",
    "        conf_dict = {labels[i]: float(prob_ar[i]) for i in range(len(prob_ar))}\n",
    "        conf_dict = dict(sorted(conf_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "        conf_dict_lst.append(str(conf_dict))\n",
    "        result = list(zip(pre_process.col_image_lst, conf_dict_lst))\n",
    "                \n",
    "    return(result)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67af10ab-b893-4bea-bd34-86445ffd45c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T18:19:48.953029Z",
     "iopub.status.busy": "2023-03-29T18:19:48.953029Z",
     "iopub.status.idle": "2023-03-29T18:19:49.297483Z",
     "shell.execute_reply": "2023-03-29T18:19:49.296484Z",
     "shell.execute_reply.started": "2023-03-29T18:19:48.953029Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Column(variant=\"panel\"):\n",
    "        with gr.Row(variant=\"compact\"):\n",
    "            inputs = gr.Image()\n",
    "            btn = gr.Button(\"Classify\").style(full_width=False)\n",
    "\n",
    "        gallery = gr.Gallery(\n",
    "            label=\"Show images\", show_label=True, elem_id=\"gallery\"\n",
    "        ).style(grid=[8], height=\"auto\")\n",
    "\n",
    "    btn.click(predict, inputs, gallery)\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac9ac87-2996-4374-bc2c-2fde90cc1094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T18:19:49.298488Z",
     "iopub.status.busy": "2023-03-29T18:19:49.298488Z",
     "iopub.status.idle": "2023-03-29T18:19:49.327696Z",
     "shell.execute_reply": "2023-03-29T18:19:49.326681Z",
     "shell.execute_reply.started": "2023-03-29T18:19:49.298488Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf478df8798f4728b4bbb06567b81b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3919eb41-b6d2-4349-bbb4-1f3539c4f983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T18:57:22.502421Z",
     "iopub.status.busy": "2023-03-29T18:57:22.501421Z",
     "iopub.status.idle": "2023-03-29T18:57:22.513428Z",
     "shell.execute_reply": "2023-03-29T18:57:22.512432Z",
     "shell.execute_reply.started": "2023-03-29T18:57:22.501421Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x1c59edb00a0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn\n",
    "# \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e538d890-0ba0-4c00-bbf9-a60ce4a636d4",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-03-29T18:57:29.943732Z",
     "iopub.status.busy": "2023-03-29T18:57:29.943732Z",
     "iopub.status.idle": "2023-03-29T18:57:30.911805Z",
     "shell.execute_reply": "2023-03-29T18:57:30.910813Z",
     "shell.execute_reply.started": "2023-03-29T18:57:29.943732Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "It looks like the config file at 'C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\LAB\\Beetle_classifier\\Apply\\gradio_test\\model.pt' is not a valid JSON file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\transformers\\configuration_utils.py:650\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;66;03m# Load config dict\u001b[39;00m\n\u001b[1;32m--> 650\u001b[0m     config_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dict_from_json_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_config_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m commit_hash\n",
      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\transformers\\configuration_utils.py:737\u001b[0m, in \u001b[0;36mPretrainedConfig._dict_from_json_file\u001b[1;34m(cls, json_file)\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m reader:\n\u001b[1;32m--> 737\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(text)\n",
      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    321\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m--> 322\u001b[0m (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# keep undecoded input until the next call\u001b[39;00m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 64: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ViTModel\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load the PyTorch model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# model = ViTModel.from_pretrained(model_path, num_classes=len(learn.dls.vocab))\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mViTModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Upload the model to Hugging Face Hub\u001b[39;00m\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChristopherMarais/Andrew_Alpha_model\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     14\u001b[0m                   use_auth_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhf_NgEPaDuSuGJXuLoDAQdNfiDRyCzejXaLaV\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     15\u001b[0m                   repo_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, organization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[0;32m     16\u001b[0m                   overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\transformers\\modeling_utils.py:2079\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2077\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m   2078\u001b[0m     config_path \u001b[38;5;241m=\u001b[39m config \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pretrained_model_name_or_path\n\u001b[1;32m-> 2079\u001b[0m     config, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m   2080\u001b[0m         config_path,\n\u001b[0;32m   2081\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   2082\u001b[0m         return_unused_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2083\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m   2084\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m   2085\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m   2086\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m   2087\u001b[0m         use_auth_token\u001b[38;5;241m=\u001b[39muse_auth_token,\n\u001b[0;32m   2088\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   2089\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[0;32m   2090\u001b[0m         _from_auto\u001b[38;5;241m=\u001b[39mfrom_auto_class,\n\u001b[0;32m   2091\u001b[0m         _from_pipeline\u001b[38;5;241m=\u001b[39mfrom_pipeline,\n\u001b[0;32m   2092\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2093\u001b[0m     )\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2095\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\transformers\\configuration_utils.py:538\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pretrained_model_name_or_path: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPretrainedConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    462\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;124;03m    Instantiate a [`PretrainedConfig`] (or a derived class) from a pretrained model configuration.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;124;03m    assert unused_kwargs == {\"foo\": False}\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;124;03m    ```\"\"\"\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m     config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[0;32m    540\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    541\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are using a model of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to instantiate a model of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    542\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    543\u001b[0m         )\n",
      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\transformers\\configuration_utils.py:565\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    563\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 565\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[0;32m    567\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\transformers\\configuration_utils.py:653\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    651\u001b[0m     config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m commit_hash\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (json\u001b[38;5;241m.\u001b[39mJSONDecodeError, \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m):\n\u001b[1;32m--> 653\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    654\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt looks like the config file at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_config_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a valid JSON file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    655\u001b[0m     )\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_local:\n\u001b[0;32m    658\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading configuration file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_config_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: It looks like the config file at 'C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\LAB\\Beetle_classifier\\Apply\\gradio_test\\model.pt' is not a valid JSON file."
     ]
    }
   ],
   "source": [
    "# Convert the Fastai model to a PyTorch model\n",
    "model = learn.model.eval()\n",
    "model_path = r'C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\LAB\\Beetle_classifier\\Apply\\gradio_test\\model.pt'\n",
    "torch.save({'model_state_dict': model.state_dict()}, model_path)\n",
    "\n",
    "\n",
    "from transformers import ViTModel\n",
    "\n",
    "# Load the PyTorch model\n",
    "# model = ViTModel.from_pretrained(model_path, num_classes=len(learn.dls.vocab))\n",
    "model = ViTModel.from_pretrained(model_path)\n",
    "# Upload the model to Hugging Face Hub\n",
    "model.push_to_hub('ChristopherMarais/Andrew_Alpha_model', \n",
    "                  use_auth_token='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', \n",
    "                  repo_url=None, organization=None, \n",
    "                  overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94310406-9c42-469e-b6ae-53f9546779ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T19:08:45.135709Z",
     "iopub.status.busy": "2023-03-29T19:08:45.135709Z",
     "iopub.status.idle": "2023-03-29T19:08:45.403451Z",
     "shell.execute_reply": "2023-03-29T19:08:45.401447Z",
     "shell.execute_reply.started": "2023-03-29T19:08:45.135709Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f77851c-94de-4382-b67b-6ea7c5ece39d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T19:17:31.001191Z",
     "iopub.status.busy": "2023-03-29T19:17:31.001191Z",
     "iopub.status.idle": "2023-03-29T19:17:31.305019Z",
     "shell.execute_reply": "2023-03-29T19:17:31.303974Z",
     "shell.execute_reply.started": "2023-03-29T19:17:31.001191Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "No huggingface_hub attribute Artifact",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m model_artifact_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeetle-model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m----> 9\u001b[0m model_artifact \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArtifact\u001b[49m(name\u001b[38;5;241m=\u001b[39mmodel_artifact_name, \n\u001b[0;32m     10\u001b[0m                                  tags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     11\u001b[0m                                  hub_model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m     12\u001b[0m model_artifact\u001b[38;5;241m.\u001b[39madd_file(model_path)\n\u001b[0;32m     13\u001b[0m model_artifact\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\huggingface_hub\\__init__.py:290\u001b[0m, in \u001b[0;36m_attach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attr\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: No huggingface_hub attribute Artifact"
     ]
    }
   ],
   "source": [
    "import huggingface_hub as hf_hub\n",
    "\n",
    "\n",
    "model_path = r\"C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\LAB\\Beetle_classifier\\Models\\beetle_classifier.pkl\"\n",
    "hf_repo = 'ChristopherMarais/Andrew_Alpha_model'\n",
    "model_artifact_name = \"beetle-model\"\n",
    "\n",
    "model = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "model_artifact = hf_hub.Artifact(name=model_artifact_name, \n",
    "                                 tags=[\"v1\"],\n",
    "                                 hub_model=model)\n",
    "model_artifact.add_file(model_path)\n",
    "model_artifact.save()\n",
    "hf_hub.HfApi().upload_artifacts(hf_repo, [model_artifact])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6188384-ed3b-49d7-a031-e9828c19a0df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T19:17:20.685529Z",
     "iopub.status.busy": "2023-03-29T19:17:20.684528Z",
     "iopub.status.idle": "2023-03-29T19:17:20.717914Z",
     "shell.execute_reply": "2023-03-29T19:17:20.715907Z",
     "shell.execute_reply.started": "2023-03-29T19:17:20.685529Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'huggingface_hub.hf_api' has no attribute '_save_pretrained_fastai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mhf_hub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_pretrained_fastai\u001b[49m(learn)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'huggingface_hub.hf_api' has no attribute '_save_pretrained_fastai'"
     ]
    }
   ],
   "source": [
    "hf_hub._save_pretrained_fastai(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a02ac66-b82f-4d1e-a7f1-119adcee5a3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T19:17:04.267278Z",
     "iopub.status.busy": "2023-03-29T19:17:04.266260Z",
     "iopub.status.idle": "2023-03-29T19:17:04.276255Z",
     "shell.execute_reply": "2023-03-29T19:17:04.275262Z",
     "shell.execute_reply.started": "2023-03-29T19:17:04.267278Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x1c59edb00a0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import huggingface_hub\n",
    "\n",
    "# Load your fine-tuned maxVit model\n",
    "model = torch.load('C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\LAB\\Beetle_classifier\\Models\\beetle_classifier.pkl', map_location='cpu')\n",
    "\n",
    "# Create an instance of the Hugging Face Hub API\n",
    "api = huggingface_hub.HfApi()\n",
    "\n",
    "# # Create a Hugging Face model repository (if it doesn't already exist)\n",
    "# hf_repo_name = \"ChristopherMarais/Andrew_Alpha_model\"\n",
    "# hf_repo = api.create_repo(hf_repo_name)\n",
    "\n",
    "# Define the name of your Hugging Face model\n",
    "model_name = \"my-maxvit-model\"\n",
    "\n",
    "# Save the `fastai`-trained model to Hugging Face Hub using `_save_pretrained_fastai`\n",
    "huggingface_hub._save_pretrained_fastai(\n",
    "    hf_api=api,\n",
    "    hf_repo_id=hf_repo.id,\n",
    "    model=model,\n",
    "    model_name=model_name,\n",
    "    revision=\"v1\",\n",
    "    tokenizer=None,\n",
    "    config=None,\n",
    "    framework=\"pytorch\",\n",
    "    private=False,\n",
    "    use_auth_token=None,\n",
    ")\n",
    "\n",
    "print(f\"Model '{model_name}' uploaded to '{hf_repo_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2809a6a3-1ac3-4482-b62d-32419f5e5940",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T19:28:36.833628Z",
     "iopub.status.busy": "2023-03-29T19:28:36.833628Z",
     "iopub.status.idle": "2023-03-29T19:28:36.873612Z",
     "shell.execute_reply": "2023-03-29T19:28:36.871618Z",
     "shell.execute_reply.started": "2023-03-29T19:28:36.833628Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "HfApi.list_repo_refs() missing 1 required positional argument: 'repo_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HfApi\n\u001b[0;32m      3\u001b[0m api \u001b[38;5;241m=\u001b[39m HfApi()\n\u001b[1;32m----> 4\u001b[0m repos \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_repo_refs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:120\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    118\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: HfApi.list_repo_refs() missing 1 required positional argument: 'repo_id'"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "repos = api.list_repo_refs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f9b906f-6234-4adc-811f-7a7e624a2cd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T19:31:24.471533Z",
     "iopub.status.busy": "2023-03-29T19:31:24.470521Z",
     "iopub.status.idle": "2023-03-29T19:31:24.751538Z",
     "shell.execute_reply": "2023-03-29T19:31:24.750516Z",
     "shell.execute_reply.started": "2023-03-29T19:31:24.471533Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If not specifying `clone_from`, you need to pass Repository a valid git clone.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Repository\n\u001b[1;32m----> 3\u001b[0m repo \u001b[38;5;241m=\u001b[39m \u001b[43mRepository\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mChristopherMarais/Andrew_Alpha_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:120\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    118\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\huggingface_hub\\repository.py:521\u001b[0m, in \u001b[0;36mRepository.__init__\u001b[1;34m(self, local_dir, clone_from, repo_type, token, git_user, git_email, revision, skip_lfs_files, client)\u001b[0m\n\u001b[0;32m    519\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Repository] is a valid git repo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf not specifying `clone_from`, you need to pass Repository a valid git clone.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhuggingface_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (git_email \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m git_user \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    524\u001b[0m     user \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mwhoami(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhuggingface_token)\n",
      "\u001b[1;31mValueError\u001b[0m: If not specifying `clone_from`, you need to pass Repository a valid git clone."
     ]
    }
   ],
   "source": [
    "from huggingface_hub import Repository\n",
    "\n",
    "repo = Repository(\"ChristopherMarais/Andrew_Alpha_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d38994-ae07-4283-b2cf-a5b99c73398c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7d2660-97ad-4c9c-b091-3a40b747fd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
