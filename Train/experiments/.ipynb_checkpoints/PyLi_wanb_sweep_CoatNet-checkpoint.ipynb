{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b471f1-f5fa-4eb1-b9ae-2d67ed8838df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "from random import randint\n",
    "\n",
    "# Weights & Biases\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# Pytorch modules\n",
    "import torch\n",
    "from torch.nn import Linear, CrossEntropyLoss, functional as F\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "\n",
    "# Pytorch-Lightning\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, Callback\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import torchmetrics # a new pakage for torchmetrics\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "# pytorch dependent packages\n",
    "import timm # try using maxvit from torchvision it should be just as good if not better\n",
    "\n",
    "# sci-kit learn and scikit-image\n",
    "import sklearn\n",
    "import skimage\n",
    "\n",
    "# Dataset\n",
    "from torchvision.datasets import MNIST ######### not required\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# to describe model\n",
    "from torchvision.models.feature_extraction import get_graph_node_names, create_feature_extractor\n",
    "\n",
    "# number of CPUs\n",
    "# cpu_count = 0 if torch.cuda.is_available() else os.cpu_count()\n",
    "\n",
    "# use GPU tensor cores\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb5a33-290c-4449-8127-0a8a1ed4c6f0",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c28e3c-850d-48b6-8db9-3a8804e0c9ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# declaring the path of the train and test folders\n",
    "train_path = \"DATASET_C/TRAIN\"\n",
    "test_path = \"DATASET_C/TEST\"\n",
    "classes_dir_data = os.listdir(train_path)\n",
    "num_of_classes = len(classes_dir_data)\n",
    "print(\"Total Number of Classes :\" , num_of_classes)\n",
    "num = 0\n",
    "classes_dict = {}\n",
    "classes_lst = []\n",
    "num_dict = {}\n",
    "for c in  classes_dir_data:\n",
    "    classes_dict[c] = num\n",
    "    num_dict[num] = c\n",
    "    classes_lst.append(c)\n",
    "    num = num +1\n",
    "\"\"\"\n",
    "num_dict contains a dictionary of the classes numerically and it's corresponding classes.\n",
    "classes_dict contains a dictionary of the classes and the coresponding values numerically.\n",
    "\"\"\"\n",
    "num_of_classes = len(classes_dir_data)\n",
    "\n",
    "classes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9e722b-cda4-4956-a0c1-8eb31023f765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creating the dataset\n",
    "#dataset\n",
    "class Image_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self,classes,image_base_dir,transform = None, target_transform = None):\n",
    "        \"\"\"\n",
    "        classes:The classes in the dataset\n",
    "        image_base_dir:The directory of the folders containing the images\n",
    "        transform:The trasformations for the Images\n",
    "        Target_transform:The trasformations for the target\n",
    "        \"\"\"\n",
    "        self.img_labels = classes\n",
    "        self.imge_base_dir = image_base_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img_dir_list = os.listdir(os.path.join(self.imge_base_dir,self.img_labels[idx]))\n",
    "        image_path = img_dir_list[randint(0,len(img_dir_list)-1)]\n",
    "        #print(image_path)\n",
    "        image_path = os.path.join(self.imge_base_dir,self.img_labels[idx],image_path)\n",
    "        image = skimage.io.imread(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.transform:\n",
    "            label = self.target_transform(self.img_labels[idx])\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbe4b19-9805-40b4-a513-ea35715a0c64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "size = 224 # need to be the same as what is used in layer_5/ input layer ot the cnn\n",
    "\n",
    "basic_transformations = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((size,size)),\n",
    "        transforms.Grayscale(1),\n",
    "    transforms.ToTensor()])\n",
    "training_transformations = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((size,size)),\n",
    "    transforms.RandomRotation(degrees = 45),\n",
    "    transforms.RandomHorizontalFlip(p = 0.005),\n",
    "        transforms.Grayscale(1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def target_transformations(x):\n",
    "    return torch.tensor(classes_dict.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7539d3a5-ca4f-4ba3-a462-05875d4b9a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataModule(LightningDataModule):\n",
    "\n",
    "    def __init__(self):\n",
    "            super().__init__()            \n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.train = Image_Dataset(classes_dir_data,train_path,training_transformations,target_transformations)\n",
    "        self.valid = Image_Dataset(classes_dir_data,train_path,basic_transformations,target_transformations)\n",
    "        self.test = Image_Dataset(classes_dir_data,test_path,basic_transformations,target_transformations)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train,batch_size = 8,shuffle = True)#False, num_workers = cpu_count)\n",
    "\n",
    "    def val_dataloader(self):  \n",
    "        return DataLoader(self.valid,batch_size = 8,shuffle = True)#False, num_workers = cpu_count)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test,batch_size = 8,shuffle = True)#False, num_workers = cpu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eadea7-8c62-4c3f-93d6-ee1bf7b03494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# train_img_dataset = Image_Dataset(classes_dir_data,train_path,training_transformations,target_transformations)\n",
    "# train_loader_obj = DataLoader(train_img_dataset, batch_size = 8, shuffle = True)\n",
    "\n",
    "# # Display image and label.\n",
    "# train_features, train_labels = next(iter(train_loader_obj))\n",
    "# print(f\"Feature batch shape: {train_features.size()}\")\n",
    "# print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "# img = train_features[0].squeeze()\n",
    "# label = train_labels[0]\n",
    "# plt.imshow(img, cmap=\"gray\")\n",
    "# plt.show()\n",
    "# print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958c02c1-2355-4c2d-85e4-31a101fdf612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_img_dataset = Image_Dataset(classes_dir_data,test_path,basic_transformations,target_transformations)\n",
    "# test_loader_obj = DataLoader(test_img_dataset, batch_size = 8, shuffle = True)\n",
    "\n",
    "# # Display image and label.\n",
    "# train_features, train_labels = next(iter(test_loader_obj))\n",
    "# print(f\"Feature batch shape: {train_features.size()}\")\n",
    "# print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "# img = train_features[0].squeeze()\n",
    "# label = train_labels[0]\n",
    "# plt.imshow(img, cmap=\"gray\")\n",
    "# plt.show()\n",
    "# print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0e41f1-2dd9-481f-ae64-3bf0f7e1bbee",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a602fc-86b5-4dd1-a70a-a784bff9b1b9",
   "metadata": {},
   "source": [
    "Repalce layers with linear part of other model, then repalce with pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1816bdd2-4846-4dee-a595-190697564b38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyModel(LightningModule):\n",
    "\n",
    "    def __init__(self, classes_lst, input_shape, num_classes=10, acc_task=\"multiclass\", lr=1e-3, transfer=False): #input_shape=(3,224,224) image shape\n",
    "        super().__init__()\n",
    "        \n",
    "        # metrics\n",
    "        self.acc_task = acc_task\n",
    "        self.lr = lr\n",
    "        self.num_classes = num_classes\n",
    "        self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.num_classes)\n",
    "        self.class_names = classes_lst\n",
    "        self.loss = CrossEntropyLoss()\n",
    "        \n",
    "       # transfer learning if pretrained=True\n",
    "        self.feature_extractor = models.resnet18(pretrained=transfer)\n",
    "\n",
    "        if transfer:\n",
    "            # layers are frozen by using eval()\n",
    "            self.feature_extractor.eval()\n",
    "            # freeze params\n",
    "            for param in self.feature_extractor.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        n_sizes = self._get_conv_output(input_shape)\n",
    "\n",
    "        self.classifier = nn.Linear(n_sizes, num_classes)\n",
    "        \n",
    "    # returns the size of the output tensor going into the Linear layer from the conv block.\n",
    "    def _get_conv_output(self, shape):\n",
    "        batch_size = 1\n",
    "        tmp_input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "\n",
    "        output_feat = self._forward_features(tmp_input) \n",
    "        n_size = output_feat.data.view(batch_size, -1).size(1)\n",
    "        \n",
    "        return n_size\n",
    "        \n",
    "    # returns the feature tensor from the conv block\n",
    "    def _forward_features(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    # will be used during inference\n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "       \n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(),lr = self.lr)\n",
    "        return optimizer\n",
    "\n",
    "# The Pytorch-Lightning module handles all the iterations of the epoch\n",
    "\n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x,y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = F.cross_entropy(y_pred,y)\n",
    "        # Log training loss\n",
    "        self.log('train_loss', loss)\n",
    "        # Log metrics\n",
    "        self.log('train_acc', self.accuracy(y_pred, y))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
    "        # Log loss and metric\n",
    "        self.log('val_loss_alt', loss)\n",
    "        self.log('val_accuracy_alt', acc)\n",
    "        \n",
    "        x,y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = F.cross_entropy(y_pred,y)\n",
    "        # Log training loss\n",
    "        self.log('val_loss', loss)\n",
    "        # Log metrics\n",
    "        self.log('val_acc', self.accuracy(y_pred, y))\n",
    "        self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
    "        self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
    "        wandb.log({\"val_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
    "                        y_true=self.cpu_y, preds=None,\n",
    "                        class_names=self.class_names)})\n",
    "        return preds\n",
    "\n",
    "    def test_step(self,batch,batch_idx):\n",
    "        x,y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = F.cross_entropy(y_pred,y)\n",
    "        # Log training loss\n",
    "        self.log('test_loss', loss)\n",
    "        # Log metrics\n",
    "        self.log('test_acc', self.accuracy(y_pred, y))\n",
    "        self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
    "        self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
    "        wandb.log({\"test_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
    "                        y_true=self.cpu_y, preds=None,\n",
    "                        class_names=self.class_names)})\n",
    "        return loss\n",
    "    \n",
    "    def _get_preds_loss_accuracy(self, batch):\n",
    "        '''convenience function since train/valid/test steps are similar'''\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        loss = self.loss(logits, y)\n",
    "        acc = accuracy(preds, y, self.acc_task, num_classes=10)\n",
    "        return preds, loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f561a2e3-1272-4e67-9322-dd9b7534fed3",
   "metadata": {},
   "source": [
    "# Single training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ce4ef-e6b7-4320-8e5d-ceeb616bf7d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(monitor='val_acc', mode='max')\n",
    "\n",
    "class LogPredictionsCallback(Callback):\n",
    "    \n",
    "    def on_validation_batch_end(\n",
    "        self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):\n",
    "        \"\"\"Called when the validation batch ends.\"\"\"\n",
    " \n",
    "        # `outputs` comes from `LightningModule.validation_step`\n",
    "        # which corresponds to our model predictions in this case\n",
    "        \n",
    "        # Let's log 20 sample image predictions from first batch\n",
    "        if batch_idx == 0:\n",
    "            n = 20\n",
    "            x, y = batch\n",
    "            images = [img for img in x[:n]]\n",
    "            captions = [f'Ground Truth: {y_i} - Prediction: {y_pred}' for y_i, y_pred in zip(y[:n], outputs[:n])]\n",
    "            \n",
    "            # Option 1: log images with `WandbLogger.log_image`\n",
    "            wandb_logger.log_image(key='sample_images', images=images, caption=captions)\n",
    "\n",
    "            # Option 2: log predictions as a Table\n",
    "            columns = ['image', 'ground truth', 'prediction']\n",
    "            data = [[wandb.Image(x_i), y_i, y_pred] for x_i, y_i, y_pred in list(zip(x[:n], y[:n], outputs[:n]))]\n",
    "            wandb_logger.log_table(key='sample_table', columns=columns, data=data)\n",
    "\n",
    "log_predictions_callback = LogPredictionsCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762279ca-26d9-4310-992f-b6f8912da7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "wandb_logger = WandbLogger(project='computer_vision_test_single', log_model=True)\n",
    "\n",
    "# TRAIN\n",
    "# setup data\n",
    "# data = MNISTDataModule()\n",
    "data = DataModule()\n",
    "\n",
    "# setup model - choose different hyperparameters per experiment\n",
    "model = MyModel(classes_lst=classes_lst, num_classes=num_of_classes, input_shape=(3,224,224))\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator='gpu', \n",
    "    devices=-1, # use all GPU's (-1)\n",
    "    #callbacks=[log_predictions_callback, checkpoint_callbacks], # log_predictions_callback, checkpoint_callback\n",
    "    logger=wandb_logger,    # W&B integration\n",
    "    max_epochs=5            # number of epochs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c5995d-f9be-4377-bfc0-ea1298711b12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28625e66-e2a3-4a91-acce-e2948485412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, datamodule=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378d95e1-4e29-4c7f-bd8c-eaa16677a063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb_logger.experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91967e96-f127-4758-b427-c996a9fcb4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb_logger.experiment.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04c136e-5986-4628-88b7-38a8b433f654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.train_dataloader.dataset.data \n",
    "shape = train_iterator.dataset.data.shape  \n",
    "datatype = train_iterator.dataset.data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b58022d-6961-41b0-a4e1-60bbc1c09791",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d'd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8956e1be-a0ff-4f71-af46-2af5a8bca845",
   "metadata": {},
   "source": [
    "# Parameter tuning sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebde1018-ddfa-43f2-b9c6-f2c1d4b19736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"project\": \"computer_vision_test_sweep\",\n",
    "    \"method\": \"bayes\",   # Random search\n",
    "    \"metric\": {           # We want to maximize val_acc\n",
    "        \"name\": \"val_acc\",\n",
    "        \"goal\": \"maximize\"\n",
    "    },\n",
    "    \"run_cap\": 10, #terminates the sweep after a number of runs\n",
    "    \"early_terminate\": { # only terminates a run early not the sweep (reduces computation time)\n",
    "        \"type\": \"hyperband\",\n",
    "        \"min_iter\": 3\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        # \"n_layer_1\": {\n",
    "        #     # Choose from pre-defined values\n",
    "        #     \"values\": [32, 64, 128, 256, 512]\n",
    "        # },\n",
    "        # \"n_layer_2\": {\n",
    "        #     # Choose from pre-defined values\n",
    "        #     \"values\": [32, 64, 128, 256, 512, 1024]\n",
    "        # },\n",
    "        \"lr\": {\n",
    "            # log uniform distribution between exp(min) and exp(max)\n",
    "            \"distribution\": \"log_uniform\",\n",
    "            \"min\": -9.21,   # exp(-9.21) = 1e-4\n",
    "            \"max\": -4.61    # exp(-4.61) = 1e-2\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aeb8a0-9ffd-4439-808c-2951d1f74b36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sweep_iteration():\n",
    "    # set up W&B logger\n",
    "    wandb.init()    # required to have access to `wandb.config`\n",
    "    wandb_logger = WandbLogger(log_model='all')\n",
    "\n",
    "    # setup data\n",
    "    # data = MNISTDataModule()\n",
    "    data = DataModule()\n",
    "\n",
    "    # setup model - note how we refer to sweep parameters with wandb.config\n",
    "    # model = LitMNIST(\n",
    "    #     n_layer_1=wandb.config.n_layer_1,\n",
    "    #     n_layer_2=wandb.config.n_layer_2,\n",
    "    #     lr=wandb.config.lr\n",
    "    # )\n",
    "    model = MyModel(lr=wandb.config.lr, num_classes=num_of_classes)\n",
    "\n",
    "    # setup Trainer\n",
    "    trainer = Trainer(\n",
    "        logger=wandb_logger,    # W&B integration\n",
    "        gpus=-1,                # use all GPU's\n",
    "        max_epochs=100            # number of epochs\n",
    "        )\n",
    "\n",
    "    # train\n",
    "    trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b0393-21cf-4fba-8efd-7678a852b697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config)\n",
    "wandb.agent(sweep_id, function=sweep_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b049f934-e5e5-490d-87ab-d3c122a29dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87009dd-3c3a-409c-ada8-3f991d17d0c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class MyModel(pl.LightningModule):\n",
    "#     def __init__(self, input_shape, num_classes=10, lr=2e-4, transfer=False):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         # log hyperparameters\n",
    "#         self.save_hyperparameters()\n",
    "#         self.learning_rate = lr\n",
    "#         self.dim = input_shape\n",
    "#         self.num_classes = num_classes\n",
    "        \n",
    "#         # transfer learning if pretrained=True\n",
    "#         self.feature_extractor = models.resnet18(pretrained=transfer)\n",
    "\n",
    "#         if transfer:\n",
    "#             # layers are frozen by using eval()\n",
    "#             self.feature_extractor.eval()\n",
    "#             # freeze params\n",
    "#             for param in self.feature_extractor.parameters():\n",
    "#                 param.requires_grad = False\n",
    "        \n",
    "#         n_sizes = self._get_conv_output(input_shape)\n",
    "\n",
    "#         self.classifier = nn.Linear(n_sizes, num_classes)\n",
    "\n",
    "#         self.criterion = nn.CrossEntropyLoss()\n",
    "#         self.accuracy = Accuracy()\n",
    "  \n",
    "#     # returns the size of the output tensor going into the Linear layer from the conv block.\n",
    "#     def _get_conv_output(self, shape):\n",
    "#         batch_size = 1\n",
    "#         tmp_input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "\n",
    "#         output_feat = self._forward_features(tmp_input) \n",
    "#         n_size = output_feat.data.view(batch_size, -1).size(1)\n",
    "#         return n_size\n",
    "        \n",
    "#     # returns the feature tensor from the conv block\n",
    "#     def _forward_features(self, x):\n",
    "#         x = self.feature_extractor(x)\n",
    "#         return x\n",
    "    \n",
    "#     # will be used during inference\n",
    "#     def forward(self, x):\n",
    "#         x = self._forward_features(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.classifier(x)\n",
    "\n",
    "#         return x\n",
    "    \n",
    "#     def training_step(self, batch):\n",
    "#         batch, gt = batch[0], batch[1]\n",
    "#         out = self.forward(batch)\n",
    "#         loss = self.criterion(out, gt)\n",
    "\n",
    "#         acc = self.accuracy(out, gt)\n",
    "\n",
    "#         self.log(\"train/loss\", loss)\n",
    "#         self.log(\"train/acc\", acc)\n",
    "\n",
    "#         return loss\n",
    "    \n",
    "#     def validation_step(self, batch, batch_idx):\n",
    "#         batch, gt = batch[0], batch[1]\n",
    "#         out = self.forward(batch)\n",
    "#         loss = self.criterion(out, gt)\n",
    "\n",
    "#         self.log(\"val/loss\", loss)\n",
    "\n",
    "#         acc = self.accuracy(out, gt)\n",
    "#         self.log(\"val/acc\", acc)\n",
    "\n",
    "#         return loss\n",
    "    \n",
    "#     def test_step(self, batch, batch_idx):\n",
    "#         batch, gt = batch[0], batch[1]\n",
    "#         out = self.forward(batch)\n",
    "#         loss = self.criterion(out, gt)\n",
    "        \n",
    "#         return {\"loss\": loss, \"outputs\": out, \"gt\": gt}\n",
    "    \n",
    "#     def test_epoch_end(self, outputs):\n",
    "#         loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "#         output = torch.cat([x['outputs'] for x in outputs], dim=0)\n",
    "        \n",
    "#         gts = torch.cat([x['gt'] for x in outputs], dim=0)\n",
    "        \n",
    "#         self.log(\"test/loss\", loss)\n",
    "#         acc = self.accuracy(output, gts)\n",
    "#         self.log(\"test/acc\", acc)\n",
    "        \n",
    "#         self.test_gts = gts\n",
    "#         self.test_output = output\n",
    "    \n",
    "#     def configure_optimizers(self):\n",
    "#         return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb34aed-792a-4022-a878-f8d6c4ffa97c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class MyModel(LightningModule):\n",
    "\n",
    "#     def __init__(self, classes_lst, num_classes=10, acc_task=\"multiclass\", lr=1e-3):\n",
    "#         super().__init__()\n",
    "        \n",
    "        \n",
    "#         \"\"\"\n",
    "#         The convolutions are arranged in such a way that the image maintain the x and y dimensions. only the channels change\n",
    "#         \"\"\"\n",
    "#         self.layer_1 = nn.Conv2d(in_channels = 1,out_channels = 3,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
    "#         self.layer_2 = nn.Conv2d(in_channels = 3,out_channels = 6,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
    "#         self.layer_3 = nn.Conv2d(in_channels = 6,out_channels = 12,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
    "#         self.pool = nn.MaxPool2d(kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
    "#         self.layer_5 = nn.Linear(12*50*50,1000)#the input dimensions are (Number of dimensions * height * width)\n",
    "#         self.layer_6 = nn.Linear(1000,100)\n",
    "#         self.layer_7 = nn.Linear(100,50)\n",
    "#         self.layer_8 = nn.Linear(50,10)\n",
    "#         self.layer_9 = nn.Linear(10,10)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         # metrics\n",
    "#         self.acc_task = acc_task\n",
    "#         self.lr = lr\n",
    "#         self.num_classes = num_classes\n",
    "#         self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.num_classes)\n",
    "#         self.class_names = classes_lst\n",
    "#         self.loss = CrossEntropyLoss()\n",
    "\n",
    "#         # optional - save hyper-parameters to self.hparams\n",
    "#         # they will also be automatically logged as config parameters in W&B\n",
    "#         self.save_hyperparameters()\n",
    "\n",
    "#     def forward(self,x):\n",
    "#         \"\"\"\n",
    "#         x is the input data\n",
    "#         \"\"\"\n",
    "#         x = self.layer_1(x)\n",
    "#         x = self.pool(x)\n",
    "#         x = self.layer_2(x)\n",
    "#         x = self.pool(x)\n",
    "#         x = self.layer_3(x)\n",
    "#         x = self.pool(x)\n",
    "#         x = x.view(x.size(0),-1)\n",
    "#         print(x.size())\n",
    "#         x = self.layer_5(x)\n",
    "#         x = self.layer_6(x)\n",
    "#         x = self.layer_7(x)\n",
    "#         x = self.layer_8(x)\n",
    "#         x = self.layer_9(x)\n",
    "#         return x\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         optimizer = torch.optim.Adam(self.parameters(),lr = self.lr)\n",
    "#         return optimizer\n",
    "\n",
    "# # The Pytorch-Lightning module handles all the iterations of the epoch\n",
    "\n",
    "#     def training_step(self,batch,batch_idx):\n",
    "#         x,y = batch\n",
    "#         y_pred = self(x)\n",
    "#         loss = F.cross_entropy(y_pred,y)\n",
    "#         # Log training loss\n",
    "#         self.log('train_loss', loss)\n",
    "#         # Log metrics\n",
    "#         self.log('train_acc', self.accuracy(y_pred, y))\n",
    "#         return loss\n",
    "\n",
    "#     def validation_step(self,batch,batch_idx):\n",
    "#         preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
    "#         # Log loss and metric\n",
    "#         self.log('val_loss_alt', loss)\n",
    "#         self.log('val_accuracy_alt', acc)\n",
    "        \n",
    "#         x,y = batch\n",
    "#         y_pred = self(x)\n",
    "#         loss = F.cross_entropy(y_pred,y)\n",
    "#         # Log training loss\n",
    "#         self.log('val_loss', loss)\n",
    "#         # Log metrics\n",
    "#         self.log('val_acc', self.accuracy(y_pred, y))\n",
    "#         self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
    "#         self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
    "#         wandb.log({\"val_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
    "#                         y_true=self.cpu_y, preds=None,\n",
    "#                         class_names=self.class_names)})\n",
    "#         return preds\n",
    "\n",
    "#     def test_step(self,batch,batch_idx):\n",
    "#         x,y = batch\n",
    "#         y_pred = self(x)\n",
    "#         loss = F.cross_entropy(y_pred,y)\n",
    "#         # Log training loss\n",
    "#         self.log('test_loss', loss)\n",
    "#         # Log metrics\n",
    "#         self.log('test_acc', self.accuracy(y_pred, y))\n",
    "#         self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
    "#         self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
    "#         wandb.log({\"test_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
    "#                         y_true=self.cpu_y, preds=None,\n",
    "#                         class_names=self.class_names)})\n",
    "#         return loss\n",
    "    \n",
    "#     def _get_preds_loss_accuracy(self, batch):\n",
    "#         '''convenience function since train/valid/test steps are similar'''\n",
    "#         x, y = batch\n",
    "#         logits = self(x)\n",
    "#         preds = torch.argmax(logits, dim=1)\n",
    "#         loss = self.loss(logits, y)\n",
    "#         acc = accuracy(preds, y, self.acc_task, num_classes=10)\n",
    "#         return preds, loss, acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
