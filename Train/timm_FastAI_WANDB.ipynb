{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "436f1771-7aa6-45e7-abae-56c8112da143",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T17:03:52.351536Z",
     "iopub.status.busy": "2023-03-09T17:03:52.351536Z",
     "iopub.status.idle": "2023-03-09T17:03:57.156787Z",
     "shell.execute_reply": "2023-03-09T17:03:57.155788Z",
     "shell.execute_reply.started": "2023-03-09T17:03:52.351536Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a8980b5-f22c-4e50-bb9f-8ade0c9583cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T17:03:57.158793Z",
     "iopub.status.busy": "2023-03-09T17:03:57.158793Z",
     "iopub.status.idle": "2023-03-09T17:03:57.172789Z",
     "shell.execute_reply": "2023-03-09T17:03:57.171788Z",
     "shell.execute_reply.started": "2023-03-09T17:03:57.158793Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.15dev0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce6dcd5a-212a-4a26-ab87-8ab81952aec4",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-03-09T17:06:06.091074Z",
     "iopub.status.busy": "2023-03-09T17:06:06.091074Z",
     "iopub.status.idle": "2023-03-09T17:37:25.330060Z",
     "shell.execute_reply": "2023-03-09T17:37:25.329053Z",
     "shell.execute_reply.started": "2023-03-09T17:06:06.091074Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6028ebec30904d63a0b5577fa37e86e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)\"pytorch_model.bin\";:   0%|          | 0.00/1.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MaxxVit(\n",
       "  (stem): Stem(\n",
       "    (conv1): Conv2dSame(3, 192, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (norm1): BatchNormAct2d(\n",
       "      192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): GELUTanh()\n",
       "    )\n",
       "    (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (stages): Sequential(\n",
       "    (0): MaxxVitStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Downsample2d(\n",
       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "              (expand): Identity()\n",
       "            )\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2dSame(768, 768, kernel_size=(3, 3), stride=(2, 2), groups=768, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): MaxxVitStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Downsample2d(\n",
       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "              (expand): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(192, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2dSame(1536, 1536, kernel_size=(3, 3), stride=(2, 2), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (2): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (3): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (4): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (5): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): MaxxVitStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Downsample2d(\n",
       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "              (expand): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(384, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2dSame(3072, 3072, kernel_size=(3, 3), stride=(2, 2), groups=3072, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (2): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (3): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (4): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (5): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (6): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (7): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (8): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (9): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (10): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (11): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (12): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (13): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): MaxxVitStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Downsample2d(\n",
       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "              (expand): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(768, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2dSame(6144, 6144, kernel_size=(3, 3), stride=(2, 2), groups=6144, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(6144, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(384, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): MaxxVitBlock(\n",
       "          (conv): MbConvBlock(\n",
       "            (shortcut): Identity()\n",
       "            (pre_norm): BatchNormAct2d(\n",
       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (down): Identity()\n",
       "            (conv1_1x1): Conv2d(1536, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): BatchNormAct2d(\n",
       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (conv2_kxk): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6144, bias=False)\n",
       "            (norm2): BatchNormAct2d(\n",
       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): GELUTanh()\n",
       "            )\n",
       "            (se): SEModule(\n",
       "              (fc1): Conv2d(6144, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "              (fc2): Conv2d(384, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv3_1x1): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (attn_block): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (attn_grid): PartitionAttentionCl(\n",
       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): AttentionCl(\n",
       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "              (rel_pos): RelPosBiasTf()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "              (act): GELUTanh()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): Identity()\n",
       "  (head): NormMlpClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
       "    (norm): LayerNorm2d((1536,), eps=1e-05, elementwise_affine=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (pre_logits): Sequential(\n",
       "      (fc): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "      (act): Tanh()\n",
       "    )\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Linear(in_features=1536, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.create_model(\"maxvit_xlarge_tf_512.in21k_ft_in1k\", pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af673a5e-c94b-4ff2-ad5a-af508a10ca18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T17:46:56.585226Z",
     "iopub.status.busy": "2023-03-09T17:46:56.585226Z",
     "iopub.status.idle": "2023-03-09T17:47:24.408985Z",
     "shell.execute_reply": "2023-03-09T17:47:24.407985Z",
     "shell.execute_reply.started": "2023-03-09T17:46:56.585226Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m transforms \u001b[38;5;241m=\u001b[39m timm\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcreate_transform(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata_config, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m output \u001b[38;5;241m=\u001b[39m model(transforms(img)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))  \u001b[38;5;66;03m# unsqueeze single image into batch of 1\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m top5_probabilities, top5_class_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mtopk(output\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "img = Image.open(\n",
    "    urlopen('https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'))\n",
    "\n",
    "model = timm.create_model('maxvit_xlarge_tf_512.in21k_ft_in1k', pretrained=True) # hf-hub:timm/\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "top5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56818f26-f610-4fe1-89a0-450d6c5e93b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-09T17:04:02.134887Z",
     "iopub.status.busy": "2023-03-09T17:04:02.134887Z",
     "iopub.status.idle": "2023-03-09T17:04:02.159457Z",
     "shell.execute_reply": "2023-03-09T17:04:02.158456Z",
     "shell.execute_reply.started": "2023-03-09T17:04:02.134887Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maxvit_base_tf_224.in1k',\n",
       " 'maxvit_base_tf_384.in1k',\n",
       " 'maxvit_base_tf_384.in21k_ft_in1k',\n",
       " 'maxvit_base_tf_512.in1k',\n",
       " 'maxvit_base_tf_512.in21k_ft_in1k',\n",
       " 'maxvit_large_tf_224.in1k',\n",
       " 'maxvit_large_tf_384.in1k',\n",
       " 'maxvit_large_tf_384.in21k_ft_in1k',\n",
       " 'maxvit_large_tf_512.in1k',\n",
       " 'maxvit_large_tf_512.in21k_ft_in1k',\n",
       " 'maxvit_nano_rw_256.sw_in1k',\n",
       " 'maxvit_rmlp_base_rw_224.sw_in12k',\n",
       " 'maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k',\n",
       " 'maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k',\n",
       " 'maxvit_rmlp_nano_rw_256.sw_in1k',\n",
       " 'maxvit_rmlp_pico_rw_256.sw_in1k',\n",
       " 'maxvit_rmlp_small_rw_224.sw_in1k',\n",
       " 'maxvit_rmlp_tiny_rw_256.sw_in1k',\n",
       " 'maxvit_small_tf_224.in1k',\n",
       " 'maxvit_small_tf_384.in1k',\n",
       " 'maxvit_small_tf_512.in1k',\n",
       " 'maxvit_tiny_rw_224.sw_in1k',\n",
       " 'maxvit_tiny_tf_224.in1k',\n",
       " 'maxvit_tiny_tf_384.in1k',\n",
       " 'maxvit_tiny_tf_512.in1k',\n",
       " 'maxvit_xlarge_tf_384.in21k_ft_in1k',\n",
       " 'maxvit_xlarge_tf_512.in21k_ft_in1k',\n",
       " 'maxxvit_rmlp_nano_rw_256.sw_in1k',\n",
       " 'maxxvit_rmlp_small_rw_256.sw_in1k',\n",
       " 'maxxvitv2_nano_rw_256.sw_in1k',\n",
       " 'maxxvitv2_rmlp_base_rw_224.sw_in12k',\n",
       " 'maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k',\n",
       " 'maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models('*max*', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1e36e7-6131-4ad7-a7cc-3e825b391108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "\n",
    "def get_pets(batch_size, img_size, seed):\n",
    "    \"The dog breeds pets datasets\"\n",
    "    dataset_path = untar_data(URLs.PETS)\n",
    "    files = get_image_files(dataset_path/\"images\")\n",
    "    dls = ImageDataLoaders.from_name_re(dataset_path, files, \n",
    "                                        pat=r'(^[a-zA-Z]+_*[a-zA-Z]+)', \n",
    "                                        valid_pct=0.2, \n",
    "                                        seed=seed, \n",
    "                                        bs=batch_size,\n",
    "                                        item_tfms=Resize(img_size)) \n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c79cc5-2685-4d40-8b07-7a79e00ade9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SimpleNamespace(\n",
    "    batch_size=64,\n",
    "    img_size=224,\n",
    "    seed=42,\n",
    "    pretrained=False,\n",
    "    model_name=\"regnetx_040\",\n",
    "    epochs=5)\n",
    "\n",
    "\n",
    "def train(config):\n",
    "    \"Train the model using the supplied config\"\n",
    "    dls = get_pets(config.batch_size, config.img_size, config.seed)\n",
    "    with wandb.init(project=PROJECT, group=GROUP, job_type=JOB_TYPE, config=config):\n",
    "        cbs = [MixedPrecision(), WandbCallback(log_preds=False)]\n",
    "        learn = vision_learner(dls, config.model_name, metrics=error_rate, \n",
    "                               cbs=cbs, pretrained=config.pretrained)\n",
    "        learn.fine_tune(config.epochs)\n",
    "\n",
    "\n",
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450bfc9b-6527-41e0-803b-633e82230dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_planets(batch_size=64, img_size=224, seed=42):\n",
    "    \"A sample of the planets dataset\"\n",
    "    dataset_path=untar_data(URLs.PLANET_SAMPLE)\n",
    "    dls = ImageDataLoaders.from_csv(dataset_path, \n",
    "                                    folder=\"train\", \n",
    "                                    csv_fname=\"labels.csv\",\n",
    "                                    label_delim=\" \",\n",
    "                                    suff=\".jpg\",\n",
    "                                    bs=batch_size,\n",
    "                                    seed=seed,\n",
    "                                    item_tfms=Resize(img_size))\n",
    "    return dls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
