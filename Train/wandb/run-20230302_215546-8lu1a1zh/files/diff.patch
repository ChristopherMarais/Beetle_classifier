diff --git a/Train/.ipynb_checkpoints/PyLi_wanb_sweep_CoatNet-checkpoint.ipynb b/Train/.ipynb_checkpoints/PyLi_wanb_sweep_CoatNet-checkpoint.ipynb
index ced9a67..cdc42c8 100644
--- a/Train/.ipynb_checkpoints/PyLi_wanb_sweep_CoatNet-checkpoint.ipynb
+++ b/Train/.ipynb_checkpoints/PyLi_wanb_sweep_CoatNet-checkpoint.ipynb
@@ -6,11 +6,11 @@
    "id": "c7b471f1-f5fa-4eb1-b9ae-2d67ed8838df",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:16.271323Z",
-     "iopub.status.busy": "2023-03-01T20:56:16.271323Z",
-     "iopub.status.idle": "2023-03-01T20:56:20.861826Z",
-     "shell.execute_reply": "2023-03-01T20:56:20.860831Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:16.271323Z"
+     "iopub.execute_input": "2023-03-03T02:50:41.830495Z",
+     "iopub.status.busy": "2023-03-03T02:50:41.829998Z",
+     "iopub.status.idle": "2023-03-03T02:50:46.465147Z",
+     "shell.execute_reply": "2023-03-03T02:50:46.464144Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:41.830495Z"
     },
     "tags": []
    },
@@ -26,13 +26,14 @@
     "\n",
     "# Pytorch modules\n",
     "import torch\n",
-    "from torch.nn import functional as F\n",
+    "from torch.nn import Linear, CrossEntropyLoss, functional as F\n",
     "from torch import nn\n",
     "from torch.optim import Adam\n",
     "from torch.utils.data import DataLoader, random_split, Dataset\n",
     "\n",
     "# Pytorch-Lightning\n",
     "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
+    "from pytorch_lightning.callbacks import ModelCheckpoint, Callback\n",
     "import pytorch_lightning as pl\n",
     "from pytorch_lightning.loggers import WandbLogger\n",
     "import torchmetrics # a new pakage for torchmetrics\n",
@@ -59,71 +60,6 @@
     "torch.set_float32_matmul_precision('high')"
    ]
   },
-  {
-   "cell_type": "code",
-   "execution_count": 2,
-   "id": "289e69f9-9a23-4f33-94af-a8950f9e1818",
-   "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:20.862838Z",
-     "iopub.status.busy": "2023-03-01T20:56:20.862838Z",
-     "iopub.status.idle": "2023-03-01T20:56:20.876388Z",
-     "shell.execute_reply": "2023-03-01T20:56:20.876388Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:20.862838Z"
-    },
-    "tags": []
-   },
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "['coatnet_0_rw_224',\n",
-       " 'coatnet_1_rw_224',\n",
-       " 'coatnet_bn_0_rw_224',\n",
-       " 'coatnet_nano_rw_224',\n",
-       " 'coatnet_rmlp_1_rw_224',\n",
-       " 'coatnet_rmlp_2_rw_224',\n",
-       " 'coatnet_rmlp_nano_rw_224']"
-      ]
-     },
-     "execution_count": 2,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "timm.list_models('*coatnet*', pretrained=True)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 3,
-   "id": "5fc60314-d2bb-4767-9cef-219da9f1955d",
-   "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:20.879932Z",
-     "iopub.status.busy": "2023-03-01T20:56:20.879932Z",
-     "iopub.status.idle": "2023-03-01T20:56:20.893218Z",
-     "shell.execute_reply": "2023-03-01T20:56:20.891688Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:20.879932Z"
-    },
-    "tags": []
-   },
-   "outputs": [],
-   "source": [
-    "# # load model\n",
-    "# model = timm.create_model('coatnet_rmlp_2_rw_224', pretrained=True, exportable=True, num_classes=10)\n",
-    "\n",
-    "# # see the output head shape\n",
-    "# clsfr_shape = model.get_classifier()\n",
-    "\n",
-    "# # get all node names\n",
-    "# nodes,_ = get_graph_node_names(model)\n",
-    "\n",
-    "# # get all layers\n",
-    "# modules = list(model.modules())"
-   ]
-  },
   {
    "cell_type": "markdown",
    "id": "2aeb5a33-290c-4449-8127-0a8a1ed4c6f0",
@@ -134,15 +70,15 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": 2,
    "id": "01c28e3c-850d-48b6-8db9-3a8804e0c9ae",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:20.895234Z",
-     "iopub.status.busy": "2023-03-01T20:56:20.894231Z",
-     "iopub.status.idle": "2023-03-01T20:56:20.908832Z",
-     "shell.execute_reply": "2023-03-01T20:56:20.907873Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:20.895234Z"
+     "iopub.execute_input": "2023-03-03T02:50:46.467648Z",
+     "iopub.status.busy": "2023-03-03T02:50:46.466648Z",
+     "iopub.status.idle": "2023-03-03T02:50:46.496649Z",
+     "shell.execute_reply": "2023-03-03T02:50:46.495147Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:46.467648Z"
     },
     "tags": []
    },
@@ -169,7 +105,7 @@
        " '9': 9}"
       ]
      },
-     "execution_count": 4,
+     "execution_count": 2,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -201,15 +137,15 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 3,
    "id": "8b9e722b-cda4-4956-a0c1-8eb31023f765",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:20.909835Z",
-     "iopub.status.busy": "2023-03-01T20:56:20.909835Z",
-     "iopub.status.idle": "2023-03-01T20:56:20.924555Z",
-     "shell.execute_reply": "2023-03-01T20:56:20.923617Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:20.909835Z"
+     "iopub.execute_input": "2023-03-03T02:50:46.501146Z",
+     "iopub.status.busy": "2023-03-03T02:50:46.500150Z",
+     "iopub.status.idle": "2023-03-03T02:50:46.589144Z",
+     "shell.execute_reply": "2023-03-03T02:50:46.588143Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:46.501146Z"
     },
     "tags": []
    },
@@ -272,15 +208,15 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
+   "execution_count": 4,
    "id": "9dbe4b19-9805-40b4-a513-ea35715a0c64",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:20.926555Z",
-     "iopub.status.busy": "2023-03-01T20:56:20.926555Z",
-     "iopub.status.idle": "2023-03-01T20:56:20.940645Z",
-     "shell.execute_reply": "2023-03-01T20:56:20.939643Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:20.926555Z"
+     "iopub.execute_input": "2023-03-03T02:50:46.591150Z",
+     "iopub.status.busy": "2023-03-03T02:50:46.590648Z",
+     "iopub.status.idle": "2023-03-03T02:50:46.681600Z",
+     "shell.execute_reply": "2023-03-03T02:50:46.680594Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:46.591150Z"
     },
     "tags": []
    },
@@ -308,21 +244,21 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 7,
+   "execution_count": 5,
    "id": "7539d3a5-ca4f-4ba3-a462-05875d4b9a90",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:20.942648Z",
-     "iopub.status.busy": "2023-03-01T20:56:20.942648Z",
-     "iopub.status.idle": "2023-03-01T20:56:20.957018Z",
-     "shell.execute_reply": "2023-03-01T20:56:20.955693Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:20.942648Z"
+     "iopub.execute_input": "2023-03-03T02:50:46.683595Z",
+     "iopub.status.busy": "2023-03-03T02:50:46.683098Z",
+     "iopub.status.idle": "2023-03-03T02:50:46.774193Z",
+     "shell.execute_reply": "2023-03-03T02:50:46.773192Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:46.683595Z"
     },
     "tags": []
    },
    "outputs": [],
    "source": [
-    "class YogaDataModule(pl.LightningDataModule):\n",
+    "class DataModule(LightningDataModule):\n",
     "\n",
     "    def __init__(self):\n",
     "            super().__init__()            \n",
@@ -352,116 +288,21 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
-   "id": "40361447-e7c3-47f2-9e04-a9058b596861",
-   "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:20.959403Z",
-     "iopub.status.busy": "2023-03-01T20:56:20.959403Z",
-     "iopub.status.idle": "2023-03-01T20:56:20.988223Z",
-     "shell.execute_reply": "2023-03-01T20:56:20.987711Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:20.959403Z"
-    },
-    "tags": []
-   },
-   "outputs": [],
-   "source": [
-    "class LitMNIST(LightningModule):\n",
-    "\n",
-    "    def __init__(self, n_classes=10, acc_task=\"multiclass\", n_layer_1=128, n_layer_2=256, lr=1e-3):\n",
-    "        '''method used to define our model parameters'''\n",
-    "        super().__init__()\n",
-    "        # mnist images are (1, 28, 28) (channels, width, height)\n",
-    "        self.layer_1 = torch.nn.Linear(28 * 28, n_layer_1)\n",
-    "        self.layer_2 = torch.nn.Linear(n_layer_1, n_layer_2)\n",
-    "        self.layer_3 = torch.nn.Linear(n_layer_2, n_classes)\n",
-    "        # optimizer parameters\n",
-    "        self.lr = lr\n",
-    "        # metrics\n",
-    "        self.acc_task = acc_task\n",
-    "        self.n_classes = n_classes\n",
-    "        self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.n_classes)\n",
-    "        self.class_names = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
-    "        # optional - save hyper-parameters to self.hparams\n",
-    "        # they will also be automatically logged as config parameters in W&B\n",
-    "        self.save_hyperparameters()\n",
-    "\n",
-    "    def forward(self, x):\n",
-    "        '''method used for inference input -> output'''\n",
-    "        batch_size, channels, width, height = x.size()\n",
-    "        # (b, 1, 28, 28) -> (b, 1*28*28)\n",
-    "        x = x.view(batch_size, -1)\n",
-    "        x = self.layer_1(x)\n",
-    "        x = F.relu(x)\n",
-    "        x = self.layer_2(x)\n",
-    "        x = F.relu(x)\n",
-    "        x = self.layer_3(x)\n",
-    "        x = F.log_softmax(x, dim=1)\n",
-    "        return x\n",
-    "\n",
-    "    def training_step(self, batch, batch_idx):\n",
-    "        '''needs to return a loss from a single batch'''\n",
-    "        x, y = batch\n",
-    "        logits = self(x)\n",
-    "        loss = F.nll_loss(logits, y)\n",
-    "        # Log training loss\n",
-    "        self.log('train_loss', loss)\n",
-    "        # Log metrics\n",
-    "        self.log('train_acc', self.accuracy(logits, y))\n",
-    "        return loss\n",
-    "\n",
-    "    def validation_step(self, batch, batch_idx):\n",
-    "        '''used for logging metrics'''\n",
-    "        x, y = batch\n",
-    "        logits = self(x)\n",
-    "        loss = F.nll_loss(logits, y)\n",
-    "        # Log validation loss (will be automatically averaged over an epoch)\n",
-    "        self.log('valid_loss', loss)\n",
-    "        # Log metrics\n",
-    "        self.log('valid_acc', self.accuracy(logits, y))\n",
-    "        self.cpu_logits = logits.to(\"cpu\").detach().numpy()\n",
-    "        self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
-    "        wandb.log({\"valid_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_logits,\n",
-    "                        y_true=self.cpu_y, preds=None,\n",
-    "                        class_names=self.class_names)})\n",
-    "\n",
-    "    def test_step(self, batch, batch_idx):\n",
-    "        '''used for logging metrics'''\n",
-    "        x, y = batch\n",
-    "        logits = self(x)\n",
-    "        loss = F.nll_loss(logits, y)\n",
-    "        # Log test loss\n",
-    "        self.log('test_loss', loss)\n",
-    "        # Log metrics\n",
-    "        self.log('test_acc', self.accuracy(logits, y))\n",
-    "        self.cpu_logits = logits.to(\"cpu\").detach().numpy()\n",
-    "        self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
-    "        wandb.log({\"test_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_logits,\n",
-    "                        y_true=self.cpu_y, preds=None,\n",
-    "                        class_names=self.class_names)})\n",
-    "    \n",
-    "    def configure_optimizers(self):\n",
-    "        '''defines model optimizer'''\n",
-    "        return Adam(self.parameters(), lr=self.lr)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 6,
    "id": "deb34aed-792a-4022-a878-f8d6c4ffa97c",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:20.989234Z",
-     "iopub.status.busy": "2023-03-01T20:56:20.989234Z",
-     "iopub.status.idle": "2023-03-01T20:56:21.019858Z",
-     "shell.execute_reply": "2023-03-01T20:56:21.018856Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:20.989234Z"
+     "iopub.execute_input": "2023-03-03T02:50:46.775693Z",
+     "iopub.status.busy": "2023-03-03T02:50:46.775195Z",
+     "iopub.status.idle": "2023-03-03T02:50:46.882206Z",
+     "shell.execute_reply": "2023-03-03T02:50:46.881203Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:46.775195Z"
     },
     "tags": []
    },
    "outputs": [],
    "source": [
-    "class YogaModel(LightningModule):\n",
+    "class MyModel(LightningModule):\n",
     "\n",
     "    def __init__(self, n_classes=10, acc_task=\"multiclass\", lr=1e-3):\n",
     "        super().__init__()\n",
@@ -483,6 +324,8 @@
     "        self.n_classes = n_classes\n",
     "        self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.n_classes)\n",
     "        self.class_names = classes_lst\n",
+    "        self.loss = CrossEntropyLoss()\n",
+    "\n",
     "        # optional - save hyper-parameters to self.hparams\n",
     "        # they will also be automatically logged as config parameters in W&B\n",
     "        self.save_hyperparameters()\n",
@@ -523,6 +366,11 @@
     "        return loss\n",
     "\n",
     "    def validation_step(self,batch,batch_idx):\n",
+    "        preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
+    "        # Log loss and metric\n",
+    "        self.log('val_loss_alt', loss)\n",
+    "        self.log('val_accuracy_alt', acc)\n",
+    "        \n",
     "        x,y = batch\n",
     "        y_pred = self(x)\n",
     "        loss = F.cross_entropy(y_pred,y)\n",
@@ -535,7 +383,7 @@
     "        wandb.log({\"val_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
     "                        y_true=self.cpu_y, preds=None,\n",
     "                        class_names=self.class_names)})\n",
-    "        return loss\n",
+    "        return preds\n",
     "\n",
     "    def test_step(self,batch,batch_idx):\n",
     "        x,y = batch\n",
@@ -550,7 +398,16 @@
     "        wandb.log({\"test_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
     "                        y_true=self.cpu_y, preds=None,\n",
     "                        class_names=self.class_names)})\n",
-    "        return loss"
+    "        return loss\n",
+    "    \n",
+    "    def _get_preds_loss_accuracy(self, batch):\n",
+    "        '''convenience function since train/valid/test steps are similar'''\n",
+    "        x, y = batch\n",
+    "        logits = self(x)\n",
+    "        preds = torch.argmax(logits, dim=1)\n",
+    "        loss = self.loss(logits, y)\n",
+    "        acc = accuracy(preds, y, self.acc_task, num_classes=10)\n",
+    "        return preds, loss, acc"
    ]
   },
   {
@@ -563,43 +420,22 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
-   "id": "e2170c95-2962-43ec-a457-31dfec8a23d2",
-   "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:21.023110Z",
-     "iopub.status.busy": "2023-03-01T20:56:21.022116Z",
-     "iopub.status.idle": "2023-03-01T20:56:21.035162Z",
-     "shell.execute_reply": "2023-03-01T20:56:21.034159Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:21.023110Z"
-    },
-    "tags": []
-   },
-   "outputs": [],
-   "source": [
-    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
-    "\n",
-    "checkpoint_callback = ModelCheckpoint(monitor='val_acc', mode='max')"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 11,
+   "execution_count": 8,
    "id": "188ce4ef-e6b7-4320-8e5d-ceeb616bf7d1",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:21.037696Z",
-     "iopub.status.busy": "2023-03-01T20:56:21.036175Z",
-     "iopub.status.idle": "2023-03-01T20:56:21.050772Z",
-     "shell.execute_reply": "2023-03-01T20:56:21.049776Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:21.037696Z"
+     "iopub.execute_input": "2023-03-03T02:50:46.977734Z",
+     "iopub.status.busy": "2023-03-03T02:50:46.977233Z",
+     "iopub.status.idle": "2023-03-03T02:50:47.067951Z",
+     "shell.execute_reply": "2023-03-03T02:50:47.066950Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:46.977734Z"
     },
     "tags": []
    },
    "outputs": [],
    "source": [
-    "from pytorch_lightning.callbacks import Callback\n",
-    " \n",
+    "checkpoint_callback = ModelCheckpoint(monitor='val_acc', mode='max')\n",
+    "\n",
     "class LogPredictionsCallback(Callback):\n",
     "    \n",
     "    def on_validation_batch_end(\n",
@@ -629,15 +465,15 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 12,
+   "execution_count": 9,
    "id": "762279ca-26d9-4310-992f-b6f8912da7fe",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:21.054045Z",
-     "iopub.status.busy": "2023-03-01T20:56:21.054045Z",
-     "iopub.status.idle": "2023-03-01T20:56:29.581762Z",
-     "shell.execute_reply": "2023-03-01T20:56:29.580856Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:21.054045Z"
+     "iopub.execute_input": "2023-03-03T02:50:47.069450Z",
+     "iopub.status.busy": "2023-03-03T02:50:47.068953Z",
+     "iopub.status.idle": "2023-03-03T02:50:56.878820Z",
+     "shell.execute_reply": "2023-03-03T02:50:56.874823Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:47.069450Z"
     },
     "tags": []
    },
@@ -664,7 +500,7 @@
     {
      "data": {
       "text/html": [
-       "Run data is saved locally in <code>.\\wandb\\run-20230301_155623-r20dbs67</code>"
+       "Run data is saved locally in <code>.\\wandb\\run-20230302_215050-shiyc5fc</code>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -676,7 +512,7 @@
     {
      "data": {
       "text/html": [
-       "Syncing run <strong><a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/r20dbs67' target=\"_blank\">tough-meadow-4</a></strong> to <a href='https://wandb.ai/christopher-marais/computer_vision_test_single' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
+       "Syncing run <strong><a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/shiyc5fc' target=\"_blank\">deep-wind-12</a></strong> to <a href='https://wandb.ai/christopher-marais/computer_vision_test_single' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -700,7 +536,7 @@
     {
      "data": {
       "text/html": [
-       " View run at <a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/r20dbs67' target=\"_blank\">https://wandb.ai/christopher-marais/computer_vision_test_single/runs/r20dbs67</a>"
+       " View run at <a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/shiyc5fc' target=\"_blank\">https://wandb.ai/christopher-marais/computer_vision_test_single/runs/shiyc5fc</a>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -719,19 +555,20 @@
       "HPU available: False, using: 0 HPUs\n",
       "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
       "\n",
-      "  | Name     | Type               | Params\n",
-      "------------------------------------------------\n",
-      "0 | layer_1  | Conv2d             | 30    \n",
-      "1 | layer_2  | Conv2d             | 168   \n",
-      "2 | layer_3  | Conv2d             | 660   \n",
-      "3 | pool     | MaxPool2d          | 0     \n",
-      "4 | layer_5  | Linear             | 30.0 M\n",
-      "5 | layer_6  | Linear             | 100 K \n",
-      "6 | layer_7  | Linear             | 5.0 K \n",
-      "7 | layer_8  | Linear             | 510   \n",
-      "8 | layer_9  | Linear             | 110   \n",
-      "9 | accuracy | MulticlassAccuracy | 0     \n",
-      "------------------------------------------------\n",
+      "   | Name     | Type               | Params\n",
+      "-------------------------------------------------\n",
+      "0  | layer_1  | Conv2d             | 30    \n",
+      "1  | layer_2  | Conv2d             | 168   \n",
+      "2  | layer_3  | Conv2d             | 660   \n",
+      "3  | pool     | MaxPool2d          | 0     \n",
+      "4  | layer_5  | Linear             | 30.0 M\n",
+      "5  | layer_6  | Linear             | 100 K \n",
+      "6  | layer_7  | Linear             | 5.0 K \n",
+      "7  | layer_8  | Linear             | 510   \n",
+      "8  | layer_9  | Linear             | 110   \n",
+      "9  | accuracy | MulticlassAccuracy | 0     \n",
+      "10 | loss     | CrossEntropyLoss   | 0     \n",
+      "-------------------------------------------------\n",
       "30.1 M    Trainable params\n",
       "0         Non-trainable params\n",
       "30.1 M    Total params\n",
@@ -741,7 +578,7 @@
     {
      "data": {
       "application/vnd.jupyter.widget-view+json": {
-       "model_id": "a55cd26ad321421b80f30fb5a2bc2460",
+       "model_id": "90e1c86718ea468db52b4e96a9683a36",
        "version_major": 2,
        "version_minor": 0
       },
@@ -756,42 +593,37 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "C:\\Users\\gcmar\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
+      "C:\\Users\\GCM\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
       "  rank_zero_warn(\n",
-      "C:\\Users\\gcmar\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
+      "C:\\Users\\GCM\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "torch.Size([10, 30000])\n"
-     ]
-    },
-    {
-     "ename": "IndexError",
-     "evalue": "Dimension specified as 0 but tensor has no dimensions",
+     "ename": "AttributeError",
+     "evalue": "'MyModel' object has no attribute '_get_preds_loss_accuracy'",
      "output_type": "error",
      "traceback": [
       "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
-      "Cell \u001b[1;32mIn[12], line 21\u001b[0m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m YogaModel(n_classes\u001b[38;5;241m=\u001b[39mnum_of_classes)\n\u001b[0;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     14\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     15\u001b[0m     devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;66;03m# use all GPU's (-1)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m            \u001b[38;5;66;03m# number of epochs\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     )\n\u001b[1;32m---> 21\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtest(model, datamodule\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m     25\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    606\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m--> 608\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     41\u001b[0m     trainer\u001b[38;5;241m.\u001b[39m_call_teardown_hook()\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    643\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_set_ckpt_path(\n\u001b[0;32m    645\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    646\u001b[0m     ckpt_path,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    647\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    648\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    649\u001b[0m )\n\u001b[1;32m--> 650\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1112\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[1;32m-> 1112\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1114\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1191\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[0;32m   1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1204\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_training_routine()\n\u001b[0;32m   1203\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;66;03m# enable train mode\u001b[39;00m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1276\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m-> 1276\u001b[0m     \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\dataloader\\evaluation_loop.py:152\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_dataloaders \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    151\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dataloader_idx\n\u001b[1;32m--> 152\u001b[0m dl_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_max_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# store batch level output per dataloader\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs\u001b[38;5;241m.\u001b[39mappend(dl_outputs)\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:143\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[1;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# track loss history\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_evaluation_batch_end(output, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_completed()\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# log batch metrics\u001b[39;00m\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:275\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._on_evaluation_batch_end\u001b[1;34m(self, output, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# TODO: the argument should be keyword for these\u001b[39;00m\n\u001b[0;32m    274\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_test_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_validation_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(hook_name, output, \u001b[38;5;241m*\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mon_batch_end()\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1394\u001b[0m, in \u001b[0;36mTrainer._call_callback_hooks\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callable(fn):\n\u001b[0;32m   1393\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback\u001b[38;5;241m.\u001b[39mstate_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1394\u001b[0m             fn(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[0;32m   1397\u001b[0m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m   1398\u001b[0m     pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
-      "Cell \u001b[1;32mIn[11], line 17\u001b[0m, in \u001b[0;36mLogPredictionsCallback.on_validation_batch_end\u001b[1;34m(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[0;32m     15\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m     16\u001b[0m images \u001b[38;5;241m=\u001b[39m [img \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m x[:n]]\n\u001b[1;32m---> 17\u001b[0m captions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGround Truth: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_i\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Prediction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_pred\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m y_i, y_pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(y[:n], \u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m)]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Option 1: log images with `WandbLogger.log_image`\u001b[39;00m\n\u001b[0;32m     20\u001b[0m wandb_logger\u001b[38;5;241m.\u001b[39mlog_image(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_images\u001b[39m\u001b[38;5;124m'\u001b[39m, images\u001b[38;5;241m=\u001b[39mimages, caption\u001b[38;5;241m=\u001b[39mcaptions)\n",
-      "\u001b[1;31mIndexError\u001b[0m: Dimension specified as 0 but tensor has no dimensions"
+      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
+      "Cell \u001b[1;32mIn[9], line 21\u001b[0m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m MyModel(n_classes\u001b[38;5;241m=\u001b[39mnum_of_classes)\n\u001b[0;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     14\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     15\u001b[0m     devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;66;03m# use all GPU's (-1)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m            \u001b[38;5;66;03m# number of epochs\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     )\n\u001b[1;32m---> 21\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtest(model, datamodule\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m     25\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Trainer.fit()` requires a `LightningModule`, got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m--> 608\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     41\u001b[0m     trainer\u001b[38;5;241m.\u001b[39m_call_teardown_hook()\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    643\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_set_ckpt_path(\n\u001b[0;32m    645\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    646\u001b[0m     ckpt_path,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    647\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    648\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    649\u001b[0m )\n\u001b[1;32m--> 650\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1103\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[1;32m-> 1103\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1182\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[1;32m-> 1182\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1195\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_training_routine()\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1195\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[38;5;66;03m# enable train mode\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1267\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m-> 1267\u001b[0m     \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\dataloader\\evaluation_loop.py:152\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_dataloaders \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    151\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dataloader_idx\n\u001b[1;32m--> 152\u001b[0m dl_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_max_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# store batch level output per dataloader\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs\u001b[38;5;241m.\u001b[39mappend(dl_outputs)\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:137\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[1;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# lightning module methods\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step_end(output)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:234\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"The evaluation step (validation_step or test_step depending on the trainer's state).\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124;03m    the outputs of the step\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    233\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 234\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1485\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1485\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m   1488\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:390\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mval_step_context():\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, ValidationStep)\n\u001b[1;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mvalidation_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
+      "Cell \u001b[1;32mIn[6], line 65\u001b[0m, in \u001b[0;36mMyModel.validation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m,batch,batch_idx):\n\u001b[1;32m---> 65\u001b[0m     preds, loss, acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_preds_loss_accuracy\u001b[49m(batch)\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Log loss and metric\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss_alt\u001b[39m\u001b[38;5;124m'\u001b[39m, loss)\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1269\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1269\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
+      "\u001b[1;31mAttributeError\u001b[0m: 'MyModel' object has no attribute '_get_preds_loss_accuracy'"
      ]
     }
    ],
@@ -802,10 +634,10 @@
     "# TRAIN\n",
     "# setup data\n",
     "# data = MNISTDataModule()\n",
-    "data = YogaDataModule()\n",
+    "data = DataModule()\n",
     "\n",
     "# setup model - choose different hyperparameters per experiment\n",
-    "model = YogaModel(n_classes=num_of_classes)\n",
+    "model = MyModel(n_classes=num_of_classes)\n",
     "\n",
     "\n",
     "trainer = Trainer(\n",
@@ -813,7 +645,7 @@
     "    devices=-1, # use all GPU's (-1)\n",
     "    callbacks=[log_predictions_callback,checkpoint_callback],\n",
     "    logger=wandb_logger,    # W&B integration\n",
-    "    max_epochs=3            # number of epochs\n",
+    "    max_epochs=100            # number of epochs\n",
     "    )\n",
     "\n",
     "trainer.fit(model, data)\n",
@@ -829,10 +661,10 @@
    "id": "3b58022d-6961-41b0-a4e1-60bbc1c09791",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-01T20:56:29.583762Z",
-     "iopub.status.idle": "2023-03-01T20:56:29.584765Z",
-     "shell.execute_reply": "2023-03-01T20:56:29.583762Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:29.583762Z"
+     "iopub.status.busy": "2023-03-03T02:50:56.880321Z",
+     "iopub.status.idle": "2023-03-03T02:50:56.880819Z",
+     "shell.execute_reply": "2023-03-03T02:50:56.880819Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:56.880321Z"
     },
     "tags": []
    },
@@ -855,10 +687,10 @@
    "id": "ebde1018-ddfa-43f2-b9c6-f2c1d4b19736",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-01T20:56:29.585969Z",
-     "iopub.status.idle": "2023-03-01T20:56:29.586972Z",
-     "shell.execute_reply": "2023-03-01T20:56:29.586972Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:29.586972Z"
+     "iopub.status.busy": "2023-03-03T02:50:56.882819Z",
+     "iopub.status.idle": "2023-03-03T02:50:56.883821Z",
+     "shell.execute_reply": "2023-03-03T02:50:56.883318Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:56.883318Z"
     },
     "tags": []
    },
@@ -901,10 +733,10 @@
    "id": "91aeb8a0-9ffd-4439-808c-2951d1f74b36",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-01T20:56:29.589019Z",
-     "iopub.status.idle": "2023-03-01T20:56:29.589019Z",
-     "shell.execute_reply": "2023-03-01T20:56:29.589019Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:29.589019Z"
+     "iopub.status.busy": "2023-03-03T02:50:56.885820Z",
+     "iopub.status.idle": "2023-03-03T02:50:56.886320Z",
+     "shell.execute_reply": "2023-03-03T02:50:56.885820Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:56.885820Z"
     },
     "tags": []
    },
@@ -917,7 +749,7 @@
     "\n",
     "    # setup data\n",
     "    # data = MNISTDataModule()\n",
-    "    data = YogaDataModule()\n",
+    "    data = DataModule()\n",
     "\n",
     "    # setup model - note how we refer to sweep parameters with wandb.config\n",
     "    # model = LitMNIST(\n",
@@ -925,7 +757,7 @@
     "    #     n_layer_2=wandb.config.n_layer_2,\n",
     "    #     lr=wandb.config.lr\n",
     "    # )\n",
-    "    model = YogaModel(lr=wandb.config.lr, n_classes=num_of_classes)\n",
+    "    model = MyModel(lr=wandb.config.lr, n_classes=num_of_classes)\n",
     "\n",
     "    # setup Trainer\n",
     "    trainer = Trainer(\n",
@@ -944,10 +776,10 @@
    "id": "869b0393-21cf-4fba-8efd-7678a852b697",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-01T20:56:29.591016Z",
-     "iopub.status.idle": "2023-03-01T20:56:29.592018Z",
-     "shell.execute_reply": "2023-03-01T20:56:29.592018Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:29.592018Z"
+     "iopub.status.busy": "2023-03-03T02:50:56.887320Z",
+     "iopub.status.idle": "2023-03-03T02:50:56.888321Z",
+     "shell.execute_reply": "2023-03-03T02:50:56.887819Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:56.887819Z"
     },
     "tags": []
    },
diff --git a/Train/Optimize_Pytorch_Lightning_models_with_Weights_&_Biases.ipynb b/Train/Optimize_Pytorch_Lightning_models_with_Weights_&_Biases.ipynb
index 37c5be9..ae3c03b 100644
--- a/Train/Optimize_Pytorch_Lightning_models_with_Weights_&_Biases.ipynb
+++ b/Train/Optimize_Pytorch_Lightning_models_with_Weights_&_Biases.ipynb
@@ -16,92 +16,55 @@
    "execution_count": 1,
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:17:03.262717Z",
-     "iopub.status.busy": "2023-03-01T20:17:03.261711Z",
-     "iopub.status.idle": "2023-03-01T20:17:11.004364Z",
-     "shell.execute_reply": "2023-03-01T20:17:11.003361Z",
-     "shell.execute_reply.started": "2023-03-01T20:17:03.262717Z"
+     "iopub.execute_input": "2023-03-03T02:53:44.392567Z",
+     "iopub.status.busy": "2023-03-03T02:53:44.392068Z",
+     "iopub.status.idle": "2023-03-03T02:53:52.065564Z",
+     "shell.execute_reply": "2023-03-03T02:53:52.062565Z",
+     "shell.execute_reply.started": "2023-03-03T02:53:44.392567Z"
     },
     "tags": []
    },
    "outputs": [
     {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristopher-marais\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
-     ]
-    },
-    {
-     "data": {
-      "text/html": [
-       "Tracking run with wandb version 0.13.10"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       "Run data is saved locally in <code>.\\wandb\\run-20230301_151709-r72pnsup</code>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       "Syncing run <strong><a href='https://wandb.ai/christopher-marais/lightning_logs/runs/r72pnsup' target=\"_blank\">proud-blaze-1</a></strong> to <a href='https://wandb.ai/christopher-marais/lightning_logs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       " View project at <a href='https://wandb.ai/christopher-marais/lightning_logs' target=\"_blank\">https://wandb.ai/christopher-marais/lightning_logs</a>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       " View run at <a href='https://wandb.ai/christopher-marais/lightning_logs/runs/r72pnsup' target=\"_blank\">https://wandb.ai/christopher-marais/lightning_logs/runs/r72pnsup</a>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "GPU available: True (cuda), used: False\n",
-      "TPU available: False, using: 0 TPU cores\n",
-      "IPU available: False, using: 0 IPUs\n",
-      "HPU available: False, using: 0 HPUs\n",
-      "C:\\Users\\gcmar\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
-      "  rank_zero_warn(\n"
+     "ename": "AssertionError",
+     "evalue": "",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:1129\u001b[0m, in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[0;32m   1128\u001b[0m wi \u001b[38;5;241m=\u001b[39m _WandbInit()\n\u001b[1;32m-> 1129\u001b[0m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m wi\u001b[38;5;241m.\u001b[39msettings\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:164\u001b[0m, in \u001b[0;36m_WandbInit.setup\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprinter\u001b[38;5;241m.\u001b[39mdisplay(line, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wl \u001b[38;5;241m=\u001b[39m \u001b[43mwandb_setup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# Make sure we have a logger setup (might be an early logger)\u001b[39;00m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\wandb\\sdk\\wandb_setup.py:307\u001b[0m, in \u001b[0;36msetup\u001b[1;34m(settings)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup\u001b[39m(settings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_WandbSetup\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 307\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\wandb\\sdk\\wandb_setup.py:302\u001b[0m, in \u001b[0;36m_setup\u001b[1;34m(settings, _reset)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m wl \u001b[38;5;241m=\u001b[39m \u001b[43m_WandbSetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wl\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\wandb\\sdk\\wandb_setup.py:288\u001b[0m, in \u001b[0;36m_WandbSetup.__init__\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 288\u001b[0m _WandbSetup\u001b[38;5;241m.\u001b[39m_instance \u001b[38;5;241m=\u001b[39m \u001b[43m_WandbSetup__WandbSetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\wandb\\sdk\\wandb_setup.py:100\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup.__init__\u001b[1;34m(self, pid, settings, environ)\u001b[0m\n\u001b[0;32m     98\u001b[0m _set_logger(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_early_logger)\n\u001b[1;32m--> 100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_early_logger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# self._settings.freeze()\u001b[39;00m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\wandb\\sdk\\wandb_setup.py:128\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup._settings_setup\u001b[1;34m(self, settings, early_logger)\u001b[0m\n\u001b[0;32m    126\u001b[0m     s\u001b[38;5;241m.\u001b[39m_apply_setup(settings, _logger\u001b[38;5;241m=\u001b[39mearly_logger)\n\u001b[1;32m--> 128\u001b[0m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_settings_from_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s\u001b[38;5;241m.\u001b[39m_cli_only_mode:\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\wandb\\sdk\\wandb_settings.py:1390\u001b[0m, in \u001b[0;36mSettings._infer_settings_from_environment\u001b[1;34m(self, _logger)\u001b[0m\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jupyter \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotebook_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotebook_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1390\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjupyter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotebook_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1391\u001b[0m     settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_jupyter_path\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\wandb\\jupyter.py:228\u001b[0m, in \u001b[0;36mnotebook_metadata\u001b[1;34m(silent)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    223\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/working\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: ipynb[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    225\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: ipynb[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    226\u001b[0m         }\n\u001b[1;32m--> 228\u001b[0m jupyter_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mnotebook_metadata_from_jupyter_servers_and_kernel_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m jupyter_metadata:\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\wandb\\jupyter.py:160\u001b[0m, in \u001b[0;36mnotebook_metadata_from_jupyter_servers_and_kernel_id\u001b[1;34m()\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnotebook_metadata_from_jupyter_servers_and_kernel_id\u001b[39m():\n\u001b[1;32m--> 160\u001b[0m     servers, kernel_id \u001b[38;5;241m=\u001b[39m \u001b[43mjupyter_servers_and_kernel_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m servers:\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\wandb\\jupyter.py:257\u001b[0m, in \u001b[0;36mjupyter_servers_and_kernel_id\u001b[1;34m()\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m serverapp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 257\u001b[0m     servers\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mlist\u001b[39m(\u001b[43mserverapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_running_servers\u001b[49m()))\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m notebookapp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\importlib\\util.py:247\u001b[0m, in \u001b[0;36m_LazyModule.__getattribute__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    246\u001b[0m         attrs_updated[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__spec__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# If exec_module() was used directly there is no guarantee the module\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# object was put into sys.modules.\u001b[39;00m\n",
+      "File \u001b[1;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
+      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\jupyter_server\\serverapp.py:116\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjupyter_server\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilemanager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    113\u001b[0m     AsyncFileContentsManager,\n\u001b[0;32m    114\u001b[0m     FileContentsManager,\n\u001b[0;32m    115\u001b[0m )\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjupyter_server\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlargefilemanager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LargeFileManager\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjupyter_server\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    118\u001b[0m     AsyncContentsManager,\n\u001b[0;32m    119\u001b[0m     ContentsManager,\n\u001b[0;32m    120\u001b[0m )\n",
+      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
+      "File \u001b[1;32m<frozen importlib._bootstrap>:1002\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
+      "File \u001b[1;32m<frozen importlib._bootstrap>:945\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
+      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1439\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
+      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1411\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
+      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1544\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
+      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
+      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
+      "\nDuring handling of the above exception, another exception occurred:\n",
+      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
+      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WandbLogger\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[1;32m----> 4\u001b[0m wandb_logger \u001b[38;5;241m=\u001b[39m \u001b[43mWandbLogger\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(logger\u001b[38;5;241m=\u001b[39mwandb_logger)\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:357\u001b[0m, in \u001b[0;36mWandbLogger.__init__\u001b[1;34m(self, name, save_dir, version, offline, dir, id, anonymous, project, log_model, experiment, prefix, checkpoint_name, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _WANDB_GREATER_EQUAL_0_12_10:\n\u001b[0;32m    356\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mrequire(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 357\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_name \u001b[38;5;241m=\u001b[39m checkpoint_name\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\lightning_fabric\\loggers\\logger.py:117\u001b[0m, in \u001b[0;36mrank_zero_experiment.<locals>.experiment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@rank_zero_only\u001b[39m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_experiment\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Callable:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m _DummyExperiment()\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\lightning_utilities\\core\\rank_zero.py:24\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `rank_zero_only.rank` needs to be set before use\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\lightning_fabric\\loggers\\logger.py:115\u001b[0m, in \u001b[0;36mrank_zero_experiment.<locals>.experiment.<locals>.get_experiment\u001b[1;34m()\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@rank_zero_only\u001b[39m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_experiment\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Callable:\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:405\u001b[0m, in \u001b[0;36mWandbLogger.experiment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39m_attach(attach_id)\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;66;03m# create new wandb process\u001b[39;00m\n\u001b[1;32m--> 405\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39minit(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wandb_init)\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;66;03m# define default x-axis\u001b[39;00m\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment, (Run, RunDisabled)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefine_metric\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     ):\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:1153\u001b[0m, in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1153\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m logger\n\u001b[0;32m   1154\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterrupted\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m   1155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
+      "\u001b[1;31mAssertionError\u001b[0m: "
      ]
     }
    ],
@@ -141,14 +104,13 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": null,
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:17:11.005879Z",
-     "iopub.status.busy": "2023-03-01T20:17:11.004364Z",
-     "iopub.status.idle": "2023-03-01T20:17:11.020491Z",
-     "shell.execute_reply": "2023-03-01T20:17:11.019572Z",
-     "shell.execute_reply.started": "2023-03-01T20:17:11.005879Z"
+     "iopub.status.busy": "2023-03-03T02:53:52.067063Z",
+     "iopub.status.idle": "2023-03-03T02:53:52.068064Z",
+     "shell.execute_reply": "2023-03-03T02:53:52.068064Z",
+     "shell.execute_reply.started": "2023-03-03T02:53:52.068064Z"
     },
     "id": "zIOoAOVrSuB_",
     "vscode": {
@@ -171,39 +133,20 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": null,
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:17:11.022487Z",
-     "iopub.status.busy": "2023-03-01T20:17:11.022487Z",
-     "iopub.status.idle": "2023-03-01T20:17:11.050756Z",
-     "shell.execute_reply": "2023-03-01T20:17:11.049229Z",
-     "shell.execute_reply.started": "2023-03-01T20:17:11.022487Z"
+     "iopub.status.busy": "2023-03-03T02:53:52.071064Z",
+     "iopub.status.idle": "2023-03-03T02:53:52.072064Z",
+     "shell.execute_reply": "2023-03-03T02:53:52.071564Z",
+     "shell.execute_reply.started": "2023-03-03T02:53:52.071564Z"
     },
     "id": "9K3LS0PlSuCC",
     "vscode": {
      "languageId": "python"
     }
    },
-   "outputs": [
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
-     ]
-    },
-    {
-     "data": {
-      "text/plain": [
-       "True"
-      ]
-     },
-     "execution_count": 3,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "import wandb\n",
     "wandb.login()"
@@ -229,14 +172,13 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": null,
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:17:11.052280Z",
-     "iopub.status.busy": "2023-03-01T20:17:11.051770Z",
-     "iopub.status.idle": "2023-03-01T20:17:11.158906Z",
-     "shell.execute_reply": "2023-03-01T20:17:11.157375Z",
-     "shell.execute_reply.started": "2023-03-01T20:17:11.052280Z"
+     "iopub.status.busy": "2023-03-03T02:53:52.073563Z",
+     "iopub.status.idle": "2023-03-03T02:53:52.074565Z",
+     "shell.execute_reply": "2023-03-03T02:53:52.074063Z",
+     "shell.execute_reply.started": "2023-03-03T02:53:52.074063Z"
     },
     "id": "LtC3tqgLSuCD",
     "tags": [],
@@ -263,29 +205,16 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": null,
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:17:11.161941Z",
-     "iopub.status.busy": "2023-03-01T20:17:11.160940Z",
-     "iopub.status.idle": "2023-03-01T20:17:11.466147Z",
-     "shell.execute_reply": "2023-03-01T20:17:11.464630Z",
-     "shell.execute_reply.started": "2023-03-01T20:17:11.161941Z"
+     "iopub.status.busy": "2023-03-03T02:53:52.076069Z",
+     "iopub.status.idle": "2023-03-03T02:53:52.077066Z",
+     "shell.execute_reply": "2023-03-03T02:53:52.076567Z",
+     "shell.execute_reply.started": "2023-03-03T02:53:52.076567Z"
     }
    },
-   "outputs": [
-    {
-     "ename": "NameError",
-     "evalue": "name 'LightningDataModule' is not defined",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
-      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMNISTDataModule\u001b[39;00m(\u001b[43mLightningDataModule\u001b[49m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m):\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
-      "\u001b[1;31mNameError\u001b[0m: name 'LightningDataModule' is not defined"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "class MNISTDataModule(LightningDataModule):\n",
     "\n",
@@ -331,10 +260,10 @@
    "execution_count": null,
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-01T20:17:11.467672Z",
-     "iopub.status.idle": "2023-03-01T20:17:11.468686Z",
-     "shell.execute_reply": "2023-03-01T20:17:11.468686Z",
-     "shell.execute_reply.started": "2023-03-01T20:17:11.468686Z"
+     "iopub.status.busy": "2023-03-03T02:53:52.079064Z",
+     "iopub.status.idle": "2023-03-03T02:53:52.079564Z",
+     "shell.execute_reply": "2023-03-03T02:53:52.079564Z",
+     "shell.execute_reply.started": "2023-03-03T02:53:52.079564Z"
     }
    },
    "outputs": [],
@@ -368,10 +297,10 @@
    "execution_count": null,
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-01T20:17:11.470707Z",
-     "iopub.status.idle": "2023-03-01T20:17:11.470707Z",
-     "shell.execute_reply": "2023-03-01T20:17:11.470707Z",
-     "shell.execute_reply.started": "2023-03-01T20:17:11.470707Z"
+     "iopub.status.busy": "2023-03-03T02:53:52.081564Z",
+     "iopub.status.idle": "2023-03-03T02:53:52.082062Z",
+     "shell.execute_reply": "2023-03-03T02:53:52.082062Z",
+     "shell.execute_reply.started": "2023-03-03T02:53:52.082062Z"
     }
    },
    "outputs": [],
@@ -436,10 +365,10 @@
    "execution_count": null,
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-01T20:17:11.472711Z",
-     "iopub.status.idle": "2023-03-01T20:17:11.473706Z",
-     "shell.execute_reply": "2023-03-01T20:17:11.473706Z",
-     "shell.execute_reply.started": "2023-03-01T20:17:11.473706Z"
+     "iopub.status.busy": "2023-03-03T02:53:52.084064Z",
+     "iopub.status.idle": "2023-03-03T02:53:52.085064Z",
+     "shell.execute_reply": "2023-03-03T02:53:52.084564Z",
+     "shell.execute_reply.started": "2023-03-03T02:53:52.084564Z"
     }
    },
    "outputs": [],
@@ -486,14 +415,13 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
+   "execution_count": null,
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:17:30.870268Z",
-     "iopub.status.busy": "2023-03-01T20:17:30.870268Z",
-     "iopub.status.idle": "2023-03-01T20:17:30.884286Z",
-     "shell.execute_reply": "2023-03-01T20:17:30.883284Z",
-     "shell.execute_reply.started": "2023-03-01T20:17:30.870268Z"
+     "iopub.status.busy": "2023-03-03T02:53:52.086563Z",
+     "iopub.status.idle": "2023-03-03T02:53:52.087066Z",
+     "shell.execute_reply": "2023-03-03T02:53:52.086563Z",
+     "shell.execute_reply.started": "2023-03-03T02:53:52.086563Z"
     },
     "tags": []
    },
@@ -508,14 +436,13 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 7,
+   "execution_count": null,
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:17:31.002409Z",
-     "iopub.status.busy": "2023-03-01T20:17:31.002409Z",
-     "iopub.status.idle": "2023-03-01T20:17:31.024668Z",
-     "shell.execute_reply": "2023-03-01T20:17:31.023665Z",
-     "shell.execute_reply.started": "2023-03-01T20:17:31.002409Z"
+     "iopub.status.busy": "2023-03-03T02:53:52.088563Z",
+     "iopub.status.idle": "2023-03-03T02:53:52.089564Z",
+     "shell.execute_reply": "2023-03-03T02:53:52.089065Z",
+     "shell.execute_reply.started": "2023-03-03T02:53:52.089065Z"
     },
     "id": "xL_JWvg9SuCE",
     "tags": [],
@@ -616,14 +543,13 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": null,
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:17:31.281922Z",
-     "iopub.status.busy": "2023-03-01T20:17:31.280940Z",
-     "iopub.status.idle": "2023-03-01T20:17:31.301566Z",
-     "shell.execute_reply": "2023-03-01T20:17:31.300589Z",
-     "shell.execute_reply.started": "2023-03-01T20:17:31.281922Z"
+     "iopub.status.busy": "2023-03-03T02:53:52.091063Z",
+     "iopub.status.idle": "2023-03-03T02:53:52.091562Z",
+     "shell.execute_reply": "2023-03-03T02:53:52.091063Z",
+     "shell.execute_reply.started": "2023-03-03T02:53:52.091063Z"
     },
     "id": "vNGDhqpnSuCF",
     "tags": [],
@@ -649,14 +575,13 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": null,
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:17:32.148038Z",
-     "iopub.status.busy": "2023-03-01T20:17:32.147050Z",
-     "iopub.status.idle": "2023-03-01T20:17:32.157129Z",
-     "shell.execute_reply": "2023-03-01T20:17:32.156231Z",
-     "shell.execute_reply.started": "2023-03-01T20:17:32.148038Z"
+     "iopub.status.busy": "2023-03-03T02:53:52.093065Z",
+     "iopub.status.idle": "2023-03-03T02:53:52.094071Z",
+     "shell.execute_reply": "2023-03-03T02:53:52.093564Z",
+     "shell.execute_reply.started": "2023-03-03T02:53:52.093564Z"
     },
     "id": "d84LZk-6SuCG",
     "tags": [],
@@ -697,14 +622,13 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
+   "execution_count": null,
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:17:32.896735Z",
-     "iopub.status.busy": "2023-03-01T20:17:32.895127Z",
-     "iopub.status.idle": "2023-03-01T20:17:32.920379Z",
-     "shell.execute_reply": "2023-03-01T20:17:32.918524Z",
-     "shell.execute_reply.started": "2023-03-01T20:17:32.896735Z"
+     "iopub.status.busy": "2023-03-03T02:53:52.096065Z",
+     "iopub.status.idle": "2023-03-03T02:53:52.097064Z",
+     "shell.execute_reply": "2023-03-03T02:53:52.096563Z",
+     "shell.execute_reply.started": "2023-03-03T02:53:52.096563Z"
     },
     "id": "8zNfGYR7SuCH",
     "tags": [],
@@ -712,16 +636,7 @@
      "languageId": "python"
     }
    },
-   "outputs": [
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "C:\\Users\\gcmar\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
-      "  rank_zero_warn(\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "from pytorch_lightning.loggers import WandbLogger\n",
     "from pytorch_lightning import Trainer\n",
@@ -749,14 +664,13 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 11,
+   "execution_count": null,
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:17:33.746922Z",
-     "iopub.status.busy": "2023-03-01T20:17:33.746922Z",
-     "iopub.status.idle": "2023-03-01T20:17:33.768774Z",
-     "shell.execute_reply": "2023-03-01T20:17:33.767773Z",
-     "shell.execute_reply.started": "2023-03-01T20:17:33.746922Z"
+     "iopub.status.busy": "2023-03-03T02:53:52.098564Z",
+     "iopub.status.idle": "2023-03-03T02:53:52.099065Z",
+     "shell.execute_reply": "2023-03-03T02:53:52.099065Z",
+     "shell.execute_reply.started": "2023-03-03T02:53:52.099065Z"
     },
     "id": "M9-321mOSuCH",
     "tags": [],
@@ -806,14 +720,13 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 12,
+   "execution_count": null,
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:17:34.531650Z",
-     "iopub.status.busy": "2023-03-01T20:17:34.531650Z",
-     "iopub.status.idle": "2023-03-01T20:17:34.566933Z",
-     "shell.execute_reply": "2023-03-01T20:17:34.565396Z",
-     "shell.execute_reply.started": "2023-03-01T20:17:34.531650Z"
+     "iopub.status.busy": "2023-03-03T02:53:52.101065Z",
+     "iopub.status.idle": "2023-03-03T02:53:52.101565Z",
+     "shell.execute_reply": "2023-03-03T02:53:52.101565Z",
+     "shell.execute_reply.started": "2023-03-03T02:53:52.101565Z"
     },
     "id": "JT4s-GKeSuCI",
     "tags": [],
@@ -821,18 +734,7 @@
      "languageId": "python"
     }
    },
-   "outputs": [
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "GPU available: True (cuda), used: True\n",
-      "TPU available: False, using: 0 TPU cores\n",
-      "IPU available: False, using: 0 IPUs\n",
-      "HPU available: False, using: 0 HPUs\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "trainer = Trainer(\n",
     "    logger=wandb_logger,                    # W&B integration\n",
@@ -844,14 +746,13 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 13,
+   "execution_count": null,
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:17:34.893588Z",
-     "iopub.status.busy": "2023-03-01T20:17:34.892578Z",
-     "iopub.status.idle": "2023-03-01T20:19:35.616443Z",
-     "shell.execute_reply": "2023-03-01T20:19:35.615932Z",
-     "shell.execute_reply.started": "2023-03-01T20:17:34.893588Z"
+     "iopub.status.busy": "2023-03-03T02:53:52.103569Z",
+     "iopub.status.idle": "2023-03-03T02:53:52.104564Z",
+     "shell.execute_reply": "2023-03-03T02:53:52.104064Z",
+     "shell.execute_reply.started": "2023-03-03T02:53:52.104064Z"
     },
     "id": "wnaXag_aSuCI",
     "tags": [],
@@ -859,142 +760,7 @@
      "languageId": "python"
     }
    },
-   "outputs": [
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
-      "\n",
-      "  | Name    | Type             | Params\n",
-      "---------------------------------------------\n",
-      "0 | layer_1 | Linear           | 100 K \n",
-      "1 | layer_2 | Linear           | 16.5 K\n",
-      "2 | layer_3 | Linear           | 1.3 K \n",
-      "3 | loss    | CrossEntropyLoss | 0     \n",
-      "---------------------------------------------\n",
-      "118 K     Trainable params\n",
-      "0         Non-trainable params\n",
-      "118 K     Total params\n",
-      "0.473     Total estimated model params size (MB)\n"
-     ]
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "Sanity Checking: 0it [00:00, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "C:\\Users\\gcmar\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
-      "  rank_zero_warn(\n",
-      "C:\\Users\\gcmar\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
-      "  rank_zero_warn(\n"
-     ]
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "521627599b1643cfa6fc84fae85d0da8",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "Training: 0it [00:00, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "Validation: 0it [00:00, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "Validation: 0it [00:00, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "Validation: 0it [00:00, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "Validation: 0it [00:00, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "Validation: 0it [00:00, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "trainer.fit(model, training_loader, validation_loader)"
    ]
@@ -1010,14 +776,13 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 14,
+   "execution_count": null,
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:19:35.618462Z",
-     "iopub.status.busy": "2023-03-01T20:19:35.618462Z",
-     "iopub.status.idle": "2023-03-01T20:19:42.269993Z",
-     "shell.execute_reply": "2023-03-01T20:19:42.268991Z",
-     "shell.execute_reply.started": "2023-03-01T20:19:35.618462Z"
+     "iopub.status.busy": "2023-03-03T02:53:52.106563Z",
+     "iopub.status.idle": "2023-03-03T02:53:52.107566Z",
+     "shell.execute_reply": "2023-03-03T02:53:52.107065Z",
+     "shell.execute_reply.started": "2023-03-03T02:53:52.107065Z"
     },
     "id": "DCngWZ_cSuCI",
     "tags": [],
@@ -1025,61 +790,7 @@
      "languageId": "python"
     }
    },
-   "outputs": [
-    {
-     "data": {
-      "text/html": [
-       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       "<style>\n",
-       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
-       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
-       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
-       "    </style>\n",
-       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████</td></tr><tr><td>train_accuracy</td><td>▁▅▆▆▆▆▅▆▅▅▇▇█▇▅▇▇█▆▇█▇▇▆▇▇▇█████▇▇▇▇▇▇▇▇</td></tr><tr><td>train_loss</td><td>█▄▃▄▃▃▃▃▃▃▂▂▁▂▅▂▂▁▃▂▁▁▂▂▂▃▁▁▁▁▁▁▂▁▁▂▂▁▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▆▇██</td></tr><tr><td>val_loss</td><td>█▄▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_accuracy</td><td>0.91667</td></tr><tr><td>train_loss</td><td>0.15424</td></tr><tr><td>trainer/global_step</td><td>4299</td></tr><tr><td>val_accuracy</td><td>0.9692</td></tr><tr><td>val_loss</td><td>0.10537</td></tr></table><br/></div></div>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       " View run <strong style=\"color:#cdcd00\">proud-blaze-1</strong> at: <a href='https://wandb.ai/christopher-marais/lightning_logs/runs/r72pnsup' target=\"_blank\">https://wandb.ai/christopher-marais/lightning_logs/runs/r72pnsup</a><br/>Synced 5 W&B file(s), 126 media file(s), 131 artifact file(s) and 0 other file(s)"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       "Find logs at: <code>.\\wandb\\run-20230301_151709-r72pnsup\\logs</code>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    }
-   ],
+   "outputs": [],
    "source": [
     "wandb.finish()"
    ]
diff --git a/Train/PyLi_wanb_sweep_CoatNet.ipynb b/Train/PyLi_wanb_sweep_CoatNet.ipynb
index ced9a67..cdc42c8 100644
--- a/Train/PyLi_wanb_sweep_CoatNet.ipynb
+++ b/Train/PyLi_wanb_sweep_CoatNet.ipynb
@@ -6,11 +6,11 @@
    "id": "c7b471f1-f5fa-4eb1-b9ae-2d67ed8838df",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:16.271323Z",
-     "iopub.status.busy": "2023-03-01T20:56:16.271323Z",
-     "iopub.status.idle": "2023-03-01T20:56:20.861826Z",
-     "shell.execute_reply": "2023-03-01T20:56:20.860831Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:16.271323Z"
+     "iopub.execute_input": "2023-03-03T02:50:41.830495Z",
+     "iopub.status.busy": "2023-03-03T02:50:41.829998Z",
+     "iopub.status.idle": "2023-03-03T02:50:46.465147Z",
+     "shell.execute_reply": "2023-03-03T02:50:46.464144Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:41.830495Z"
     },
     "tags": []
    },
@@ -26,13 +26,14 @@
     "\n",
     "# Pytorch modules\n",
     "import torch\n",
-    "from torch.nn import functional as F\n",
+    "from torch.nn import Linear, CrossEntropyLoss, functional as F\n",
     "from torch import nn\n",
     "from torch.optim import Adam\n",
     "from torch.utils.data import DataLoader, random_split, Dataset\n",
     "\n",
     "# Pytorch-Lightning\n",
     "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
+    "from pytorch_lightning.callbacks import ModelCheckpoint, Callback\n",
     "import pytorch_lightning as pl\n",
     "from pytorch_lightning.loggers import WandbLogger\n",
     "import torchmetrics # a new pakage for torchmetrics\n",
@@ -59,71 +60,6 @@
     "torch.set_float32_matmul_precision('high')"
    ]
   },
-  {
-   "cell_type": "code",
-   "execution_count": 2,
-   "id": "289e69f9-9a23-4f33-94af-a8950f9e1818",
-   "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:20.862838Z",
-     "iopub.status.busy": "2023-03-01T20:56:20.862838Z",
-     "iopub.status.idle": "2023-03-01T20:56:20.876388Z",
-     "shell.execute_reply": "2023-03-01T20:56:20.876388Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:20.862838Z"
-    },
-    "tags": []
-   },
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "['coatnet_0_rw_224',\n",
-       " 'coatnet_1_rw_224',\n",
-       " 'coatnet_bn_0_rw_224',\n",
-       " 'coatnet_nano_rw_224',\n",
-       " 'coatnet_rmlp_1_rw_224',\n",
-       " 'coatnet_rmlp_2_rw_224',\n",
-       " 'coatnet_rmlp_nano_rw_224']"
-      ]
-     },
-     "execution_count": 2,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "timm.list_models('*coatnet*', pretrained=True)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 3,
-   "id": "5fc60314-d2bb-4767-9cef-219da9f1955d",
-   "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:20.879932Z",
-     "iopub.status.busy": "2023-03-01T20:56:20.879932Z",
-     "iopub.status.idle": "2023-03-01T20:56:20.893218Z",
-     "shell.execute_reply": "2023-03-01T20:56:20.891688Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:20.879932Z"
-    },
-    "tags": []
-   },
-   "outputs": [],
-   "source": [
-    "# # load model\n",
-    "# model = timm.create_model('coatnet_rmlp_2_rw_224', pretrained=True, exportable=True, num_classes=10)\n",
-    "\n",
-    "# # see the output head shape\n",
-    "# clsfr_shape = model.get_classifier()\n",
-    "\n",
-    "# # get all node names\n",
-    "# nodes,_ = get_graph_node_names(model)\n",
-    "\n",
-    "# # get all layers\n",
-    "# modules = list(model.modules())"
-   ]
-  },
   {
    "cell_type": "markdown",
    "id": "2aeb5a33-290c-4449-8127-0a8a1ed4c6f0",
@@ -134,15 +70,15 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": 2,
    "id": "01c28e3c-850d-48b6-8db9-3a8804e0c9ae",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:20.895234Z",
-     "iopub.status.busy": "2023-03-01T20:56:20.894231Z",
-     "iopub.status.idle": "2023-03-01T20:56:20.908832Z",
-     "shell.execute_reply": "2023-03-01T20:56:20.907873Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:20.895234Z"
+     "iopub.execute_input": "2023-03-03T02:50:46.467648Z",
+     "iopub.status.busy": "2023-03-03T02:50:46.466648Z",
+     "iopub.status.idle": "2023-03-03T02:50:46.496649Z",
+     "shell.execute_reply": "2023-03-03T02:50:46.495147Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:46.467648Z"
     },
     "tags": []
    },
@@ -169,7 +105,7 @@
        " '9': 9}"
       ]
      },
-     "execution_count": 4,
+     "execution_count": 2,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -201,15 +137,15 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 3,
    "id": "8b9e722b-cda4-4956-a0c1-8eb31023f765",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:20.909835Z",
-     "iopub.status.busy": "2023-03-01T20:56:20.909835Z",
-     "iopub.status.idle": "2023-03-01T20:56:20.924555Z",
-     "shell.execute_reply": "2023-03-01T20:56:20.923617Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:20.909835Z"
+     "iopub.execute_input": "2023-03-03T02:50:46.501146Z",
+     "iopub.status.busy": "2023-03-03T02:50:46.500150Z",
+     "iopub.status.idle": "2023-03-03T02:50:46.589144Z",
+     "shell.execute_reply": "2023-03-03T02:50:46.588143Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:46.501146Z"
     },
     "tags": []
    },
@@ -272,15 +208,15 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
+   "execution_count": 4,
    "id": "9dbe4b19-9805-40b4-a513-ea35715a0c64",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:20.926555Z",
-     "iopub.status.busy": "2023-03-01T20:56:20.926555Z",
-     "iopub.status.idle": "2023-03-01T20:56:20.940645Z",
-     "shell.execute_reply": "2023-03-01T20:56:20.939643Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:20.926555Z"
+     "iopub.execute_input": "2023-03-03T02:50:46.591150Z",
+     "iopub.status.busy": "2023-03-03T02:50:46.590648Z",
+     "iopub.status.idle": "2023-03-03T02:50:46.681600Z",
+     "shell.execute_reply": "2023-03-03T02:50:46.680594Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:46.591150Z"
     },
     "tags": []
    },
@@ -308,21 +244,21 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 7,
+   "execution_count": 5,
    "id": "7539d3a5-ca4f-4ba3-a462-05875d4b9a90",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:20.942648Z",
-     "iopub.status.busy": "2023-03-01T20:56:20.942648Z",
-     "iopub.status.idle": "2023-03-01T20:56:20.957018Z",
-     "shell.execute_reply": "2023-03-01T20:56:20.955693Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:20.942648Z"
+     "iopub.execute_input": "2023-03-03T02:50:46.683595Z",
+     "iopub.status.busy": "2023-03-03T02:50:46.683098Z",
+     "iopub.status.idle": "2023-03-03T02:50:46.774193Z",
+     "shell.execute_reply": "2023-03-03T02:50:46.773192Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:46.683595Z"
     },
     "tags": []
    },
    "outputs": [],
    "source": [
-    "class YogaDataModule(pl.LightningDataModule):\n",
+    "class DataModule(LightningDataModule):\n",
     "\n",
     "    def __init__(self):\n",
     "            super().__init__()            \n",
@@ -352,116 +288,21 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
-   "id": "40361447-e7c3-47f2-9e04-a9058b596861",
-   "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:20.959403Z",
-     "iopub.status.busy": "2023-03-01T20:56:20.959403Z",
-     "iopub.status.idle": "2023-03-01T20:56:20.988223Z",
-     "shell.execute_reply": "2023-03-01T20:56:20.987711Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:20.959403Z"
-    },
-    "tags": []
-   },
-   "outputs": [],
-   "source": [
-    "class LitMNIST(LightningModule):\n",
-    "\n",
-    "    def __init__(self, n_classes=10, acc_task=\"multiclass\", n_layer_1=128, n_layer_2=256, lr=1e-3):\n",
-    "        '''method used to define our model parameters'''\n",
-    "        super().__init__()\n",
-    "        # mnist images are (1, 28, 28) (channels, width, height)\n",
-    "        self.layer_1 = torch.nn.Linear(28 * 28, n_layer_1)\n",
-    "        self.layer_2 = torch.nn.Linear(n_layer_1, n_layer_2)\n",
-    "        self.layer_3 = torch.nn.Linear(n_layer_2, n_classes)\n",
-    "        # optimizer parameters\n",
-    "        self.lr = lr\n",
-    "        # metrics\n",
-    "        self.acc_task = acc_task\n",
-    "        self.n_classes = n_classes\n",
-    "        self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.n_classes)\n",
-    "        self.class_names = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
-    "        # optional - save hyper-parameters to self.hparams\n",
-    "        # they will also be automatically logged as config parameters in W&B\n",
-    "        self.save_hyperparameters()\n",
-    "\n",
-    "    def forward(self, x):\n",
-    "        '''method used for inference input -> output'''\n",
-    "        batch_size, channels, width, height = x.size()\n",
-    "        # (b, 1, 28, 28) -> (b, 1*28*28)\n",
-    "        x = x.view(batch_size, -1)\n",
-    "        x = self.layer_1(x)\n",
-    "        x = F.relu(x)\n",
-    "        x = self.layer_2(x)\n",
-    "        x = F.relu(x)\n",
-    "        x = self.layer_3(x)\n",
-    "        x = F.log_softmax(x, dim=1)\n",
-    "        return x\n",
-    "\n",
-    "    def training_step(self, batch, batch_idx):\n",
-    "        '''needs to return a loss from a single batch'''\n",
-    "        x, y = batch\n",
-    "        logits = self(x)\n",
-    "        loss = F.nll_loss(logits, y)\n",
-    "        # Log training loss\n",
-    "        self.log('train_loss', loss)\n",
-    "        # Log metrics\n",
-    "        self.log('train_acc', self.accuracy(logits, y))\n",
-    "        return loss\n",
-    "\n",
-    "    def validation_step(self, batch, batch_idx):\n",
-    "        '''used for logging metrics'''\n",
-    "        x, y = batch\n",
-    "        logits = self(x)\n",
-    "        loss = F.nll_loss(logits, y)\n",
-    "        # Log validation loss (will be automatically averaged over an epoch)\n",
-    "        self.log('valid_loss', loss)\n",
-    "        # Log metrics\n",
-    "        self.log('valid_acc', self.accuracy(logits, y))\n",
-    "        self.cpu_logits = logits.to(\"cpu\").detach().numpy()\n",
-    "        self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
-    "        wandb.log({\"valid_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_logits,\n",
-    "                        y_true=self.cpu_y, preds=None,\n",
-    "                        class_names=self.class_names)})\n",
-    "\n",
-    "    def test_step(self, batch, batch_idx):\n",
-    "        '''used for logging metrics'''\n",
-    "        x, y = batch\n",
-    "        logits = self(x)\n",
-    "        loss = F.nll_loss(logits, y)\n",
-    "        # Log test loss\n",
-    "        self.log('test_loss', loss)\n",
-    "        # Log metrics\n",
-    "        self.log('test_acc', self.accuracy(logits, y))\n",
-    "        self.cpu_logits = logits.to(\"cpu\").detach().numpy()\n",
-    "        self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
-    "        wandb.log({\"test_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_logits,\n",
-    "                        y_true=self.cpu_y, preds=None,\n",
-    "                        class_names=self.class_names)})\n",
-    "    \n",
-    "    def configure_optimizers(self):\n",
-    "        '''defines model optimizer'''\n",
-    "        return Adam(self.parameters(), lr=self.lr)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 6,
    "id": "deb34aed-792a-4022-a878-f8d6c4ffa97c",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:20.989234Z",
-     "iopub.status.busy": "2023-03-01T20:56:20.989234Z",
-     "iopub.status.idle": "2023-03-01T20:56:21.019858Z",
-     "shell.execute_reply": "2023-03-01T20:56:21.018856Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:20.989234Z"
+     "iopub.execute_input": "2023-03-03T02:50:46.775693Z",
+     "iopub.status.busy": "2023-03-03T02:50:46.775195Z",
+     "iopub.status.idle": "2023-03-03T02:50:46.882206Z",
+     "shell.execute_reply": "2023-03-03T02:50:46.881203Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:46.775195Z"
     },
     "tags": []
    },
    "outputs": [],
    "source": [
-    "class YogaModel(LightningModule):\n",
+    "class MyModel(LightningModule):\n",
     "\n",
     "    def __init__(self, n_classes=10, acc_task=\"multiclass\", lr=1e-3):\n",
     "        super().__init__()\n",
@@ -483,6 +324,8 @@
     "        self.n_classes = n_classes\n",
     "        self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.n_classes)\n",
     "        self.class_names = classes_lst\n",
+    "        self.loss = CrossEntropyLoss()\n",
+    "\n",
     "        # optional - save hyper-parameters to self.hparams\n",
     "        # they will also be automatically logged as config parameters in W&B\n",
     "        self.save_hyperparameters()\n",
@@ -523,6 +366,11 @@
     "        return loss\n",
     "\n",
     "    def validation_step(self,batch,batch_idx):\n",
+    "        preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
+    "        # Log loss and metric\n",
+    "        self.log('val_loss_alt', loss)\n",
+    "        self.log('val_accuracy_alt', acc)\n",
+    "        \n",
     "        x,y = batch\n",
     "        y_pred = self(x)\n",
     "        loss = F.cross_entropy(y_pred,y)\n",
@@ -535,7 +383,7 @@
     "        wandb.log({\"val_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
     "                        y_true=self.cpu_y, preds=None,\n",
     "                        class_names=self.class_names)})\n",
-    "        return loss\n",
+    "        return preds\n",
     "\n",
     "    def test_step(self,batch,batch_idx):\n",
     "        x,y = batch\n",
@@ -550,7 +398,16 @@
     "        wandb.log({\"test_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
     "                        y_true=self.cpu_y, preds=None,\n",
     "                        class_names=self.class_names)})\n",
-    "        return loss"
+    "        return loss\n",
+    "    \n",
+    "    def _get_preds_loss_accuracy(self, batch):\n",
+    "        '''convenience function since train/valid/test steps are similar'''\n",
+    "        x, y = batch\n",
+    "        logits = self(x)\n",
+    "        preds = torch.argmax(logits, dim=1)\n",
+    "        loss = self.loss(logits, y)\n",
+    "        acc = accuracy(preds, y, self.acc_task, num_classes=10)\n",
+    "        return preds, loss, acc"
    ]
   },
   {
@@ -563,43 +420,22 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
-   "id": "e2170c95-2962-43ec-a457-31dfec8a23d2",
-   "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:21.023110Z",
-     "iopub.status.busy": "2023-03-01T20:56:21.022116Z",
-     "iopub.status.idle": "2023-03-01T20:56:21.035162Z",
-     "shell.execute_reply": "2023-03-01T20:56:21.034159Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:21.023110Z"
-    },
-    "tags": []
-   },
-   "outputs": [],
-   "source": [
-    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
-    "\n",
-    "checkpoint_callback = ModelCheckpoint(monitor='val_acc', mode='max')"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 11,
+   "execution_count": 8,
    "id": "188ce4ef-e6b7-4320-8e5d-ceeb616bf7d1",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:21.037696Z",
-     "iopub.status.busy": "2023-03-01T20:56:21.036175Z",
-     "iopub.status.idle": "2023-03-01T20:56:21.050772Z",
-     "shell.execute_reply": "2023-03-01T20:56:21.049776Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:21.037696Z"
+     "iopub.execute_input": "2023-03-03T02:50:46.977734Z",
+     "iopub.status.busy": "2023-03-03T02:50:46.977233Z",
+     "iopub.status.idle": "2023-03-03T02:50:47.067951Z",
+     "shell.execute_reply": "2023-03-03T02:50:47.066950Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:46.977734Z"
     },
     "tags": []
    },
    "outputs": [],
    "source": [
-    "from pytorch_lightning.callbacks import Callback\n",
-    " \n",
+    "checkpoint_callback = ModelCheckpoint(monitor='val_acc', mode='max')\n",
+    "\n",
     "class LogPredictionsCallback(Callback):\n",
     "    \n",
     "    def on_validation_batch_end(\n",
@@ -629,15 +465,15 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 12,
+   "execution_count": 9,
    "id": "762279ca-26d9-4310-992f-b6f8912da7fe",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-01T20:56:21.054045Z",
-     "iopub.status.busy": "2023-03-01T20:56:21.054045Z",
-     "iopub.status.idle": "2023-03-01T20:56:29.581762Z",
-     "shell.execute_reply": "2023-03-01T20:56:29.580856Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:21.054045Z"
+     "iopub.execute_input": "2023-03-03T02:50:47.069450Z",
+     "iopub.status.busy": "2023-03-03T02:50:47.068953Z",
+     "iopub.status.idle": "2023-03-03T02:50:56.878820Z",
+     "shell.execute_reply": "2023-03-03T02:50:56.874823Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:47.069450Z"
     },
     "tags": []
    },
@@ -664,7 +500,7 @@
     {
      "data": {
       "text/html": [
-       "Run data is saved locally in <code>.\\wandb\\run-20230301_155623-r20dbs67</code>"
+       "Run data is saved locally in <code>.\\wandb\\run-20230302_215050-shiyc5fc</code>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -676,7 +512,7 @@
     {
      "data": {
       "text/html": [
-       "Syncing run <strong><a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/r20dbs67' target=\"_blank\">tough-meadow-4</a></strong> to <a href='https://wandb.ai/christopher-marais/computer_vision_test_single' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
+       "Syncing run <strong><a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/shiyc5fc' target=\"_blank\">deep-wind-12</a></strong> to <a href='https://wandb.ai/christopher-marais/computer_vision_test_single' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -700,7 +536,7 @@
     {
      "data": {
       "text/html": [
-       " View run at <a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/r20dbs67' target=\"_blank\">https://wandb.ai/christopher-marais/computer_vision_test_single/runs/r20dbs67</a>"
+       " View run at <a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/shiyc5fc' target=\"_blank\">https://wandb.ai/christopher-marais/computer_vision_test_single/runs/shiyc5fc</a>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -719,19 +555,20 @@
       "HPU available: False, using: 0 HPUs\n",
       "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
       "\n",
-      "  | Name     | Type               | Params\n",
-      "------------------------------------------------\n",
-      "0 | layer_1  | Conv2d             | 30    \n",
-      "1 | layer_2  | Conv2d             | 168   \n",
-      "2 | layer_3  | Conv2d             | 660   \n",
-      "3 | pool     | MaxPool2d          | 0     \n",
-      "4 | layer_5  | Linear             | 30.0 M\n",
-      "5 | layer_6  | Linear             | 100 K \n",
-      "6 | layer_7  | Linear             | 5.0 K \n",
-      "7 | layer_8  | Linear             | 510   \n",
-      "8 | layer_9  | Linear             | 110   \n",
-      "9 | accuracy | MulticlassAccuracy | 0     \n",
-      "------------------------------------------------\n",
+      "   | Name     | Type               | Params\n",
+      "-------------------------------------------------\n",
+      "0  | layer_1  | Conv2d             | 30    \n",
+      "1  | layer_2  | Conv2d             | 168   \n",
+      "2  | layer_3  | Conv2d             | 660   \n",
+      "3  | pool     | MaxPool2d          | 0     \n",
+      "4  | layer_5  | Linear             | 30.0 M\n",
+      "5  | layer_6  | Linear             | 100 K \n",
+      "6  | layer_7  | Linear             | 5.0 K \n",
+      "7  | layer_8  | Linear             | 510   \n",
+      "8  | layer_9  | Linear             | 110   \n",
+      "9  | accuracy | MulticlassAccuracy | 0     \n",
+      "10 | loss     | CrossEntropyLoss   | 0     \n",
+      "-------------------------------------------------\n",
       "30.1 M    Trainable params\n",
       "0         Non-trainable params\n",
       "30.1 M    Total params\n",
@@ -741,7 +578,7 @@
     {
      "data": {
       "application/vnd.jupyter.widget-view+json": {
-       "model_id": "a55cd26ad321421b80f30fb5a2bc2460",
+       "model_id": "90e1c86718ea468db52b4e96a9683a36",
        "version_major": 2,
        "version_minor": 0
       },
@@ -756,42 +593,37 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "C:\\Users\\gcmar\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
+      "C:\\Users\\GCM\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
       "  rank_zero_warn(\n",
-      "C:\\Users\\gcmar\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
+      "C:\\Users\\GCM\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "torch.Size([10, 30000])\n"
-     ]
-    },
-    {
-     "ename": "IndexError",
-     "evalue": "Dimension specified as 0 but tensor has no dimensions",
+     "ename": "AttributeError",
+     "evalue": "'MyModel' object has no attribute '_get_preds_loss_accuracy'",
      "output_type": "error",
      "traceback": [
       "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
-      "Cell \u001b[1;32mIn[12], line 21\u001b[0m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m YogaModel(n_classes\u001b[38;5;241m=\u001b[39mnum_of_classes)\n\u001b[0;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     14\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     15\u001b[0m     devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;66;03m# use all GPU's (-1)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m            \u001b[38;5;66;03m# number of epochs\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     )\n\u001b[1;32m---> 21\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtest(model, datamodule\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m     25\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    606\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m--> 608\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     41\u001b[0m     trainer\u001b[38;5;241m.\u001b[39m_call_teardown_hook()\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    643\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_set_ckpt_path(\n\u001b[0;32m    645\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    646\u001b[0m     ckpt_path,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    647\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    648\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    649\u001b[0m )\n\u001b[1;32m--> 650\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1112\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[1;32m-> 1112\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1114\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1191\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[0;32m   1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1204\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_training_routine()\n\u001b[0;32m   1203\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;66;03m# enable train mode\u001b[39;00m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1276\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m-> 1276\u001b[0m     \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\dataloader\\evaluation_loop.py:152\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_dataloaders \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    151\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dataloader_idx\n\u001b[1;32m--> 152\u001b[0m dl_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_max_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# store batch level output per dataloader\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs\u001b[38;5;241m.\u001b[39mappend(dl_outputs)\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:143\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[1;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# track loss history\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_evaluation_batch_end(output, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_completed()\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# log batch metrics\u001b[39;00m\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:275\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._on_evaluation_batch_end\u001b[1;34m(self, output, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# TODO: the argument should be keyword for these\u001b[39;00m\n\u001b[0;32m    274\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_test_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_validation_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(hook_name, output, \u001b[38;5;241m*\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mon_batch_end()\n",
-      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1394\u001b[0m, in \u001b[0;36mTrainer._call_callback_hooks\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callable(fn):\n\u001b[0;32m   1393\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback\u001b[38;5;241m.\u001b[39mstate_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1394\u001b[0m             fn(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[0;32m   1397\u001b[0m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m   1398\u001b[0m     pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
-      "Cell \u001b[1;32mIn[11], line 17\u001b[0m, in \u001b[0;36mLogPredictionsCallback.on_validation_batch_end\u001b[1;34m(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[0;32m     15\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m     16\u001b[0m images \u001b[38;5;241m=\u001b[39m [img \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m x[:n]]\n\u001b[1;32m---> 17\u001b[0m captions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGround Truth: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_i\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Prediction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_pred\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m y_i, y_pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(y[:n], \u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m)]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Option 1: log images with `WandbLogger.log_image`\u001b[39;00m\n\u001b[0;32m     20\u001b[0m wandb_logger\u001b[38;5;241m.\u001b[39mlog_image(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_images\u001b[39m\u001b[38;5;124m'\u001b[39m, images\u001b[38;5;241m=\u001b[39mimages, caption\u001b[38;5;241m=\u001b[39mcaptions)\n",
-      "\u001b[1;31mIndexError\u001b[0m: Dimension specified as 0 but tensor has no dimensions"
+      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
+      "Cell \u001b[1;32mIn[9], line 21\u001b[0m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m MyModel(n_classes\u001b[38;5;241m=\u001b[39mnum_of_classes)\n\u001b[0;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     14\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     15\u001b[0m     devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;66;03m# use all GPU's (-1)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m            \u001b[38;5;66;03m# number of epochs\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     )\n\u001b[1;32m---> 21\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtest(model, datamodule\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m     25\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Trainer.fit()` requires a `LightningModule`, got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m--> 608\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     41\u001b[0m     trainer\u001b[38;5;241m.\u001b[39m_call_teardown_hook()\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    643\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_set_ckpt_path(\n\u001b[0;32m    645\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    646\u001b[0m     ckpt_path,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    647\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    648\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    649\u001b[0m )\n\u001b[1;32m--> 650\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1103\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[1;32m-> 1103\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1182\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[1;32m-> 1182\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1195\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_training_routine()\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1195\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[38;5;66;03m# enable train mode\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1267\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m-> 1267\u001b[0m     \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\dataloader\\evaluation_loop.py:152\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_dataloaders \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    151\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dataloader_idx\n\u001b[1;32m--> 152\u001b[0m dl_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_max_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# store batch level output per dataloader\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs\u001b[38;5;241m.\u001b[39mappend(dl_outputs)\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:137\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[1;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# lightning module methods\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step_end(output)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:234\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"The evaluation step (validation_step or test_step depending on the trainer's state).\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124;03m    the outputs of the step\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    233\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 234\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1485\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1485\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m   1488\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:390\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mval_step_context():\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, ValidationStep)\n\u001b[1;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mvalidation_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
+      "Cell \u001b[1;32mIn[6], line 65\u001b[0m, in \u001b[0;36mMyModel.validation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m,batch,batch_idx):\n\u001b[1;32m---> 65\u001b[0m     preds, loss, acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_preds_loss_accuracy\u001b[49m(batch)\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Log loss and metric\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss_alt\u001b[39m\u001b[38;5;124m'\u001b[39m, loss)\n",
+      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1269\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1269\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
+      "\u001b[1;31mAttributeError\u001b[0m: 'MyModel' object has no attribute '_get_preds_loss_accuracy'"
      ]
     }
    ],
@@ -802,10 +634,10 @@
     "# TRAIN\n",
     "# setup data\n",
     "# data = MNISTDataModule()\n",
-    "data = YogaDataModule()\n",
+    "data = DataModule()\n",
     "\n",
     "# setup model - choose different hyperparameters per experiment\n",
-    "model = YogaModel(n_classes=num_of_classes)\n",
+    "model = MyModel(n_classes=num_of_classes)\n",
     "\n",
     "\n",
     "trainer = Trainer(\n",
@@ -813,7 +645,7 @@
     "    devices=-1, # use all GPU's (-1)\n",
     "    callbacks=[log_predictions_callback,checkpoint_callback],\n",
     "    logger=wandb_logger,    # W&B integration\n",
-    "    max_epochs=3            # number of epochs\n",
+    "    max_epochs=100            # number of epochs\n",
     "    )\n",
     "\n",
     "trainer.fit(model, data)\n",
@@ -829,10 +661,10 @@
    "id": "3b58022d-6961-41b0-a4e1-60bbc1c09791",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-01T20:56:29.583762Z",
-     "iopub.status.idle": "2023-03-01T20:56:29.584765Z",
-     "shell.execute_reply": "2023-03-01T20:56:29.583762Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:29.583762Z"
+     "iopub.status.busy": "2023-03-03T02:50:56.880321Z",
+     "iopub.status.idle": "2023-03-03T02:50:56.880819Z",
+     "shell.execute_reply": "2023-03-03T02:50:56.880819Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:56.880321Z"
     },
     "tags": []
    },
@@ -855,10 +687,10 @@
    "id": "ebde1018-ddfa-43f2-b9c6-f2c1d4b19736",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-01T20:56:29.585969Z",
-     "iopub.status.idle": "2023-03-01T20:56:29.586972Z",
-     "shell.execute_reply": "2023-03-01T20:56:29.586972Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:29.586972Z"
+     "iopub.status.busy": "2023-03-03T02:50:56.882819Z",
+     "iopub.status.idle": "2023-03-03T02:50:56.883821Z",
+     "shell.execute_reply": "2023-03-03T02:50:56.883318Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:56.883318Z"
     },
     "tags": []
    },
@@ -901,10 +733,10 @@
    "id": "91aeb8a0-9ffd-4439-808c-2951d1f74b36",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-01T20:56:29.589019Z",
-     "iopub.status.idle": "2023-03-01T20:56:29.589019Z",
-     "shell.execute_reply": "2023-03-01T20:56:29.589019Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:29.589019Z"
+     "iopub.status.busy": "2023-03-03T02:50:56.885820Z",
+     "iopub.status.idle": "2023-03-03T02:50:56.886320Z",
+     "shell.execute_reply": "2023-03-03T02:50:56.885820Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:56.885820Z"
     },
     "tags": []
    },
@@ -917,7 +749,7 @@
     "\n",
     "    # setup data\n",
     "    # data = MNISTDataModule()\n",
-    "    data = YogaDataModule()\n",
+    "    data = DataModule()\n",
     "\n",
     "    # setup model - note how we refer to sweep parameters with wandb.config\n",
     "    # model = LitMNIST(\n",
@@ -925,7 +757,7 @@
     "    #     n_layer_2=wandb.config.n_layer_2,\n",
     "    #     lr=wandb.config.lr\n",
     "    # )\n",
-    "    model = YogaModel(lr=wandb.config.lr, n_classes=num_of_classes)\n",
+    "    model = MyModel(lr=wandb.config.lr, n_classes=num_of_classes)\n",
     "\n",
     "    # setup Trainer\n",
     "    trainer = Trainer(\n",
@@ -944,10 +776,10 @@
    "id": "869b0393-21cf-4fba-8efd-7678a852b697",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-01T20:56:29.591016Z",
-     "iopub.status.idle": "2023-03-01T20:56:29.592018Z",
-     "shell.execute_reply": "2023-03-01T20:56:29.592018Z",
-     "shell.execute_reply.started": "2023-03-01T20:56:29.592018Z"
+     "iopub.status.busy": "2023-03-03T02:50:56.887320Z",
+     "iopub.status.idle": "2023-03-03T02:50:56.888321Z",
+     "shell.execute_reply": "2023-03-03T02:50:56.887819Z",
+     "shell.execute_reply.started": "2023-03-03T02:50:56.887819Z"
     },
     "tags": []
    },
diff --git a/Train/wandb/debug-cli.GCM.log b/Train/wandb/debug-cli.GCM.log
index db5ddbf..5aca688 100644
--- a/Train/wandb/debug-cli.GCM.log
+++ b/Train/wandb/debug-cli.GCM.log
@@ -1,111 +1,118 @@
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:53 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:53 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:53 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:17 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:17 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:05 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:05 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:05 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:53 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:53 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:53 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:17 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:17 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:05 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:05 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:05 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-03-02 21:28:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-03-02 21:28:11 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-03-02 21:28:50 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-03-02 21:28:56 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-03-02 21:33:34 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-03-02 21:35:11 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-03-02 21:35:17 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
