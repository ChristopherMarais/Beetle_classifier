diff --git a/Train/.ipynb_checkpoints/PyLi_wanb_sweep_CoatNet-checkpoint.ipynb b/Train/.ipynb_checkpoints/PyLi_wanb_sweep_CoatNet-checkpoint.ipynb
index b3f7aa6..d994032 100644
--- a/Train/.ipynb_checkpoints/PyLi_wanb_sweep_CoatNet-checkpoint.ipynb
+++ b/Train/.ipynb_checkpoints/PyLi_wanb_sweep_CoatNet-checkpoint.ipynb
@@ -2,16 +2,9 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": null,
    "id": "c7b471f1-f5fa-4eb1-b9ae-2d67ed8838df",
    "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:21.824252Z",
-     "iopub.status.busy": "2023-03-08T17:10:21.824252Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.893295Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.892300Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:21.824252Z"
-    },
     "tags": []
    },
    "outputs": [],
@@ -70,46 +63,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": null,
    "id": "01c28e3c-850d-48b6-8db9-3a8804e0c9ae",
    "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.896303Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.895302Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.924332Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.923339Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.895302Z"
-    },
     "tags": []
    },
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Total Number of Classes : 10\n"
-     ]
-    },
-    {
-     "data": {
-      "text/plain": [
-       "{'0': 0,\n",
-       " '1': 1,\n",
-       " '2': 2,\n",
-       " '3': 3,\n",
-       " '4': 4,\n",
-       " '5': 5,\n",
-       " '6': 6,\n",
-       " '7': 7,\n",
-       " '8': 8,\n",
-       " '9': 9}"
-      ]
-     },
-     "execution_count": 2,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "# declaring the path of the train and test folders\n",
     "train_path = \"DATASET_C/TRAIN\"\n",
@@ -137,16 +96,9 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": null,
    "id": "8b9e722b-cda4-4956-a0c1-8eb31023f765",
    "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.926331Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.926331Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.939867Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.938864Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.926331Z"
-    },
     "tags": []
    },
    "outputs": [],
@@ -185,21 +137,14 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": null,
    "id": "9dbe4b19-9805-40b4-a513-ea35715a0c64",
    "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.940865Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.940865Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.953853Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.953853Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.940865Z"
-    },
     "tags": []
    },
    "outputs": [],
    "source": [
-    "size = 50 # need to be the same as what is used in layer_5/ input layer ot the cnn\n",
+    "size = 224 # need to be the same as what is used in layer_5/ input layer ot the cnn\n",
     "\n",
     "basic_transformations = transforms.Compose([\n",
     "    transforms.ToPILImage(),\n",
@@ -221,16 +166,9 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": null,
    "id": "7539d3a5-ca4f-4ba3-a462-05875d4b9a90",
    "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.956852Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.955851Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.970854Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.969851Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.956852Z"
-    },
     "tags": []
    },
    "outputs": [],
@@ -242,17 +180,64 @@
     "\n",
     "    def prepare_data(self):\n",
     "        self.train = Image_Dataset(classes_dir_data,train_path,training_transformations,target_transformations)\n",
-    "        self.valid = Image_Dataset(classes_dir_data,test_path,basic_transformations,target_transformations)\n",
+    "        self.valid = Image_Dataset(classes_dir_data,train_path,basic_transformations,target_transformations)\n",
     "        self.test = Image_Dataset(classes_dir_data,test_path,basic_transformations,target_transformations)\n",
     "\n",
     "    def train_dataloader(self):\n",
-    "        return DataLoader(self.train,batch_size = 64,shuffle = True)#False, num_workers = cpu_count)\n",
+    "        return DataLoader(self.train,batch_size = 8,shuffle = True)#False, num_workers = cpu_count)\n",
     "\n",
     "    def val_dataloader(self):  \n",
-    "        return DataLoader(self.valid,batch_size = 64,shuffle = True)#False, num_workers = cpu_count)\n",
+    "        return DataLoader(self.valid,batch_size = 8,shuffle = True)#False, num_workers = cpu_count)\n",
     "\n",
     "    def test_dataloader(self):\n",
-    "        return DataLoader(self.test,batch_size = 64,shuffle = True)#False, num_workers = cpu_count)"
+    "        return DataLoader(self.test,batch_size = 8,shuffle = True)#False, num_workers = cpu_count)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "66eadea7-8c62-4c3f-93d6-ee1bf7b03494",
+   "metadata": {
+    "tags": []
+   },
+   "outputs": [],
+   "source": [
+    "# import matplotlib.pyplot as plt\n",
+    "# train_img_dataset = Image_Dataset(classes_dir_data,train_path,training_transformations,target_transformations)\n",
+    "# train_loader_obj = DataLoader(train_img_dataset, batch_size = 8, shuffle = True)\n",
+    "\n",
+    "# # Display image and label.\n",
+    "# train_features, train_labels = next(iter(train_loader_obj))\n",
+    "# print(f\"Feature batch shape: {train_features.size()}\")\n",
+    "# print(f\"Labels batch shape: {train_labels.size()}\")\n",
+    "# img = train_features[0].squeeze()\n",
+    "# label = train_labels[0]\n",
+    "# plt.imshow(img, cmap=\"gray\")\n",
+    "# plt.show()\n",
+    "# print(f\"Label: {label}\")"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "958c02c1-2355-4c2d-85e4-31a101fdf612",
+   "metadata": {
+    "tags": []
+   },
+   "outputs": [],
+   "source": [
+    "# test_img_dataset = Image_Dataset(classes_dir_data,test_path,basic_transformations,target_transformations)\n",
+    "# test_loader_obj = DataLoader(test_img_dataset, batch_size = 8, shuffle = True)\n",
+    "\n",
+    "# # Display image and label.\n",
+    "# train_features, train_labels = next(iter(test_loader_obj))\n",
+    "# print(f\"Feature batch shape: {train_features.size()}\")\n",
+    "# print(f\"Labels batch shape: {train_labels.size()}\")\n",
+    "# img = train_features[0].squeeze()\n",
+    "# label = train_labels[0]\n",
+    "# plt.imshow(img, cmap=\"gray\")\n",
+    "# plt.show()\n",
+    "# print(f\"Label: {label}\")"
    ]
   },
   {
@@ -273,159 +258,23 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
-   "id": "deb34aed-792a-4022-a878-f8d6c4ffa97c",
-   "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.972851Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.971852Z",
-     "iopub.status.idle": "2023-03-08T17:10:27.000852Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.999851Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.972851Z"
-    },
-    "tags": []
-   },
-   "outputs": [],
-   "source": [
-    "class MyModel(LightningModule):\n",
-    "\n",
-    "    def __init__(self, classes_lst, n_classes=10, acc_task=\"multiclass\", lr=1e-3):\n",
-    "        super().__init__()\n",
-    "        \n",
-    "        \n",
-    "        \"\"\"\n",
-    "        The convolutions are arranged in such a way that the image maintain the x and y dimensions. only the channels change\n",
-    "        \"\"\"\n",
-    "        self.layer_1 = nn.Conv2d(in_channels = 1,out_channels = 3,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "        self.layer_2 = nn.Conv2d(in_channels = 3,out_channels = 6,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "        self.layer_3 = nn.Conv2d(in_channels = 6,out_channels = 12,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "        self.pool = nn.MaxPool2d(kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "        self.layer_5 = nn.Linear(12*50*50,1000)#the input dimensions are (Number of dimensions * height * width)\n",
-    "        self.layer_6 = nn.Linear(1000,100)\n",
-    "        self.layer_7 = nn.Linear(100,50)\n",
-    "        self.layer_8 = nn.Linear(50,10)\n",
-    "        self.layer_9 = nn.Linear(10,10)\n",
-    "        \n",
-    "        \n",
-    "        \n",
-    "        # metrics\n",
-    "        self.acc_task = acc_task\n",
-    "        self.lr = lr\n",
-    "        self.n_classes = n_classes\n",
-    "        self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.n_classes)\n",
-    "        self.class_names = classes_lst\n",
-    "        self.loss = CrossEntropyLoss()\n",
-    "\n",
-    "        # optional - save hyper-parameters to self.hparams\n",
-    "        # they will also be automatically logged as config parameters in W&B\n",
-    "        self.save_hyperparameters()\n",
-    "\n",
-    "    def forward(self,x):\n",
-    "        \"\"\"\n",
-    "        x is the input data\n",
-    "        \"\"\"\n",
-    "        x = self.layer_1(x)\n",
-    "        x = self.pool(x)\n",
-    "        x = self.layer_2(x)\n",
-    "        x = self.pool(x)\n",
-    "        x = self.layer_3(x)\n",
-    "        x = self.pool(x)\n",
-    "        x = x.view(x.size(0),-1)\n",
-    "        print(x.size())\n",
-    "        x = self.layer_5(x)\n",
-    "        x = self.layer_6(x)\n",
-    "        x = self.layer_7(x)\n",
-    "        x = self.layer_8(x)\n",
-    "        x = self.layer_9(x)\n",
-    "        return x\n",
-    "\n",
-    "    def configure_optimizers(self):\n",
-    "        optimizer = torch.optim.Adam(self.parameters(),lr = self.lr)\n",
-    "        return optimizer\n",
-    "\n",
-    "# The Pytorch-Lightning module handles all the iterations of the epoch\n",
-    "\n",
-    "    def training_step(self,batch,batch_idx):\n",
-    "        x,y = batch\n",
-    "        y_pred = self(x)\n",
-    "        loss = F.cross_entropy(y_pred,y)\n",
-    "        # Log training loss\n",
-    "        self.log('train_loss', loss)\n",
-    "        # Log metrics\n",
-    "        self.log('train_acc', self.accuracy(y_pred, y))\n",
-    "        return loss\n",
-    "\n",
-    "    def validation_step(self,batch,batch_idx):\n",
-    "        preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
-    "        # Log loss and metric\n",
-    "        self.log('val_loss_alt', loss)\n",
-    "        self.log('val_accuracy_alt', acc)\n",
-    "        \n",
-    "        x,y = batch\n",
-    "        y_pred = self(x)\n",
-    "        loss = F.cross_entropy(y_pred,y)\n",
-    "        # Log training loss\n",
-    "        self.log('val_loss', loss)\n",
-    "        # Log metrics\n",
-    "        self.log('val_acc', self.accuracy(y_pred, y))\n",
-    "        self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
-    "        self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
-    "        wandb.log({\"val_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
-    "                        y_true=self.cpu_y, preds=None,\n",
-    "                        class_names=self.class_names)})\n",
-    "        return preds\n",
-    "\n",
-    "    def test_step(self,batch,batch_idx):\n",
-    "        x,y = batch\n",
-    "        y_pred = self(x)\n",
-    "        loss = F.cross_entropy(y_pred,y)\n",
-    "        # Log training loss\n",
-    "        self.log('test_loss', loss)\n",
-    "        # Log metrics\n",
-    "        self.log('test_acc', self.accuracy(y_pred, y))\n",
-    "        self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
-    "        self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
-    "        wandb.log({\"test_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
-    "                        y_true=self.cpu_y, preds=None,\n",
-    "                        class_names=self.class_names)})\n",
-    "        return loss\n",
-    "    \n",
-    "    def _get_preds_loss_accuracy(self, batch):\n",
-    "        '''convenience function since train/valid/test steps are similar'''\n",
-    "        x, y = batch\n",
-    "        logits = self(x)\n",
-    "        preds = torch.argmax(logits, dim=1)\n",
-    "        loss = self.loss(logits, y)\n",
-    "        acc = accuracy(preds, y, self.acc_task, num_classes=10)\n",
-    "        return preds, loss, acc"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 7,
+   "execution_count": null,
    "id": "1816bdd2-4846-4dee-a595-190697564b38",
    "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:27.002857Z",
-     "iopub.status.busy": "2023-03-08T17:10:27.001851Z",
-     "iopub.status.idle": "2023-03-08T17:10:27.032396Z",
-     "shell.execute_reply": "2023-03-08T17:10:27.031390Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:27.002857Z"
-    },
     "tags": []
    },
    "outputs": [],
    "source": [
     "class MyModel(LightningModule):\n",
     "\n",
-    "    def __init__(self, classes_lst, input_shape=(1,224,224), n_classes=10, acc_task=\"multiclass\", lr=1e-3, transfer=False): #input_shape=(3,224,224) image shape\n",
+    "    def __init__(self, classes_lst, input_shape, num_classes=10, acc_task=\"multiclass\", lr=1e-3, transfer=False): #input_shape=(3,224,224) image shape\n",
     "        super().__init__()\n",
     "        \n",
     "        # metrics\n",
     "        self.acc_task = acc_task\n",
     "        self.lr = lr\n",
-    "        self.n_classes = n_classes\n",
-    "        self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.n_classes)\n",
+    "        self.num_classes = num_classes\n",
+    "        self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.num_classes)\n",
     "        self.class_names = classes_lst\n",
     "        self.loss = CrossEntropyLoss()\n",
     "        \n",
@@ -528,118 +377,6 @@
     "        return preds, loss, acc"
    ]
   },
-  {
-   "cell_type": "code",
-   "execution_count": 8,
-   "id": "f87009dd-3c3a-409c-ada8-3f991d17d0c1",
-   "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:27.034398Z",
-     "iopub.status.busy": "2023-03-08T17:10:27.033399Z",
-     "iopub.status.idle": "2023-03-08T17:10:27.049387Z",
-     "shell.execute_reply": "2023-03-08T17:10:27.047400Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:27.034398Z"
-    }
-   },
-   "outputs": [],
-   "source": [
-    "# class MyModel(pl.LightningModule):\n",
-    "#     def __init__(self, input_shape, n_classes=10, lr=2e-4, transfer=False):\n",
-    "#         super().__init__()\n",
-    "        \n",
-    "#         # log hyperparameters\n",
-    "#         self.save_hyperparameters()\n",
-    "#         self.learning_rate = lr\n",
-    "#         self.dim = input_shape\n",
-    "#         self.num_classes = num_classes\n",
-    "        \n",
-    "#         # transfer learning if pretrained=True\n",
-    "#         self.feature_extractor = models.resnet18(pretrained=transfer)\n",
-    "\n",
-    "#         if transfer:\n",
-    "#             # layers are frozen by using eval()\n",
-    "#             self.feature_extractor.eval()\n",
-    "#             # freeze params\n",
-    "#             for param in self.feature_extractor.parameters():\n",
-    "#                 param.requires_grad = False\n",
-    "        \n",
-    "#         n_sizes = self._get_conv_output(input_shape)\n",
-    "\n",
-    "#         self.classifier = nn.Linear(n_sizes, num_classes)\n",
-    "\n",
-    "#         self.criterion = nn.CrossEntropyLoss()\n",
-    "#         self.accuracy = Accuracy()\n",
-    "  \n",
-    "#     # returns the size of the output tensor going into the Linear layer from the conv block.\n",
-    "#     def _get_conv_output(self, shape):\n",
-    "#         batch_size = 1\n",
-    "#         tmp_input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
-    "\n",
-    "#         output_feat = self._forward_features(tmp_input) \n",
-    "#         n_size = output_feat.data.view(batch_size, -1).size(1)\n",
-    "#         return n_size\n",
-    "        \n",
-    "#     # returns the feature tensor from the conv block\n",
-    "#     def _forward_features(self, x):\n",
-    "#         x = self.feature_extractor(x)\n",
-    "#         return x\n",
-    "    \n",
-    "#     # will be used during inference\n",
-    "#     def forward(self, x):\n",
-    "#         x = self._forward_features(x)\n",
-    "#         x = x.view(x.size(0), -1)\n",
-    "#         x = self.classifier(x)\n",
-    "\n",
-    "#         return x\n",
-    "    \n",
-    "#     def training_step(self, batch):\n",
-    "#         batch, gt = batch[0], batch[1]\n",
-    "#         out = self.forward(batch)\n",
-    "#         loss = self.criterion(out, gt)\n",
-    "\n",
-    "#         acc = self.accuracy(out, gt)\n",
-    "\n",
-    "#         self.log(\"train/loss\", loss)\n",
-    "#         self.log(\"train/acc\", acc)\n",
-    "\n",
-    "#         return loss\n",
-    "    \n",
-    "#     def validation_step(self, batch, batch_idx):\n",
-    "#         batch, gt = batch[0], batch[1]\n",
-    "#         out = self.forward(batch)\n",
-    "#         loss = self.criterion(out, gt)\n",
-    "\n",
-    "#         self.log(\"val/loss\", loss)\n",
-    "\n",
-    "#         acc = self.accuracy(out, gt)\n",
-    "#         self.log(\"val/acc\", acc)\n",
-    "\n",
-    "#         return loss\n",
-    "    \n",
-    "#     def test_step(self, batch, batch_idx):\n",
-    "#         batch, gt = batch[0], batch[1]\n",
-    "#         out = self.forward(batch)\n",
-    "#         loss = self.criterion(out, gt)\n",
-    "        \n",
-    "#         return {\"loss\": loss, \"outputs\": out, \"gt\": gt}\n",
-    "    \n",
-    "#     def test_epoch_end(self, outputs):\n",
-    "#         loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
-    "#         output = torch.cat([x['outputs'] for x in outputs], dim=0)\n",
-    "        \n",
-    "#         gts = torch.cat([x['gt'] for x in outputs], dim=0)\n",
-    "        \n",
-    "#         self.log(\"test/loss\", loss)\n",
-    "#         acc = self.accuracy(output, gts)\n",
-    "#         self.log(\"test/acc\", acc)\n",
-    "        \n",
-    "#         self.test_gts = gts\n",
-    "#         self.test_output = output\n",
-    "    \n",
-    "#     def configure_optimizers(self):\n",
-    "#         return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
-   ]
-  },
   {
    "cell_type": "markdown",
    "id": "f561a2e3-1272-4e67-9322-dd9b7534fed3",
@@ -650,16 +387,9 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": null,
    "id": "188ce4ef-e6b7-4320-8e5d-ceeb616bf7d1",
    "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:27.051399Z",
-     "iopub.status.busy": "2023-03-08T17:10:27.050393Z",
-     "iopub.status.idle": "2023-03-08T17:10:27.063388Z",
-     "shell.execute_reply": "2023-03-08T17:10:27.062386Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:27.051399Z"
-    },
     "tags": []
    },
    "outputs": [],
@@ -695,112 +425,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
+   "execution_count": null,
    "id": "762279ca-26d9-4310-992f-b6f8912da7fe",
    "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:27.065390Z",
-     "iopub.status.busy": "2023-03-08T17:10:27.064390Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.633996Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.631459Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:27.065390Z"
-    },
     "tags": []
    },
-   "outputs": [
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristopher-marais\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
-     ]
-    },
-    {
-     "data": {
-      "text/html": [
-       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
-       " $ pip install wandb --upgrade"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       "Tracking run with wandb version 0.13.10"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       "Run data is saved locally in <code>.\\wandb\\run-20230308_121030-fq5x8q4o</code>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       "Syncing run <strong><a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/fq5x8q4o' target=\"_blank\">fallen-shadow-43</a></strong> to <a href='https://wandb.ai/christopher-marais/computer_vision_test_single' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       " View project at <a href='https://wandb.ai/christopher-marais/computer_vision_test_single' target=\"_blank\">https://wandb.ai/christopher-marais/computer_vision_test_single</a>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       " View run at <a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/fq5x8q4o' target=\"_blank\">https://wandb.ai/christopher-marais/computer_vision_test_single/runs/fq5x8q4o</a>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "ename": "NameError",
-     "evalue": "name 'models' is not defined",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
-      "Cell \u001b[1;32mIn[10], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m DataModule()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# setup model - choose different hyperparameters per experiment\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMyModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclasses_lst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses_lst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_of_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     14\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     15\u001b[0m     devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;66;03m# use all GPU's (-1)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m            \u001b[38;5;66;03m# number of epochs\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     )\n",
-      "Cell \u001b[1;32mIn[7], line 15\u001b[0m, in \u001b[0;36mMyModel.__init__\u001b[1;34m(self, classes_lst, input_shape, n_classes, acc_task, lr, transfer)\u001b[0m\n\u001b[0;32m     12\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# transfer learning if pretrained=True\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241m.\u001b[39mresnet18(pretrained\u001b[38;5;241m=\u001b[39mtransfer)\n\u001b[0;32m     17\u001b[0m  \u001b[38;5;28;01mif\u001b[39;00m transfer:\n\u001b[0;32m     18\u001b[0m      \u001b[38;5;66;03m# layers are frozen by using eval()\u001b[39;00m\n\u001b[0;32m     19\u001b[0m      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor\u001b[38;5;241m.\u001b[39meval()\n",
-      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "wandb.login()\n",
     "wandb_logger = WandbLogger(project='computer_vision_test_single', log_model=True)\n",
@@ -811,7 +441,7 @@
     "data = DataModule()\n",
     "\n",
     "# setup model - choose different hyperparameters per experiment\n",
-    "model = MyModel(classes_lst=classes_lst, n_classes=num_of_classes, input_shape=(3,224,224))\n",
+    "model = MyModel(classes_lst=classes_lst, num_classes=num_of_classes, input_shape=(3,224,224))\n",
     "\n",
     "\n",
     "trainer = Trainer(\n",
@@ -828,12 +458,7 @@
    "execution_count": null,
    "id": "05c5995d-f9be-4377-bfc0-ea1298711b12",
    "metadata": {
-    "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.635025Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.636024Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.635025Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.635025Z"
-    }
+    "tags": []
    },
    "outputs": [],
    "source": [
@@ -844,14 +469,7 @@
    "cell_type": "code",
    "execution_count": null,
    "id": "28625e66-e2a3-4a91-acce-e2948485412b",
-   "metadata": {
-    "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.637021Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.638026Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.637021Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.637021Z"
-    }
-   },
+   "metadata": {},
    "outputs": [],
    "source": [
     "trainer.test(model, datamodule=data)"
@@ -862,12 +480,6 @@
    "execution_count": null,
    "id": "378d95e1-4e29-4c7f-bd8c-eaa16677a063",
    "metadata": {
-    "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.639013Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.639013Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.639013Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.639013Z"
-    },
     "tags": []
    },
    "outputs": [],
@@ -879,14 +491,7 @@
    "cell_type": "code",
    "execution_count": null,
    "id": "91967e96-f127-4758-b427-c996a9fcb4dc",
-   "metadata": {
-    "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.641013Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.642013Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.642013Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.642013Z"
-    }
-   },
+   "metadata": {},
    "outputs": [],
    "source": [
     "# wandb_logger.experiment.finish()"
@@ -896,21 +501,21 @@
    "cell_type": "code",
    "execution_count": null,
    "id": "f04c136e-5986-4628-88b7-38a8b433f654",
-   "metadata": {},
+   "metadata": {
+    "tags": []
+   },
    "outputs": [],
-   "source": []
+   "source": [
+    "data = data.train_dataloader.dataset.data \n",
+    "shape = train_iterator.dataset.data.shape  \n",
+    "datatype = train_iterator.dataset.data.dtype"
+   ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "id": "3b58022d-6961-41b0-a4e1-60bbc1c09791",
    "metadata": {
-    "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.643011Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.644008Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.644008Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.644008Z"
-    },
     "tags": []
    },
    "outputs": [],
@@ -931,12 +536,6 @@
    "execution_count": null,
    "id": "ebde1018-ddfa-43f2-b9c6-f2c1d4b19736",
    "metadata": {
-    "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.645011Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.646017Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.646017Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.646017Z"
-    },
     "tags": []
    },
    "outputs": [],
@@ -977,12 +576,6 @@
    "execution_count": null,
    "id": "91aeb8a0-9ffd-4439-808c-2951d1f74b36",
    "metadata": {
-    "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.648016Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.649014Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.649014Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.649014Z"
-    },
     "tags": []
    },
    "outputs": [],
@@ -1002,7 +595,7 @@
     "    #     n_layer_2=wandb.config.n_layer_2,\n",
     "    #     lr=wandb.config.lr\n",
     "    # )\n",
-    "    model = MyModel(lr=wandb.config.lr, n_classes=num_of_classes)\n",
+    "    model = MyModel(lr=wandb.config.lr, num_classes=num_of_classes)\n",
     "\n",
     "    # setup Trainer\n",
     "    trainer = Trainer(\n",
@@ -1020,12 +613,6 @@
    "execution_count": null,
    "id": "869b0393-21cf-4fba-8efd-7678a852b697",
    "metadata": {
-    "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.650013Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.651012Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.651012Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.651012Z"
-    },
     "tags": []
    },
    "outputs": [],
@@ -1041,6 +628,234 @@
    "metadata": {},
    "outputs": [],
    "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "f87009dd-3c3a-409c-ada8-3f991d17d0c1",
+   "metadata": {
+    "tags": []
+   },
+   "outputs": [],
+   "source": [
+    "# class MyModel(pl.LightningModule):\n",
+    "#     def __init__(self, input_shape, num_classes=10, lr=2e-4, transfer=False):\n",
+    "#         super().__init__()\n",
+    "        \n",
+    "#         # log hyperparameters\n",
+    "#         self.save_hyperparameters()\n",
+    "#         self.learning_rate = lr\n",
+    "#         self.dim = input_shape\n",
+    "#         self.num_classes = num_classes\n",
+    "        \n",
+    "#         # transfer learning if pretrained=True\n",
+    "#         self.feature_extractor = models.resnet18(pretrained=transfer)\n",
+    "\n",
+    "#         if transfer:\n",
+    "#             # layers are frozen by using eval()\n",
+    "#             self.feature_extractor.eval()\n",
+    "#             # freeze params\n",
+    "#             for param in self.feature_extractor.parameters():\n",
+    "#                 param.requires_grad = False\n",
+    "        \n",
+    "#         n_sizes = self._get_conv_output(input_shape)\n",
+    "\n",
+    "#         self.classifier = nn.Linear(n_sizes, num_classes)\n",
+    "\n",
+    "#         self.criterion = nn.CrossEntropyLoss()\n",
+    "#         self.accuracy = Accuracy()\n",
+    "  \n",
+    "#     # returns the size of the output tensor going into the Linear layer from the conv block.\n",
+    "#     def _get_conv_output(self, shape):\n",
+    "#         batch_size = 1\n",
+    "#         tmp_input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
+    "\n",
+    "#         output_feat = self._forward_features(tmp_input) \n",
+    "#         n_size = output_feat.data.view(batch_size, -1).size(1)\n",
+    "#         return n_size\n",
+    "        \n",
+    "#     # returns the feature tensor from the conv block\n",
+    "#     def _forward_features(self, x):\n",
+    "#         x = self.feature_extractor(x)\n",
+    "#         return x\n",
+    "    \n",
+    "#     # will be used during inference\n",
+    "#     def forward(self, x):\n",
+    "#         x = self._forward_features(x)\n",
+    "#         x = x.view(x.size(0), -1)\n",
+    "#         x = self.classifier(x)\n",
+    "\n",
+    "#         return x\n",
+    "    \n",
+    "#     def training_step(self, batch):\n",
+    "#         batch, gt = batch[0], batch[1]\n",
+    "#         out = self.forward(batch)\n",
+    "#         loss = self.criterion(out, gt)\n",
+    "\n",
+    "#         acc = self.accuracy(out, gt)\n",
+    "\n",
+    "#         self.log(\"train/loss\", loss)\n",
+    "#         self.log(\"train/acc\", acc)\n",
+    "\n",
+    "#         return loss\n",
+    "    \n",
+    "#     def validation_step(self, batch, batch_idx):\n",
+    "#         batch, gt = batch[0], batch[1]\n",
+    "#         out = self.forward(batch)\n",
+    "#         loss = self.criterion(out, gt)\n",
+    "\n",
+    "#         self.log(\"val/loss\", loss)\n",
+    "\n",
+    "#         acc = self.accuracy(out, gt)\n",
+    "#         self.log(\"val/acc\", acc)\n",
+    "\n",
+    "#         return loss\n",
+    "    \n",
+    "#     def test_step(self, batch, batch_idx):\n",
+    "#         batch, gt = batch[0], batch[1]\n",
+    "#         out = self.forward(batch)\n",
+    "#         loss = self.criterion(out, gt)\n",
+    "        \n",
+    "#         return {\"loss\": loss, \"outputs\": out, \"gt\": gt}\n",
+    "    \n",
+    "#     def test_epoch_end(self, outputs):\n",
+    "#         loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
+    "#         output = torch.cat([x['outputs'] for x in outputs], dim=0)\n",
+    "        \n",
+    "#         gts = torch.cat([x['gt'] for x in outputs], dim=0)\n",
+    "        \n",
+    "#         self.log(\"test/loss\", loss)\n",
+    "#         acc = self.accuracy(output, gts)\n",
+    "#         self.log(\"test/acc\", acc)\n",
+    "        \n",
+    "#         self.test_gts = gts\n",
+    "#         self.test_output = output\n",
+    "    \n",
+    "#     def configure_optimizers(self):\n",
+    "#         return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "deb34aed-792a-4022-a878-f8d6c4ffa97c",
+   "metadata": {
+    "tags": []
+   },
+   "outputs": [],
+   "source": [
+    "# class MyModel(LightningModule):\n",
+    "\n",
+    "#     def __init__(self, classes_lst, num_classes=10, acc_task=\"multiclass\", lr=1e-3):\n",
+    "#         super().__init__()\n",
+    "        \n",
+    "        \n",
+    "#         \"\"\"\n",
+    "#         The convolutions are arranged in such a way that the image maintain the x and y dimensions. only the channels change\n",
+    "#         \"\"\"\n",
+    "#         self.layer_1 = nn.Conv2d(in_channels = 1,out_channels = 3,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "#         self.layer_2 = nn.Conv2d(in_channels = 3,out_channels = 6,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "#         self.layer_3 = nn.Conv2d(in_channels = 6,out_channels = 12,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "#         self.pool = nn.MaxPool2d(kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "#         self.layer_5 = nn.Linear(12*50*50,1000)#the input dimensions are (Number of dimensions * height * width)\n",
+    "#         self.layer_6 = nn.Linear(1000,100)\n",
+    "#         self.layer_7 = nn.Linear(100,50)\n",
+    "#         self.layer_8 = nn.Linear(50,10)\n",
+    "#         self.layer_9 = nn.Linear(10,10)\n",
+    "        \n",
+    "        \n",
+    "        \n",
+    "#         # metrics\n",
+    "#         self.acc_task = acc_task\n",
+    "#         self.lr = lr\n",
+    "#         self.num_classes = num_classes\n",
+    "#         self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.num_classes)\n",
+    "#         self.class_names = classes_lst\n",
+    "#         self.loss = CrossEntropyLoss()\n",
+    "\n",
+    "#         # optional - save hyper-parameters to self.hparams\n",
+    "#         # they will also be automatically logged as config parameters in W&B\n",
+    "#         self.save_hyperparameters()\n",
+    "\n",
+    "#     def forward(self,x):\n",
+    "#         \"\"\"\n",
+    "#         x is the input data\n",
+    "#         \"\"\"\n",
+    "#         x = self.layer_1(x)\n",
+    "#         x = self.pool(x)\n",
+    "#         x = self.layer_2(x)\n",
+    "#         x = self.pool(x)\n",
+    "#         x = self.layer_3(x)\n",
+    "#         x = self.pool(x)\n",
+    "#         x = x.view(x.size(0),-1)\n",
+    "#         print(x.size())\n",
+    "#         x = self.layer_5(x)\n",
+    "#         x = self.layer_6(x)\n",
+    "#         x = self.layer_7(x)\n",
+    "#         x = self.layer_8(x)\n",
+    "#         x = self.layer_9(x)\n",
+    "#         return x\n",
+    "\n",
+    "#     def configure_optimizers(self):\n",
+    "#         optimizer = torch.optim.Adam(self.parameters(),lr = self.lr)\n",
+    "#         return optimizer\n",
+    "\n",
+    "# # The Pytorch-Lightning module handles all the iterations of the epoch\n",
+    "\n",
+    "#     def training_step(self,batch,batch_idx):\n",
+    "#         x,y = batch\n",
+    "#         y_pred = self(x)\n",
+    "#         loss = F.cross_entropy(y_pred,y)\n",
+    "#         # Log training loss\n",
+    "#         self.log('train_loss', loss)\n",
+    "#         # Log metrics\n",
+    "#         self.log('train_acc', self.accuracy(y_pred, y))\n",
+    "#         return loss\n",
+    "\n",
+    "#     def validation_step(self,batch,batch_idx):\n",
+    "#         preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
+    "#         # Log loss and metric\n",
+    "#         self.log('val_loss_alt', loss)\n",
+    "#         self.log('val_accuracy_alt', acc)\n",
+    "        \n",
+    "#         x,y = batch\n",
+    "#         y_pred = self(x)\n",
+    "#         loss = F.cross_entropy(y_pred,y)\n",
+    "#         # Log training loss\n",
+    "#         self.log('val_loss', loss)\n",
+    "#         # Log metrics\n",
+    "#         self.log('val_acc', self.accuracy(y_pred, y))\n",
+    "#         self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
+    "#         self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
+    "#         wandb.log({\"val_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
+    "#                         y_true=self.cpu_y, preds=None,\n",
+    "#                         class_names=self.class_names)})\n",
+    "#         return preds\n",
+    "\n",
+    "#     def test_step(self,batch,batch_idx):\n",
+    "#         x,y = batch\n",
+    "#         y_pred = self(x)\n",
+    "#         loss = F.cross_entropy(y_pred,y)\n",
+    "#         # Log training loss\n",
+    "#         self.log('test_loss', loss)\n",
+    "#         # Log metrics\n",
+    "#         self.log('test_acc', self.accuracy(y_pred, y))\n",
+    "#         self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
+    "#         self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
+    "#         wandb.log({\"test_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
+    "#                         y_true=self.cpu_y, preds=None,\n",
+    "#                         class_names=self.class_names)})\n",
+    "#         return loss\n",
+    "    \n",
+    "#     def _get_preds_loss_accuracy(self, batch):\n",
+    "#         '''convenience function since train/valid/test steps are similar'''\n",
+    "#         x, y = batch\n",
+    "#         logits = self(x)\n",
+    "#         preds = torch.argmax(logits, dim=1)\n",
+    "#         loss = self.loss(logits, y)\n",
+    "#         acc = accuracy(preds, y, self.acc_task, num_classes=10)\n",
+    "#         return preds, loss, acc"
+   ]
   }
  ],
  "metadata": {
diff --git a/Train/PyLi_wanb_sweep_CoatNet.ipynb b/Train/PyLi_wanb_sweep_CoatNet.ipynb
index b3f7aa6..d994032 100644
--- a/Train/PyLi_wanb_sweep_CoatNet.ipynb
+++ b/Train/PyLi_wanb_sweep_CoatNet.ipynb
@@ -2,16 +2,9 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": null,
    "id": "c7b471f1-f5fa-4eb1-b9ae-2d67ed8838df",
    "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:21.824252Z",
-     "iopub.status.busy": "2023-03-08T17:10:21.824252Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.893295Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.892300Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:21.824252Z"
-    },
     "tags": []
    },
    "outputs": [],
@@ -70,46 +63,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": null,
    "id": "01c28e3c-850d-48b6-8db9-3a8804e0c9ae",
    "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.896303Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.895302Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.924332Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.923339Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.895302Z"
-    },
     "tags": []
    },
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Total Number of Classes : 10\n"
-     ]
-    },
-    {
-     "data": {
-      "text/plain": [
-       "{'0': 0,\n",
-       " '1': 1,\n",
-       " '2': 2,\n",
-       " '3': 3,\n",
-       " '4': 4,\n",
-       " '5': 5,\n",
-       " '6': 6,\n",
-       " '7': 7,\n",
-       " '8': 8,\n",
-       " '9': 9}"
-      ]
-     },
-     "execution_count": 2,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "# declaring the path of the train and test folders\n",
     "train_path = \"DATASET_C/TRAIN\"\n",
@@ -137,16 +96,9 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": null,
    "id": "8b9e722b-cda4-4956-a0c1-8eb31023f765",
    "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.926331Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.926331Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.939867Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.938864Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.926331Z"
-    },
     "tags": []
    },
    "outputs": [],
@@ -185,21 +137,14 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": null,
    "id": "9dbe4b19-9805-40b4-a513-ea35715a0c64",
    "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.940865Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.940865Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.953853Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.953853Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.940865Z"
-    },
     "tags": []
    },
    "outputs": [],
    "source": [
-    "size = 50 # need to be the same as what is used in layer_5/ input layer ot the cnn\n",
+    "size = 224 # need to be the same as what is used in layer_5/ input layer ot the cnn\n",
     "\n",
     "basic_transformations = transforms.Compose([\n",
     "    transforms.ToPILImage(),\n",
@@ -221,16 +166,9 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": null,
    "id": "7539d3a5-ca4f-4ba3-a462-05875d4b9a90",
    "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.956852Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.955851Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.970854Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.969851Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.956852Z"
-    },
     "tags": []
    },
    "outputs": [],
@@ -242,17 +180,64 @@
     "\n",
     "    def prepare_data(self):\n",
     "        self.train = Image_Dataset(classes_dir_data,train_path,training_transformations,target_transformations)\n",
-    "        self.valid = Image_Dataset(classes_dir_data,test_path,basic_transformations,target_transformations)\n",
+    "        self.valid = Image_Dataset(classes_dir_data,train_path,basic_transformations,target_transformations)\n",
     "        self.test = Image_Dataset(classes_dir_data,test_path,basic_transformations,target_transformations)\n",
     "\n",
     "    def train_dataloader(self):\n",
-    "        return DataLoader(self.train,batch_size = 64,shuffle = True)#False, num_workers = cpu_count)\n",
+    "        return DataLoader(self.train,batch_size = 8,shuffle = True)#False, num_workers = cpu_count)\n",
     "\n",
     "    def val_dataloader(self):  \n",
-    "        return DataLoader(self.valid,batch_size = 64,shuffle = True)#False, num_workers = cpu_count)\n",
+    "        return DataLoader(self.valid,batch_size = 8,shuffle = True)#False, num_workers = cpu_count)\n",
     "\n",
     "    def test_dataloader(self):\n",
-    "        return DataLoader(self.test,batch_size = 64,shuffle = True)#False, num_workers = cpu_count)"
+    "        return DataLoader(self.test,batch_size = 8,shuffle = True)#False, num_workers = cpu_count)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "66eadea7-8c62-4c3f-93d6-ee1bf7b03494",
+   "metadata": {
+    "tags": []
+   },
+   "outputs": [],
+   "source": [
+    "# import matplotlib.pyplot as plt\n",
+    "# train_img_dataset = Image_Dataset(classes_dir_data,train_path,training_transformations,target_transformations)\n",
+    "# train_loader_obj = DataLoader(train_img_dataset, batch_size = 8, shuffle = True)\n",
+    "\n",
+    "# # Display image and label.\n",
+    "# train_features, train_labels = next(iter(train_loader_obj))\n",
+    "# print(f\"Feature batch shape: {train_features.size()}\")\n",
+    "# print(f\"Labels batch shape: {train_labels.size()}\")\n",
+    "# img = train_features[0].squeeze()\n",
+    "# label = train_labels[0]\n",
+    "# plt.imshow(img, cmap=\"gray\")\n",
+    "# plt.show()\n",
+    "# print(f\"Label: {label}\")"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "958c02c1-2355-4c2d-85e4-31a101fdf612",
+   "metadata": {
+    "tags": []
+   },
+   "outputs": [],
+   "source": [
+    "# test_img_dataset = Image_Dataset(classes_dir_data,test_path,basic_transformations,target_transformations)\n",
+    "# test_loader_obj = DataLoader(test_img_dataset, batch_size = 8, shuffle = True)\n",
+    "\n",
+    "# # Display image and label.\n",
+    "# train_features, train_labels = next(iter(test_loader_obj))\n",
+    "# print(f\"Feature batch shape: {train_features.size()}\")\n",
+    "# print(f\"Labels batch shape: {train_labels.size()}\")\n",
+    "# img = train_features[0].squeeze()\n",
+    "# label = train_labels[0]\n",
+    "# plt.imshow(img, cmap=\"gray\")\n",
+    "# plt.show()\n",
+    "# print(f\"Label: {label}\")"
    ]
   },
   {
@@ -273,159 +258,23 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
-   "id": "deb34aed-792a-4022-a878-f8d6c4ffa97c",
-   "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.972851Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.971852Z",
-     "iopub.status.idle": "2023-03-08T17:10:27.000852Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.999851Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.972851Z"
-    },
-    "tags": []
-   },
-   "outputs": [],
-   "source": [
-    "class MyModel(LightningModule):\n",
-    "\n",
-    "    def __init__(self, classes_lst, n_classes=10, acc_task=\"multiclass\", lr=1e-3):\n",
-    "        super().__init__()\n",
-    "        \n",
-    "        \n",
-    "        \"\"\"\n",
-    "        The convolutions are arranged in such a way that the image maintain the x and y dimensions. only the channels change\n",
-    "        \"\"\"\n",
-    "        self.layer_1 = nn.Conv2d(in_channels = 1,out_channels = 3,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "        self.layer_2 = nn.Conv2d(in_channels = 3,out_channels = 6,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "        self.layer_3 = nn.Conv2d(in_channels = 6,out_channels = 12,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "        self.pool = nn.MaxPool2d(kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "        self.layer_5 = nn.Linear(12*50*50,1000)#the input dimensions are (Number of dimensions * height * width)\n",
-    "        self.layer_6 = nn.Linear(1000,100)\n",
-    "        self.layer_7 = nn.Linear(100,50)\n",
-    "        self.layer_8 = nn.Linear(50,10)\n",
-    "        self.layer_9 = nn.Linear(10,10)\n",
-    "        \n",
-    "        \n",
-    "        \n",
-    "        # metrics\n",
-    "        self.acc_task = acc_task\n",
-    "        self.lr = lr\n",
-    "        self.n_classes = n_classes\n",
-    "        self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.n_classes)\n",
-    "        self.class_names = classes_lst\n",
-    "        self.loss = CrossEntropyLoss()\n",
-    "\n",
-    "        # optional - save hyper-parameters to self.hparams\n",
-    "        # they will also be automatically logged as config parameters in W&B\n",
-    "        self.save_hyperparameters()\n",
-    "\n",
-    "    def forward(self,x):\n",
-    "        \"\"\"\n",
-    "        x is the input data\n",
-    "        \"\"\"\n",
-    "        x = self.layer_1(x)\n",
-    "        x = self.pool(x)\n",
-    "        x = self.layer_2(x)\n",
-    "        x = self.pool(x)\n",
-    "        x = self.layer_3(x)\n",
-    "        x = self.pool(x)\n",
-    "        x = x.view(x.size(0),-1)\n",
-    "        print(x.size())\n",
-    "        x = self.layer_5(x)\n",
-    "        x = self.layer_6(x)\n",
-    "        x = self.layer_7(x)\n",
-    "        x = self.layer_8(x)\n",
-    "        x = self.layer_9(x)\n",
-    "        return x\n",
-    "\n",
-    "    def configure_optimizers(self):\n",
-    "        optimizer = torch.optim.Adam(self.parameters(),lr = self.lr)\n",
-    "        return optimizer\n",
-    "\n",
-    "# The Pytorch-Lightning module handles all the iterations of the epoch\n",
-    "\n",
-    "    def training_step(self,batch,batch_idx):\n",
-    "        x,y = batch\n",
-    "        y_pred = self(x)\n",
-    "        loss = F.cross_entropy(y_pred,y)\n",
-    "        # Log training loss\n",
-    "        self.log('train_loss', loss)\n",
-    "        # Log metrics\n",
-    "        self.log('train_acc', self.accuracy(y_pred, y))\n",
-    "        return loss\n",
-    "\n",
-    "    def validation_step(self,batch,batch_idx):\n",
-    "        preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
-    "        # Log loss and metric\n",
-    "        self.log('val_loss_alt', loss)\n",
-    "        self.log('val_accuracy_alt', acc)\n",
-    "        \n",
-    "        x,y = batch\n",
-    "        y_pred = self(x)\n",
-    "        loss = F.cross_entropy(y_pred,y)\n",
-    "        # Log training loss\n",
-    "        self.log('val_loss', loss)\n",
-    "        # Log metrics\n",
-    "        self.log('val_acc', self.accuracy(y_pred, y))\n",
-    "        self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
-    "        self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
-    "        wandb.log({\"val_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
-    "                        y_true=self.cpu_y, preds=None,\n",
-    "                        class_names=self.class_names)})\n",
-    "        return preds\n",
-    "\n",
-    "    def test_step(self,batch,batch_idx):\n",
-    "        x,y = batch\n",
-    "        y_pred = self(x)\n",
-    "        loss = F.cross_entropy(y_pred,y)\n",
-    "        # Log training loss\n",
-    "        self.log('test_loss', loss)\n",
-    "        # Log metrics\n",
-    "        self.log('test_acc', self.accuracy(y_pred, y))\n",
-    "        self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
-    "        self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
-    "        wandb.log({\"test_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
-    "                        y_true=self.cpu_y, preds=None,\n",
-    "                        class_names=self.class_names)})\n",
-    "        return loss\n",
-    "    \n",
-    "    def _get_preds_loss_accuracy(self, batch):\n",
-    "        '''convenience function since train/valid/test steps are similar'''\n",
-    "        x, y = batch\n",
-    "        logits = self(x)\n",
-    "        preds = torch.argmax(logits, dim=1)\n",
-    "        loss = self.loss(logits, y)\n",
-    "        acc = accuracy(preds, y, self.acc_task, num_classes=10)\n",
-    "        return preds, loss, acc"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 7,
+   "execution_count": null,
    "id": "1816bdd2-4846-4dee-a595-190697564b38",
    "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:27.002857Z",
-     "iopub.status.busy": "2023-03-08T17:10:27.001851Z",
-     "iopub.status.idle": "2023-03-08T17:10:27.032396Z",
-     "shell.execute_reply": "2023-03-08T17:10:27.031390Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:27.002857Z"
-    },
     "tags": []
    },
    "outputs": [],
    "source": [
     "class MyModel(LightningModule):\n",
     "\n",
-    "    def __init__(self, classes_lst, input_shape=(1,224,224), n_classes=10, acc_task=\"multiclass\", lr=1e-3, transfer=False): #input_shape=(3,224,224) image shape\n",
+    "    def __init__(self, classes_lst, input_shape, num_classes=10, acc_task=\"multiclass\", lr=1e-3, transfer=False): #input_shape=(3,224,224) image shape\n",
     "        super().__init__()\n",
     "        \n",
     "        # metrics\n",
     "        self.acc_task = acc_task\n",
     "        self.lr = lr\n",
-    "        self.n_classes = n_classes\n",
-    "        self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.n_classes)\n",
+    "        self.num_classes = num_classes\n",
+    "        self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.num_classes)\n",
     "        self.class_names = classes_lst\n",
     "        self.loss = CrossEntropyLoss()\n",
     "        \n",
@@ -528,118 +377,6 @@
     "        return preds, loss, acc"
    ]
   },
-  {
-   "cell_type": "code",
-   "execution_count": 8,
-   "id": "f87009dd-3c3a-409c-ada8-3f991d17d0c1",
-   "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:27.034398Z",
-     "iopub.status.busy": "2023-03-08T17:10:27.033399Z",
-     "iopub.status.idle": "2023-03-08T17:10:27.049387Z",
-     "shell.execute_reply": "2023-03-08T17:10:27.047400Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:27.034398Z"
-    }
-   },
-   "outputs": [],
-   "source": [
-    "# class MyModel(pl.LightningModule):\n",
-    "#     def __init__(self, input_shape, n_classes=10, lr=2e-4, transfer=False):\n",
-    "#         super().__init__()\n",
-    "        \n",
-    "#         # log hyperparameters\n",
-    "#         self.save_hyperparameters()\n",
-    "#         self.learning_rate = lr\n",
-    "#         self.dim = input_shape\n",
-    "#         self.num_classes = num_classes\n",
-    "        \n",
-    "#         # transfer learning if pretrained=True\n",
-    "#         self.feature_extractor = models.resnet18(pretrained=transfer)\n",
-    "\n",
-    "#         if transfer:\n",
-    "#             # layers are frozen by using eval()\n",
-    "#             self.feature_extractor.eval()\n",
-    "#             # freeze params\n",
-    "#             for param in self.feature_extractor.parameters():\n",
-    "#                 param.requires_grad = False\n",
-    "        \n",
-    "#         n_sizes = self._get_conv_output(input_shape)\n",
-    "\n",
-    "#         self.classifier = nn.Linear(n_sizes, num_classes)\n",
-    "\n",
-    "#         self.criterion = nn.CrossEntropyLoss()\n",
-    "#         self.accuracy = Accuracy()\n",
-    "  \n",
-    "#     # returns the size of the output tensor going into the Linear layer from the conv block.\n",
-    "#     def _get_conv_output(self, shape):\n",
-    "#         batch_size = 1\n",
-    "#         tmp_input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
-    "\n",
-    "#         output_feat = self._forward_features(tmp_input) \n",
-    "#         n_size = output_feat.data.view(batch_size, -1).size(1)\n",
-    "#         return n_size\n",
-    "        \n",
-    "#     # returns the feature tensor from the conv block\n",
-    "#     def _forward_features(self, x):\n",
-    "#         x = self.feature_extractor(x)\n",
-    "#         return x\n",
-    "    \n",
-    "#     # will be used during inference\n",
-    "#     def forward(self, x):\n",
-    "#         x = self._forward_features(x)\n",
-    "#         x = x.view(x.size(0), -1)\n",
-    "#         x = self.classifier(x)\n",
-    "\n",
-    "#         return x\n",
-    "    \n",
-    "#     def training_step(self, batch):\n",
-    "#         batch, gt = batch[0], batch[1]\n",
-    "#         out = self.forward(batch)\n",
-    "#         loss = self.criterion(out, gt)\n",
-    "\n",
-    "#         acc = self.accuracy(out, gt)\n",
-    "\n",
-    "#         self.log(\"train/loss\", loss)\n",
-    "#         self.log(\"train/acc\", acc)\n",
-    "\n",
-    "#         return loss\n",
-    "    \n",
-    "#     def validation_step(self, batch, batch_idx):\n",
-    "#         batch, gt = batch[0], batch[1]\n",
-    "#         out = self.forward(batch)\n",
-    "#         loss = self.criterion(out, gt)\n",
-    "\n",
-    "#         self.log(\"val/loss\", loss)\n",
-    "\n",
-    "#         acc = self.accuracy(out, gt)\n",
-    "#         self.log(\"val/acc\", acc)\n",
-    "\n",
-    "#         return loss\n",
-    "    \n",
-    "#     def test_step(self, batch, batch_idx):\n",
-    "#         batch, gt = batch[0], batch[1]\n",
-    "#         out = self.forward(batch)\n",
-    "#         loss = self.criterion(out, gt)\n",
-    "        \n",
-    "#         return {\"loss\": loss, \"outputs\": out, \"gt\": gt}\n",
-    "    \n",
-    "#     def test_epoch_end(self, outputs):\n",
-    "#         loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
-    "#         output = torch.cat([x['outputs'] for x in outputs], dim=0)\n",
-    "        \n",
-    "#         gts = torch.cat([x['gt'] for x in outputs], dim=0)\n",
-    "        \n",
-    "#         self.log(\"test/loss\", loss)\n",
-    "#         acc = self.accuracy(output, gts)\n",
-    "#         self.log(\"test/acc\", acc)\n",
-    "        \n",
-    "#         self.test_gts = gts\n",
-    "#         self.test_output = output\n",
-    "    \n",
-    "#     def configure_optimizers(self):\n",
-    "#         return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
-   ]
-  },
   {
    "cell_type": "markdown",
    "id": "f561a2e3-1272-4e67-9322-dd9b7534fed3",
@@ -650,16 +387,9 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": null,
    "id": "188ce4ef-e6b7-4320-8e5d-ceeb616bf7d1",
    "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:27.051399Z",
-     "iopub.status.busy": "2023-03-08T17:10:27.050393Z",
-     "iopub.status.idle": "2023-03-08T17:10:27.063388Z",
-     "shell.execute_reply": "2023-03-08T17:10:27.062386Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:27.051399Z"
-    },
     "tags": []
    },
    "outputs": [],
@@ -695,112 +425,12 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
+   "execution_count": null,
    "id": "762279ca-26d9-4310-992f-b6f8912da7fe",
    "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:27.065390Z",
-     "iopub.status.busy": "2023-03-08T17:10:27.064390Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.633996Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.631459Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:27.065390Z"
-    },
     "tags": []
    },
-   "outputs": [
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristopher-marais\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
-     ]
-    },
-    {
-     "data": {
-      "text/html": [
-       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
-       " $ pip install wandb --upgrade"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       "Tracking run with wandb version 0.13.10"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       "Run data is saved locally in <code>.\\wandb\\run-20230308_121030-fq5x8q4o</code>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       "Syncing run <strong><a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/fq5x8q4o' target=\"_blank\">fallen-shadow-43</a></strong> to <a href='https://wandb.ai/christopher-marais/computer_vision_test_single' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       " View project at <a href='https://wandb.ai/christopher-marais/computer_vision_test_single' target=\"_blank\">https://wandb.ai/christopher-marais/computer_vision_test_single</a>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       " View run at <a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/fq5x8q4o' target=\"_blank\">https://wandb.ai/christopher-marais/computer_vision_test_single/runs/fq5x8q4o</a>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "ename": "NameError",
-     "evalue": "name 'models' is not defined",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
-      "Cell \u001b[1;32mIn[10], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m DataModule()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# setup model - choose different hyperparameters per experiment\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMyModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclasses_lst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses_lst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_of_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     14\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     15\u001b[0m     devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;66;03m# use all GPU's (-1)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m            \u001b[38;5;66;03m# number of epochs\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     )\n",
-      "Cell \u001b[1;32mIn[7], line 15\u001b[0m, in \u001b[0;36mMyModel.__init__\u001b[1;34m(self, classes_lst, input_shape, n_classes, acc_task, lr, transfer)\u001b[0m\n\u001b[0;32m     12\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# transfer learning if pretrained=True\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241m.\u001b[39mresnet18(pretrained\u001b[38;5;241m=\u001b[39mtransfer)\n\u001b[0;32m     17\u001b[0m  \u001b[38;5;28;01mif\u001b[39;00m transfer:\n\u001b[0;32m     18\u001b[0m      \u001b[38;5;66;03m# layers are frozen by using eval()\u001b[39;00m\n\u001b[0;32m     19\u001b[0m      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor\u001b[38;5;241m.\u001b[39meval()\n",
-      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "wandb.login()\n",
     "wandb_logger = WandbLogger(project='computer_vision_test_single', log_model=True)\n",
@@ -811,7 +441,7 @@
     "data = DataModule()\n",
     "\n",
     "# setup model - choose different hyperparameters per experiment\n",
-    "model = MyModel(classes_lst=classes_lst, n_classes=num_of_classes, input_shape=(3,224,224))\n",
+    "model = MyModel(classes_lst=classes_lst, num_classes=num_of_classes, input_shape=(3,224,224))\n",
     "\n",
     "\n",
     "trainer = Trainer(\n",
@@ -828,12 +458,7 @@
    "execution_count": null,
    "id": "05c5995d-f9be-4377-bfc0-ea1298711b12",
    "metadata": {
-    "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.635025Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.636024Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.635025Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.635025Z"
-    }
+    "tags": []
    },
    "outputs": [],
    "source": [
@@ -844,14 +469,7 @@
    "cell_type": "code",
    "execution_count": null,
    "id": "28625e66-e2a3-4a91-acce-e2948485412b",
-   "metadata": {
-    "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.637021Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.638026Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.637021Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.637021Z"
-    }
-   },
+   "metadata": {},
    "outputs": [],
    "source": [
     "trainer.test(model, datamodule=data)"
@@ -862,12 +480,6 @@
    "execution_count": null,
    "id": "378d95e1-4e29-4c7f-bd8c-eaa16677a063",
    "metadata": {
-    "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.639013Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.639013Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.639013Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.639013Z"
-    },
     "tags": []
    },
    "outputs": [],
@@ -879,14 +491,7 @@
    "cell_type": "code",
    "execution_count": null,
    "id": "91967e96-f127-4758-b427-c996a9fcb4dc",
-   "metadata": {
-    "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.641013Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.642013Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.642013Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.642013Z"
-    }
-   },
+   "metadata": {},
    "outputs": [],
    "source": [
     "# wandb_logger.experiment.finish()"
@@ -896,21 +501,21 @@
    "cell_type": "code",
    "execution_count": null,
    "id": "f04c136e-5986-4628-88b7-38a8b433f654",
-   "metadata": {},
+   "metadata": {
+    "tags": []
+   },
    "outputs": [],
-   "source": []
+   "source": [
+    "data = data.train_dataloader.dataset.data \n",
+    "shape = train_iterator.dataset.data.shape  \n",
+    "datatype = train_iterator.dataset.data.dtype"
+   ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "id": "3b58022d-6961-41b0-a4e1-60bbc1c09791",
    "metadata": {
-    "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.643011Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.644008Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.644008Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.644008Z"
-    },
     "tags": []
    },
    "outputs": [],
@@ -931,12 +536,6 @@
    "execution_count": null,
    "id": "ebde1018-ddfa-43f2-b9c6-f2c1d4b19736",
    "metadata": {
-    "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.645011Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.646017Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.646017Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.646017Z"
-    },
     "tags": []
    },
    "outputs": [],
@@ -977,12 +576,6 @@
    "execution_count": null,
    "id": "91aeb8a0-9ffd-4439-808c-2951d1f74b36",
    "metadata": {
-    "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.648016Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.649014Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.649014Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.649014Z"
-    },
     "tags": []
    },
    "outputs": [],
@@ -1002,7 +595,7 @@
     "    #     n_layer_2=wandb.config.n_layer_2,\n",
     "    #     lr=wandb.config.lr\n",
     "    # )\n",
-    "    model = MyModel(lr=wandb.config.lr, n_classes=num_of_classes)\n",
+    "    model = MyModel(lr=wandb.config.lr, num_classes=num_of_classes)\n",
     "\n",
     "    # setup Trainer\n",
     "    trainer = Trainer(\n",
@@ -1020,12 +613,6 @@
    "execution_count": null,
    "id": "869b0393-21cf-4fba-8efd-7678a852b697",
    "metadata": {
-    "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.650013Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.651012Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.651012Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.651012Z"
-    },
     "tags": []
    },
    "outputs": [],
@@ -1041,6 +628,234 @@
    "metadata": {},
    "outputs": [],
    "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "f87009dd-3c3a-409c-ada8-3f991d17d0c1",
+   "metadata": {
+    "tags": []
+   },
+   "outputs": [],
+   "source": [
+    "# class MyModel(pl.LightningModule):\n",
+    "#     def __init__(self, input_shape, num_classes=10, lr=2e-4, transfer=False):\n",
+    "#         super().__init__()\n",
+    "        \n",
+    "#         # log hyperparameters\n",
+    "#         self.save_hyperparameters()\n",
+    "#         self.learning_rate = lr\n",
+    "#         self.dim = input_shape\n",
+    "#         self.num_classes = num_classes\n",
+    "        \n",
+    "#         # transfer learning if pretrained=True\n",
+    "#         self.feature_extractor = models.resnet18(pretrained=transfer)\n",
+    "\n",
+    "#         if transfer:\n",
+    "#             # layers are frozen by using eval()\n",
+    "#             self.feature_extractor.eval()\n",
+    "#             # freeze params\n",
+    "#             for param in self.feature_extractor.parameters():\n",
+    "#                 param.requires_grad = False\n",
+    "        \n",
+    "#         n_sizes = self._get_conv_output(input_shape)\n",
+    "\n",
+    "#         self.classifier = nn.Linear(n_sizes, num_classes)\n",
+    "\n",
+    "#         self.criterion = nn.CrossEntropyLoss()\n",
+    "#         self.accuracy = Accuracy()\n",
+    "  \n",
+    "#     # returns the size of the output tensor going into the Linear layer from the conv block.\n",
+    "#     def _get_conv_output(self, shape):\n",
+    "#         batch_size = 1\n",
+    "#         tmp_input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
+    "\n",
+    "#         output_feat = self._forward_features(tmp_input) \n",
+    "#         n_size = output_feat.data.view(batch_size, -1).size(1)\n",
+    "#         return n_size\n",
+    "        \n",
+    "#     # returns the feature tensor from the conv block\n",
+    "#     def _forward_features(self, x):\n",
+    "#         x = self.feature_extractor(x)\n",
+    "#         return x\n",
+    "    \n",
+    "#     # will be used during inference\n",
+    "#     def forward(self, x):\n",
+    "#         x = self._forward_features(x)\n",
+    "#         x = x.view(x.size(0), -1)\n",
+    "#         x = self.classifier(x)\n",
+    "\n",
+    "#         return x\n",
+    "    \n",
+    "#     def training_step(self, batch):\n",
+    "#         batch, gt = batch[0], batch[1]\n",
+    "#         out = self.forward(batch)\n",
+    "#         loss = self.criterion(out, gt)\n",
+    "\n",
+    "#         acc = self.accuracy(out, gt)\n",
+    "\n",
+    "#         self.log(\"train/loss\", loss)\n",
+    "#         self.log(\"train/acc\", acc)\n",
+    "\n",
+    "#         return loss\n",
+    "    \n",
+    "#     def validation_step(self, batch, batch_idx):\n",
+    "#         batch, gt = batch[0], batch[1]\n",
+    "#         out = self.forward(batch)\n",
+    "#         loss = self.criterion(out, gt)\n",
+    "\n",
+    "#         self.log(\"val/loss\", loss)\n",
+    "\n",
+    "#         acc = self.accuracy(out, gt)\n",
+    "#         self.log(\"val/acc\", acc)\n",
+    "\n",
+    "#         return loss\n",
+    "    \n",
+    "#     def test_step(self, batch, batch_idx):\n",
+    "#         batch, gt = batch[0], batch[1]\n",
+    "#         out = self.forward(batch)\n",
+    "#         loss = self.criterion(out, gt)\n",
+    "        \n",
+    "#         return {\"loss\": loss, \"outputs\": out, \"gt\": gt}\n",
+    "    \n",
+    "#     def test_epoch_end(self, outputs):\n",
+    "#         loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
+    "#         output = torch.cat([x['outputs'] for x in outputs], dim=0)\n",
+    "        \n",
+    "#         gts = torch.cat([x['gt'] for x in outputs], dim=0)\n",
+    "        \n",
+    "#         self.log(\"test/loss\", loss)\n",
+    "#         acc = self.accuracy(output, gts)\n",
+    "#         self.log(\"test/acc\", acc)\n",
+    "        \n",
+    "#         self.test_gts = gts\n",
+    "#         self.test_output = output\n",
+    "    \n",
+    "#     def configure_optimizers(self):\n",
+    "#         return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "deb34aed-792a-4022-a878-f8d6c4ffa97c",
+   "metadata": {
+    "tags": []
+   },
+   "outputs": [],
+   "source": [
+    "# class MyModel(LightningModule):\n",
+    "\n",
+    "#     def __init__(self, classes_lst, num_classes=10, acc_task=\"multiclass\", lr=1e-3):\n",
+    "#         super().__init__()\n",
+    "        \n",
+    "        \n",
+    "#         \"\"\"\n",
+    "#         The convolutions are arranged in such a way that the image maintain the x and y dimensions. only the channels change\n",
+    "#         \"\"\"\n",
+    "#         self.layer_1 = nn.Conv2d(in_channels = 1,out_channels = 3,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "#         self.layer_2 = nn.Conv2d(in_channels = 3,out_channels = 6,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "#         self.layer_3 = nn.Conv2d(in_channels = 6,out_channels = 12,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "#         self.pool = nn.MaxPool2d(kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "#         self.layer_5 = nn.Linear(12*50*50,1000)#the input dimensions are (Number of dimensions * height * width)\n",
+    "#         self.layer_6 = nn.Linear(1000,100)\n",
+    "#         self.layer_7 = nn.Linear(100,50)\n",
+    "#         self.layer_8 = nn.Linear(50,10)\n",
+    "#         self.layer_9 = nn.Linear(10,10)\n",
+    "        \n",
+    "        \n",
+    "        \n",
+    "#         # metrics\n",
+    "#         self.acc_task = acc_task\n",
+    "#         self.lr = lr\n",
+    "#         self.num_classes = num_classes\n",
+    "#         self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.num_classes)\n",
+    "#         self.class_names = classes_lst\n",
+    "#         self.loss = CrossEntropyLoss()\n",
+    "\n",
+    "#         # optional - save hyper-parameters to self.hparams\n",
+    "#         # they will also be automatically logged as config parameters in W&B\n",
+    "#         self.save_hyperparameters()\n",
+    "\n",
+    "#     def forward(self,x):\n",
+    "#         \"\"\"\n",
+    "#         x is the input data\n",
+    "#         \"\"\"\n",
+    "#         x = self.layer_1(x)\n",
+    "#         x = self.pool(x)\n",
+    "#         x = self.layer_2(x)\n",
+    "#         x = self.pool(x)\n",
+    "#         x = self.layer_3(x)\n",
+    "#         x = self.pool(x)\n",
+    "#         x = x.view(x.size(0),-1)\n",
+    "#         print(x.size())\n",
+    "#         x = self.layer_5(x)\n",
+    "#         x = self.layer_6(x)\n",
+    "#         x = self.layer_7(x)\n",
+    "#         x = self.layer_8(x)\n",
+    "#         x = self.layer_9(x)\n",
+    "#         return x\n",
+    "\n",
+    "#     def configure_optimizers(self):\n",
+    "#         optimizer = torch.optim.Adam(self.parameters(),lr = self.lr)\n",
+    "#         return optimizer\n",
+    "\n",
+    "# # The Pytorch-Lightning module handles all the iterations of the epoch\n",
+    "\n",
+    "#     def training_step(self,batch,batch_idx):\n",
+    "#         x,y = batch\n",
+    "#         y_pred = self(x)\n",
+    "#         loss = F.cross_entropy(y_pred,y)\n",
+    "#         # Log training loss\n",
+    "#         self.log('train_loss', loss)\n",
+    "#         # Log metrics\n",
+    "#         self.log('train_acc', self.accuracy(y_pred, y))\n",
+    "#         return loss\n",
+    "\n",
+    "#     def validation_step(self,batch,batch_idx):\n",
+    "#         preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
+    "#         # Log loss and metric\n",
+    "#         self.log('val_loss_alt', loss)\n",
+    "#         self.log('val_accuracy_alt', acc)\n",
+    "        \n",
+    "#         x,y = batch\n",
+    "#         y_pred = self(x)\n",
+    "#         loss = F.cross_entropy(y_pred,y)\n",
+    "#         # Log training loss\n",
+    "#         self.log('val_loss', loss)\n",
+    "#         # Log metrics\n",
+    "#         self.log('val_acc', self.accuracy(y_pred, y))\n",
+    "#         self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
+    "#         self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
+    "#         wandb.log({\"val_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
+    "#                         y_true=self.cpu_y, preds=None,\n",
+    "#                         class_names=self.class_names)})\n",
+    "#         return preds\n",
+    "\n",
+    "#     def test_step(self,batch,batch_idx):\n",
+    "#         x,y = batch\n",
+    "#         y_pred = self(x)\n",
+    "#         loss = F.cross_entropy(y_pred,y)\n",
+    "#         # Log training loss\n",
+    "#         self.log('test_loss', loss)\n",
+    "#         # Log metrics\n",
+    "#         self.log('test_acc', self.accuracy(y_pred, y))\n",
+    "#         self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
+    "#         self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
+    "#         wandb.log({\"test_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
+    "#                         y_true=self.cpu_y, preds=None,\n",
+    "#                         class_names=self.class_names)})\n",
+    "#         return loss\n",
+    "    \n",
+    "#     def _get_preds_loss_accuracy(self, batch):\n",
+    "#         '''convenience function since train/valid/test steps are similar'''\n",
+    "#         x, y = batch\n",
+    "#         logits = self(x)\n",
+    "#         preds = torch.argmax(logits, dim=1)\n",
+    "#         loss = self.loss(logits, y)\n",
+    "#         acc = accuracy(preds, y, self.acc_task, num_classes=10)\n",
+    "#         return preds, loss, acc"
+   ]
   }
  ],
  "metadata": {
