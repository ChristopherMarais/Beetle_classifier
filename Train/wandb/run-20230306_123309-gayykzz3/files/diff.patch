diff --git a/Train/.ipynb_checkpoints/PyLi_wanb_sweep_CoatNet-checkpoint.ipynb b/Train/.ipynb_checkpoints/PyLi_wanb_sweep_CoatNet-checkpoint.ipynb
index cd4d5a1..4db001c 100644
--- a/Train/.ipynb_checkpoints/PyLi_wanb_sweep_CoatNet-checkpoint.ipynb
+++ b/Train/.ipynb_checkpoints/PyLi_wanb_sweep_CoatNet-checkpoint.ipynb
@@ -287,112 +287,112 @@
    },
    "outputs": [],
    "source": [
-    "# class MyModel(LightningModule):\n",
+    "class MyModel(LightningModule):\n",
     "\n",
-    "#     def __init__(self, n_classes=10, acc_task=\"multiclass\", lr=1e-3):\n",
-    "#         super().__init__()\n",
-    "#         \"\"\"\n",
-    "#         The convolutions are arranged in such a way that the image maintain the x and y dimensions. only the channels change\n",
-    "#         \"\"\"\n",
-    "#         self.layer_1 = nn.Conv2d(in_channels = 1,out_channels = 3,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "#         self.layer_2 = nn.Conv2d(in_channels = 3,out_channels = 6,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "#         self.layer_3 = nn.Conv2d(in_channels = 6,out_channels = 12,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "#         self.pool = nn.MaxPool2d(kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "#         self.layer_5 = nn.Linear(12*50*50,1000)#the input dimensions are (Number of dimensions * height * width)\n",
-    "#         self.layer_6 = nn.Linear(1000,100)\n",
-    "#         self.layer_7 = nn.Linear(100,50)\n",
-    "#         self.layer_8 = nn.Linear(50,10)\n",
-    "#         self.layer_9 = nn.Linear(10,10)\n",
-    "#         self.lr = lr\n",
-    "#         # metrics\n",
-    "#         self.acc_task = acc_task\n",
-    "#         self.n_classes = n_classes\n",
-    "#         self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.n_classes)\n",
-    "#         self.class_names = classes_lst\n",
-    "#         self.loss = CrossEntropyLoss()\n",
+    "    def __init__(self, n_classes=10, acc_task=\"multiclass\", lr=1e-3):\n",
+    "        super().__init__()\n",
+    "        \"\"\"\n",
+    "        The convolutions are arranged in such a way that the image maintain the x and y dimensions. only the channels change\n",
+    "        \"\"\"\n",
+    "        self.layer_1 = nn.Conv2d(in_channels = 1,out_channels = 3,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "        self.layer_2 = nn.Conv2d(in_channels = 3,out_channels = 6,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "        self.layer_3 = nn.Conv2d(in_channels = 6,out_channels = 12,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "        self.pool = nn.MaxPool2d(kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "        self.layer_5 = nn.Linear(12*50*50,1000)#the input dimensions are (Number of dimensions * height * width)\n",
+    "        self.layer_6 = nn.Linear(1000,100)\n",
+    "        self.layer_7 = nn.Linear(100,50)\n",
+    "        self.layer_8 = nn.Linear(50,10)\n",
+    "        self.layer_9 = nn.Linear(10,10)\n",
+    "        self.lr = lr\n",
+    "        # metrics\n",
+    "        self.acc_task = acc_task\n",
+    "        self.n_classes = n_classes\n",
+    "        self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.n_classes)\n",
+    "        self.class_names = classes_lst\n",
+    "        self.loss = CrossEntropyLoss()\n",
     "\n",
-    "#         # optional - save hyper-parameters to self.hparams\n",
-    "#         # they will also be automatically logged as config parameters in W&B\n",
-    "#         self.save_hyperparameters()\n",
+    "        # optional - save hyper-parameters to self.hparams\n",
+    "        # they will also be automatically logged as config parameters in W&B\n",
+    "        self.save_hyperparameters()\n",
     "\n",
-    "#     def forward(self,x):\n",
-    "#         \"\"\"\n",
-    "#         x is the input data\n",
-    "#         \"\"\"\n",
-    "#         x = self.layer_1(x)\n",
-    "#         x = self.pool(x)\n",
-    "#         x = self.layer_2(x)\n",
-    "#         x = self.pool(x)\n",
-    "#         x = self.layer_3(x)\n",
-    "#         x = self.pool(x)\n",
-    "#         x = x.view(x.size(0),-1)\n",
-    "#         print(x.size())\n",
-    "#         x = self.layer_5(x)\n",
-    "#         x = self.layer_6(x)\n",
-    "#         x = self.layer_7(x)\n",
-    "#         x = self.layer_8(x)\n",
-    "#         x = self.layer_9(x)\n",
-    "#         return x\n",
+    "    def forward(self,x):\n",
+    "        \"\"\"\n",
+    "        x is the input data\n",
+    "        \"\"\"\n",
+    "        x = self.layer_1(x)\n",
+    "        x = self.pool(x)\n",
+    "        x = self.layer_2(x)\n",
+    "        x = self.pool(x)\n",
+    "        x = self.layer_3(x)\n",
+    "        x = self.pool(x)\n",
+    "        x = x.view(x.size(0),-1)\n",
+    "        print(x.size())\n",
+    "        x = self.layer_5(x)\n",
+    "        x = self.layer_6(x)\n",
+    "        x = self.layer_7(x)\n",
+    "        x = self.layer_8(x)\n",
+    "        x = self.layer_9(x)\n",
+    "        return x\n",
     "\n",
-    "#     def configure_optimizers(self):\n",
-    "#         optimizer = torch.optim.Adam(self.parameters(),lr = self.lr)\n",
-    "#         return optimizer\n",
+    "    def configure_optimizers(self):\n",
+    "        optimizer = torch.optim.Adam(self.parameters(),lr = self.lr)\n",
+    "        return optimizer\n",
     "\n",
-    "# # The Pytorch-Lightning module handles all the iterations of the epoch\n",
+    "# The Pytorch-Lightning module handles all the iterations of the epoch\n",
     "\n",
-    "#     def training_step(self,batch,batch_idx):\n",
-    "#         x,y = batch\n",
-    "#         y_pred = self(x)\n",
-    "#         loss = F.cross_entropy(y_pred,y)\n",
-    "#         # Log training loss\n",
-    "#         self.log('train_loss', loss)\n",
-    "#         # Log metrics\n",
-    "#         self.log('train_acc', self.accuracy(y_pred, y))\n",
-    "#         return loss\n",
+    "    def training_step(self,batch,batch_idx):\n",
+    "        x,y = batch\n",
+    "        y_pred = self(x)\n",
+    "        loss = F.cross_entropy(y_pred,y)\n",
+    "        # Log training loss\n",
+    "        self.log('train_loss', loss)\n",
+    "        # Log metrics\n",
+    "        self.log('train_acc', self.accuracy(y_pred, y))\n",
+    "        return loss\n",
     "\n",
-    "#     def validation_step(self,batch,batch_idx):\n",
-    "#         preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
-    "#         # Log loss and metric\n",
-    "#         self.log('val_loss_alt', loss)\n",
-    "#         self.log('val_accuracy_alt', acc)\n",
+    "    def validation_step(self,batch,batch_idx):\n",
+    "        preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
+    "        # Log loss and metric\n",
+    "        self.log('val_loss_alt', loss)\n",
+    "        self.log('val_accuracy_alt', acc)\n",
     "        \n",
-    "#         x,y = batch\n",
-    "#         y_pred = self(x)\n",
-    "#         loss = F.cross_entropy(y_pred,y)\n",
-    "#         # Log training loss\n",
-    "#         self.log('val_loss', loss)\n",
-    "#         # Log metrics\n",
-    "#         self.log('val_acc', self.accuracy(y_pred, y))\n",
-    "#         self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
-    "#         self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
-    "#         wandb.log({\"val_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
-    "#                         y_true=self.cpu_y, preds=None,\n",
-    "#                         class_names=self.class_names)})\n",
-    "#         return preds\n",
+    "        x,y = batch\n",
+    "        y_pred = self(x)\n",
+    "        loss = F.cross_entropy(y_pred,y)\n",
+    "        # Log training loss\n",
+    "        self.log('val_loss', loss)\n",
+    "        # Log metrics\n",
+    "        self.log('val_acc', self.accuracy(y_pred, y))\n",
+    "        self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
+    "        self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
+    "        wandb.log({\"val_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
+    "                        y_true=self.cpu_y, preds=None,\n",
+    "                        class_names=self.class_names)})\n",
+    "        return preds\n",
     "\n",
-    "#     def test_step(self,batch,batch_idx):\n",
-    "#         x,y = batch\n",
-    "#         y_pred = self(x)\n",
-    "#         loss = F.cross_entropy(y_pred,y)\n",
-    "#         # Log training loss\n",
-    "#         self.log('test_loss', loss)\n",
-    "#         # Log metrics\n",
-    "#         self.log('test_acc', self.accuracy(y_pred, y))\n",
-    "#         self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
-    "#         self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
-    "#         wandb.log({\"test_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
-    "#                         y_true=self.cpu_y, preds=None,\n",
-    "#                         class_names=self.class_names)})\n",
-    "#         return loss\n",
+    "    def test_step(self,batch,batch_idx):\n",
+    "        x,y = batch\n",
+    "        y_pred = self(x)\n",
+    "        loss = F.cross_entropy(y_pred,y)\n",
+    "        # Log training loss\n",
+    "        self.log('test_loss', loss)\n",
+    "        # Log metrics\n",
+    "        self.log('test_acc', self.accuracy(y_pred, y))\n",
+    "        self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
+    "        self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
+    "        wandb.log({\"test_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
+    "                        y_true=self.cpu_y, preds=None,\n",
+    "                        class_names=self.class_names)})\n",
+    "        return loss\n",
     "    \n",
-    "#     def _get_preds_loss_accuracy(self, batch):\n",
-    "#         '''convenience function since train/valid/test steps are similar'''\n",
-    "#         x, y = batch\n",
-    "#         logits = self(x)\n",
-    "#         preds = torch.argmax(logits, dim=1)\n",
-    "#         loss = self.loss(logits, y)\n",
-    "#         acc = accuracy(preds, y, self.acc_task, num_classes=10)\n",
-    "#         return preds, loss, acc"
+    "    def _get_preds_loss_accuracy(self, batch):\n",
+    "        '''convenience function since train/valid/test steps are similar'''\n",
+    "        x, y = batch\n",
+    "        logits = self(x)\n",
+    "        preds = torch.argmax(logits, dim=1)\n",
+    "        loss = self.loss(logits, y)\n",
+    "        acc = accuracy(preds, y, self.acc_task, num_classes=10)\n",
+    "        return preds, loss, acc"
    ]
   },
   {
@@ -410,84 +410,84 @@
    },
    "outputs": [],
    "source": [
-    "class MyModel(LightningModule): \n",
+    "# class MyModel(LightningModule): \n",
     "\n",
-    "    def __init__(self, n_classes=10, n_layer_1=128, n_layer_2=256, lr=1e-3): \n",
-    "        '''method used to define our model parameters'''\n",
-    "        super().__init__()\n",
+    "#     def __init__(self, n_classes=10, n_layer_1=128, n_layer_2=256, lr=1e-3): \n",
+    "#         '''method used to define our model parameters'''\n",
+    "#         super().__init__()\n",
     "\n",
-    "        # mnist images are (1, 28, 28) (channels, width, height\n",
-    "        self.layer_1 = Linear(28 * 28, n_layer_1)\n",
-    "        self.layer_2 = Linear(n_layer_1, n_layer_2)\n",
-    "        self.layer_3 = Linear(n_layer_2, n_classes)\n",
+    "#         # mnist images are (1, 28, 28) (channels, width, height\n",
+    "#         self.layer_1 = Linear(28 * 28, n_layer_1)\n",
+    "#         self.layer_2 = Linear(n_layer_1, n_layer_2)\n",
+    "#         self.layer_3 = Linear(n_layer_2, n_classes)\n",
     "\n",
-    "        # loss\n",
-    "        self.loss = CrossEntropyLoss()\n",
+    "#         # loss\n",
+    "#         self.loss = CrossEntropyLoss()\n",
     "\n",
-    "        # optimizer parameters\n",
-    "        self.lr = lr\n",
+    "#         # optimizer parameters\n",
+    "#         self.lr = lr\n",
     "\n",
-    "        # save hyper-parameters to self.hparams (auto-logged by W&B)\n",
-    "        self.save_hyperparameters() \n",
+    "#         # save hyper-parameters to self.hparams (auto-logged by W&B)\n",
+    "#         self.save_hyperparameters() \n",
     "\n",
-    "    def forward(self, x):\n",
-    "        '''method used for inference input -> output'''\n",
+    "#     def forward(self, x):\n",
+    "#         '''method used for inference input -> output'''\n",
     "\n",
-    "        batch_size, channels, width, height = x.size()\n",
+    "#         batch_size, channels, width, height = x.size()\n",
     "\n",
-    "        # (b, 1, 28, 28) -> (b, 1*28*28)\n",
-    "        x = x.view(batch_size, -1)\n",
+    "#         # (b, 1, 28, 28) -> (b, 1*28*28)\n",
+    "#         x = x.view(batch_size, -1)\n",
     "\n",
-    "        # let's do 3 x (linear + relu)\n",
-    "        x = self.layer_1(x)\n",
-    "        x = F.relu(x)\n",
-    "        x = self.layer_2(x)\n",
-    "        x = F.relu(x)\n",
-    "        x = self.layer_3(x)\n",
+    "#         # let's do 3 x (linear + relu)\n",
+    "#         x = self.layer_1(x)\n",
+    "#         x = F.relu(x)\n",
+    "#         x = self.layer_2(x)\n",
+    "#         x = F.relu(x)\n",
+    "#         x = self.layer_3(x)\n",
     "\n",
-    "        return x\n",
+    "#         return x\n",
     "\n",
-    "    def training_step(self, batch, batch_idx):\n",
-    "        '''needs to return a loss from a single batch'''\n",
-    "        _, loss, acc = self._get_preds_loss_accuracy(batch)\n",
+    "#     def training_step(self, batch, batch_idx):\n",
+    "#         '''needs to return a loss from a single batch'''\n",
+    "#         _, loss, acc = self._get_preds_loss_accuracy(batch)\n",
     "\n",
-    "        # Log loss and metric\n",
-    "        self.log('train_loss', loss)\n",
-    "        self.log('train_accuracy', acc)\n",
+    "#         # Log loss and metric\n",
+    "#         self.log('train_loss', loss)\n",
+    "#         self.log('train_accuracy', acc)\n",
     "\n",
-    "        return loss\n",
+    "#         return loss\n",
     "\n",
-    "    def validation_step(self, batch, batch_idx):\n",
-    "        '''used for logging metrics'''\n",
-    "        preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
+    "#     def validation_step(self, batch, batch_idx):\n",
+    "#         '''used for logging metrics'''\n",
+    "#         preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
     "\n",
-    "        # Log loss and metric\n",
-    "        self.log('val_loss', loss)\n",
-    "        self.log('val_accuracy', acc)\n",
+    "#         # Log loss and metric\n",
+    "#         self.log('val_loss', loss)\n",
+    "#         self.log('val_accuracy', acc)\n",
     "\n",
-    "        # Let's return preds to use it in a custom callback\n",
-    "        return preds\n",
+    "#         # Let's return preds to use it in a custom callback\n",
+    "#         return preds\n",
     "\n",
-    "    def test_step(self, batch, batch_idx):\n",
-    "        '''used for logging metrics'''\n",
-    "        _, loss, acc = self._get_preds_loss_accuracy(batch)\n",
+    "#     def test_step(self, batch, batch_idx):\n",
+    "#         '''used for logging metrics'''\n",
+    "#         _, loss, acc = self._get_preds_loss_accuracy(batch)\n",
     "\n",
-    "        # Log loss and metric\n",
-    "        self.log('test_loss', loss)\n",
-    "        self.log('test_accuracy', acc)\n",
+    "#         # Log loss and metric\n",
+    "#         self.log('test_loss', loss)\n",
+    "#         self.log('test_accuracy', acc)\n",
     "    \n",
-    "    def configure_optimizers(self):\n",
-    "        '''defines model optimizer'''\n",
-    "        return Adam(self.parameters(), lr=self.lr)\n",
+    "#     def configure_optimizers(self):\n",
+    "#         '''defines model optimizer'''\n",
+    "#         return Adam(self.parameters(), lr=self.lr)\n",
     "    \n",
-    "    def _get_preds_loss_accuracy(self, batch):\n",
-    "        '''convenience function since train/valid/test steps are similar'''\n",
-    "        x, y = batch\n",
-    "        logits = self(x)\n",
-    "        preds = torch.argmax(logits, dim=1)\n",
-    "        loss = self.loss(logits, y)\n",
-    "        acc = accuracy(preds, y, 'multiclass', num_classes=10)\n",
-    "        return preds, loss, acc"
+    "#     def _get_preds_loss_accuracy(self, batch):\n",
+    "#         '''convenience function since train/valid/test steps are similar'''\n",
+    "#         x, y = batch\n",
+    "#         logits = self(x)\n",
+    "#         preds = torch.argmax(logits, dim=1)\n",
+    "#         loss = self.loss(logits, y)\n",
+    "#         acc = accuracy(preds, y, 'multiclass', num_classes=10)\n",
+    "#         return preds, loss, acc"
    ]
   },
   {
diff --git a/Train/PyLi_wanb_sweep_CoatNet.ipynb b/Train/PyLi_wanb_sweep_CoatNet.ipynb
index cd4d5a1..6366a5c 100644
--- a/Train/PyLi_wanb_sweep_CoatNet.ipynb
+++ b/Train/PyLi_wanb_sweep_CoatNet.ipynb
@@ -6,11 +6,11 @@
    "id": "c7b471f1-f5fa-4eb1-b9ae-2d67ed8838df",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-03T03:11:02.279914Z",
-     "iopub.status.busy": "2023-03-03T03:11:02.279412Z",
-     "iopub.status.idle": "2023-03-03T03:11:06.839816Z",
-     "shell.execute_reply": "2023-03-03T03:11:06.838820Z",
-     "shell.execute_reply.started": "2023-03-03T03:11:02.279914Z"
+     "iopub.execute_input": "2023-03-06T17:27:33.222867Z",
+     "iopub.status.busy": "2023-03-06T17:27:33.222371Z",
+     "iopub.status.idle": "2023-03-06T17:27:39.815563Z",
+     "shell.execute_reply": "2023-03-06T17:27:39.814561Z",
+     "shell.execute_reply.started": "2023-03-06T17:27:33.222867Z"
     },
     "tags": []
    },
@@ -74,11 +74,11 @@
    "id": "01c28e3c-850d-48b6-8db9-3a8804e0c9ae",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-03T03:11:06.841817Z",
-     "iopub.status.busy": "2023-03-03T03:11:06.841318Z",
-     "iopub.status.idle": "2023-03-03T03:11:06.871317Z",
-     "shell.execute_reply": "2023-03-03T03:11:06.869816Z",
-     "shell.execute_reply.started": "2023-03-03T03:11:06.841817Z"
+     "iopub.execute_input": "2023-03-06T17:27:39.817562Z",
+     "iopub.status.busy": "2023-03-06T17:27:39.817061Z",
+     "iopub.status.idle": "2023-03-06T17:27:39.846563Z",
+     "shell.execute_reply": "2023-03-06T17:27:39.845562Z",
+     "shell.execute_reply.started": "2023-03-06T17:27:39.817562Z"
     },
     "tags": []
    },
@@ -141,11 +141,11 @@
    "id": "8b9e722b-cda4-4956-a0c1-8eb31023f765",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-03T03:11:06.875318Z",
-     "iopub.status.busy": "2023-03-03T03:11:06.874818Z",
-     "iopub.status.idle": "2023-03-03T03:11:06.932817Z",
-     "shell.execute_reply": "2023-03-03T03:11:06.931815Z",
-     "shell.execute_reply.started": "2023-03-03T03:11:06.875318Z"
+     "iopub.execute_input": "2023-03-06T17:27:39.850061Z",
+     "iopub.status.busy": "2023-03-06T17:27:39.849563Z",
+     "iopub.status.idle": "2023-03-06T17:27:39.877562Z",
+     "shell.execute_reply": "2023-03-06T17:27:39.876563Z",
+     "shell.execute_reply.started": "2023-03-06T17:27:39.850061Z"
     },
     "tags": []
    },
@@ -189,11 +189,11 @@
    "id": "9dbe4b19-9805-40b4-a513-ea35715a0c64",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-03T03:11:06.934316Z",
-     "iopub.status.busy": "2023-03-03T03:11:06.933816Z",
-     "iopub.status.idle": "2023-03-03T03:11:07.009898Z",
-     "shell.execute_reply": "2023-03-03T03:11:07.008895Z",
-     "shell.execute_reply.started": "2023-03-03T03:11:06.934316Z"
+     "iopub.execute_input": "2023-03-06T17:27:39.880061Z",
+     "iopub.status.busy": "2023-03-06T17:27:39.879563Z",
+     "iopub.status.idle": "2023-03-06T17:27:39.955070Z",
+     "shell.execute_reply": "2023-03-06T17:27:39.954068Z",
+     "shell.execute_reply.started": "2023-03-06T17:27:39.880061Z"
     },
     "tags": []
    },
@@ -225,11 +225,11 @@
    "id": "7539d3a5-ca4f-4ba3-a462-05875d4b9a90",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-03T03:11:07.011896Z",
-     "iopub.status.busy": "2023-03-03T03:11:07.011396Z",
-     "iopub.status.idle": "2023-03-03T03:11:07.087447Z",
-     "shell.execute_reply": "2023-03-03T03:11:07.086446Z",
-     "shell.execute_reply.started": "2023-03-03T03:11:07.011896Z"
+     "iopub.execute_input": "2023-03-06T17:27:39.956571Z",
+     "iopub.status.busy": "2023-03-06T17:27:39.956571Z",
+     "iopub.status.idle": "2023-03-06T17:27:40.155595Z",
+     "shell.execute_reply": "2023-03-06T17:27:40.154594Z",
+     "shell.execute_reply.started": "2023-03-06T17:27:39.956571Z"
     },
     "tags": []
    },
@@ -277,122 +277,122 @@
    "id": "deb34aed-792a-4022-a878-f8d6c4ffa97c",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-03T03:11:07.089454Z",
-     "iopub.status.busy": "2023-03-03T03:11:07.088953Z",
-     "iopub.status.idle": "2023-03-03T03:11:07.164394Z",
-     "shell.execute_reply": "2023-03-03T03:11:07.163393Z",
-     "shell.execute_reply.started": "2023-03-03T03:11:07.089454Z"
+     "iopub.execute_input": "2023-03-06T17:27:40.157598Z",
+     "iopub.status.busy": "2023-03-06T17:27:40.157096Z",
+     "iopub.status.idle": "2023-03-06T17:27:40.248232Z",
+     "shell.execute_reply": "2023-03-06T17:27:40.247229Z",
+     "shell.execute_reply.started": "2023-03-06T17:27:40.157598Z"
     },
     "tags": []
    },
    "outputs": [],
    "source": [
-    "# class MyModel(LightningModule):\n",
+    "class MyModel(LightningModule):\n",
     "\n",
-    "#     def __init__(self, n_classes=10, acc_task=\"multiclass\", lr=1e-3):\n",
-    "#         super().__init__()\n",
-    "#         \"\"\"\n",
-    "#         The convolutions are arranged in such a way that the image maintain the x and y dimensions. only the channels change\n",
-    "#         \"\"\"\n",
-    "#         self.layer_1 = nn.Conv2d(in_channels = 1,out_channels = 3,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "#         self.layer_2 = nn.Conv2d(in_channels = 3,out_channels = 6,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "#         self.layer_3 = nn.Conv2d(in_channels = 6,out_channels = 12,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "#         self.pool = nn.MaxPool2d(kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "#         self.layer_5 = nn.Linear(12*50*50,1000)#the input dimensions are (Number of dimensions * height * width)\n",
-    "#         self.layer_6 = nn.Linear(1000,100)\n",
-    "#         self.layer_7 = nn.Linear(100,50)\n",
-    "#         self.layer_8 = nn.Linear(50,10)\n",
-    "#         self.layer_9 = nn.Linear(10,10)\n",
-    "#         self.lr = lr\n",
-    "#         # metrics\n",
-    "#         self.acc_task = acc_task\n",
-    "#         self.n_classes = n_classes\n",
-    "#         self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.n_classes)\n",
-    "#         self.class_names = classes_lst\n",
-    "#         self.loss = CrossEntropyLoss()\n",
+    "    def __init__(self, n_classes=10, acc_task=\"multiclass\", lr=1e-3):\n",
+    "        super().__init__()\n",
+    "        \"\"\"\n",
+    "        The convolutions are arranged in such a way that the image maintain the x and y dimensions. only the channels change\n",
+    "        \"\"\"\n",
+    "        self.layer_1 = nn.Conv2d(in_channels = 1,out_channels = 3,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "        self.layer_2 = nn.Conv2d(in_channels = 3,out_channels = 6,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "        self.layer_3 = nn.Conv2d(in_channels = 6,out_channels = 12,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "        self.pool = nn.MaxPool2d(kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "        self.layer_5 = nn.Linear(12*50*50,1000)#the input dimensions are (Number of dimensions * height * width)\n",
+    "        self.layer_6 = nn.Linear(1000,100)\n",
+    "        self.layer_7 = nn.Linear(100,50)\n",
+    "        self.layer_8 = nn.Linear(50,10)\n",
+    "        self.layer_9 = nn.Linear(10,10)\n",
+    "        self.lr = lr\n",
+    "        # metrics\n",
+    "        self.acc_task = acc_task\n",
+    "        self.n_classes = n_classes\n",
+    "        self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.n_classes)\n",
+    "        self.class_names = classes_lst\n",
+    "        self.loss = CrossEntropyLoss()\n",
     "\n",
-    "#         # optional - save hyper-parameters to self.hparams\n",
-    "#         # they will also be automatically logged as config parameters in W&B\n",
-    "#         self.save_hyperparameters()\n",
+    "        # optional - save hyper-parameters to self.hparams\n",
+    "        # they will also be automatically logged as config parameters in W&B\n",
+    "        self.save_hyperparameters()\n",
     "\n",
-    "#     def forward(self,x):\n",
-    "#         \"\"\"\n",
-    "#         x is the input data\n",
-    "#         \"\"\"\n",
-    "#         x = self.layer_1(x)\n",
-    "#         x = self.pool(x)\n",
-    "#         x = self.layer_2(x)\n",
-    "#         x = self.pool(x)\n",
-    "#         x = self.layer_3(x)\n",
-    "#         x = self.pool(x)\n",
-    "#         x = x.view(x.size(0),-1)\n",
-    "#         print(x.size())\n",
-    "#         x = self.layer_5(x)\n",
-    "#         x = self.layer_6(x)\n",
-    "#         x = self.layer_7(x)\n",
-    "#         x = self.layer_8(x)\n",
-    "#         x = self.layer_9(x)\n",
-    "#         return x\n",
+    "    def forward(self,x):\n",
+    "        \"\"\"\n",
+    "        x is the input data\n",
+    "        \"\"\"\n",
+    "        x = self.layer_1(x)\n",
+    "        x = self.pool(x)\n",
+    "        x = self.layer_2(x)\n",
+    "        x = self.pool(x)\n",
+    "        x = self.layer_3(x)\n",
+    "        x = self.pool(x)\n",
+    "        x = x.view(x.size(0),-1)\n",
+    "        print(x.size())\n",
+    "        x = self.layer_5(x)\n",
+    "        x = self.layer_6(x)\n",
+    "        x = self.layer_7(x)\n",
+    "        x = self.layer_8(x)\n",
+    "        x = self.layer_9(x)\n",
+    "        return x\n",
     "\n",
-    "#     def configure_optimizers(self):\n",
-    "#         optimizer = torch.optim.Adam(self.parameters(),lr = self.lr)\n",
-    "#         return optimizer\n",
+    "    def configure_optimizers(self):\n",
+    "        optimizer = torch.optim.Adam(self.parameters(),lr = self.lr)\n",
+    "        return optimizer\n",
     "\n",
-    "# # The Pytorch-Lightning module handles all the iterations of the epoch\n",
+    "# The Pytorch-Lightning module handles all the iterations of the epoch\n",
     "\n",
-    "#     def training_step(self,batch,batch_idx):\n",
-    "#         x,y = batch\n",
-    "#         y_pred = self(x)\n",
-    "#         loss = F.cross_entropy(y_pred,y)\n",
-    "#         # Log training loss\n",
-    "#         self.log('train_loss', loss)\n",
-    "#         # Log metrics\n",
-    "#         self.log('train_acc', self.accuracy(y_pred, y))\n",
-    "#         return loss\n",
+    "    def training_step(self,batch,batch_idx):\n",
+    "        x,y = batch\n",
+    "        y_pred = self(x)\n",
+    "        loss = F.cross_entropy(y_pred,y)\n",
+    "        # Log training loss\n",
+    "        self.log('train_loss', loss)\n",
+    "        # Log metrics\n",
+    "        self.log('train_acc', self.accuracy(y_pred, y))\n",
+    "        return loss\n",
     "\n",
-    "#     def validation_step(self,batch,batch_idx):\n",
-    "#         preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
-    "#         # Log loss and metric\n",
-    "#         self.log('val_loss_alt', loss)\n",
-    "#         self.log('val_accuracy_alt', acc)\n",
+    "    def validation_step(self,batch,batch_idx):\n",
+    "        preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
+    "        # Log loss and metric\n",
+    "        self.log('val_loss_alt', loss)\n",
+    "        self.log('val_accuracy_alt', acc)\n",
     "        \n",
-    "#         x,y = batch\n",
-    "#         y_pred = self(x)\n",
-    "#         loss = F.cross_entropy(y_pred,y)\n",
-    "#         # Log training loss\n",
-    "#         self.log('val_loss', loss)\n",
-    "#         # Log metrics\n",
-    "#         self.log('val_acc', self.accuracy(y_pred, y))\n",
-    "#         self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
-    "#         self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
-    "#         wandb.log({\"val_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
-    "#                         y_true=self.cpu_y, preds=None,\n",
-    "#                         class_names=self.class_names)})\n",
-    "#         return preds\n",
+    "        x,y = batch\n",
+    "        y_pred = self(x)\n",
+    "        loss = F.cross_entropy(y_pred,y)\n",
+    "        # Log training loss\n",
+    "        self.log('val_loss', loss)\n",
+    "        # Log metrics\n",
+    "        self.log('val_acc', self.accuracy(y_pred, y))\n",
+    "        self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
+    "        self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
+    "        wandb.log({\"val_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
+    "                        y_true=self.cpu_y, preds=None,\n",
+    "                        class_names=self.class_names)})\n",
+    "        return preds\n",
     "\n",
-    "#     def test_step(self,batch,batch_idx):\n",
-    "#         x,y = batch\n",
-    "#         y_pred = self(x)\n",
-    "#         loss = F.cross_entropy(y_pred,y)\n",
-    "#         # Log training loss\n",
-    "#         self.log('test_loss', loss)\n",
-    "#         # Log metrics\n",
-    "#         self.log('test_acc', self.accuracy(y_pred, y))\n",
-    "#         self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
-    "#         self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
-    "#         wandb.log({\"test_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
-    "#                         y_true=self.cpu_y, preds=None,\n",
-    "#                         class_names=self.class_names)})\n",
-    "#         return loss\n",
+    "    def test_step(self,batch,batch_idx):\n",
+    "        x,y = batch\n",
+    "        y_pred = self(x)\n",
+    "        loss = F.cross_entropy(y_pred,y)\n",
+    "        # Log training loss\n",
+    "        self.log('test_loss', loss)\n",
+    "        # Log metrics\n",
+    "        self.log('test_acc', self.accuracy(y_pred, y))\n",
+    "        self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
+    "        self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
+    "        wandb.log({\"test_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
+    "                        y_true=self.cpu_y, preds=None,\n",
+    "                        class_names=self.class_names)})\n",
+    "        return loss\n",
     "    \n",
-    "#     def _get_preds_loss_accuracy(self, batch):\n",
-    "#         '''convenience function since train/valid/test steps are similar'''\n",
-    "#         x, y = batch\n",
-    "#         logits = self(x)\n",
-    "#         preds = torch.argmax(logits, dim=1)\n",
-    "#         loss = self.loss(logits, y)\n",
-    "#         acc = accuracy(preds, y, self.acc_task, num_classes=10)\n",
-    "#         return preds, loss, acc"
+    "    def _get_preds_loss_accuracy(self, batch):\n",
+    "        '''convenience function since train/valid/test steps are similar'''\n",
+    "        x, y = batch\n",
+    "        logits = self(x)\n",
+    "        preds = torch.argmax(logits, dim=1)\n",
+    "        loss = self.loss(logits, y)\n",
+    "        acc = accuracy(preds, y, self.acc_task, num_classes=10)\n",
+    "        return preds, loss, acc"
    ]
   },
   {
@@ -401,93 +401,93 @@
    "id": "da2dc124-242c-4eca-9de0-410760b205bd",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-03T03:11:07.166393Z",
-     "iopub.status.busy": "2023-03-03T03:11:07.165893Z",
-     "iopub.status.idle": "2023-03-03T03:11:07.241567Z",
-     "shell.execute_reply": "2023-03-03T03:11:07.240568Z",
-     "shell.execute_reply.started": "2023-03-03T03:11:07.165893Z"
+     "iopub.execute_input": "2023-03-06T17:27:40.250230Z",
+     "iopub.status.busy": "2023-03-06T17:27:40.249730Z",
+     "iopub.status.idle": "2023-03-06T17:27:40.294728Z",
+     "shell.execute_reply": "2023-03-06T17:27:40.293727Z",
+     "shell.execute_reply.started": "2023-03-06T17:27:40.250230Z"
     }
    },
    "outputs": [],
    "source": [
-    "class MyModel(LightningModule): \n",
+    "# class MyModel(LightningModule): \n",
     "\n",
-    "    def __init__(self, n_classes=10, n_layer_1=128, n_layer_2=256, lr=1e-3): \n",
-    "        '''method used to define our model parameters'''\n",
-    "        super().__init__()\n",
+    "#     def __init__(self, n_classes=10, n_layer_1=128, n_layer_2=256, lr=1e-3): \n",
+    "#         '''method used to define our model parameters'''\n",
+    "#         super().__init__()\n",
     "\n",
-    "        # mnist images are (1, 28, 28) (channels, width, height\n",
-    "        self.layer_1 = Linear(28 * 28, n_layer_1)\n",
-    "        self.layer_2 = Linear(n_layer_1, n_layer_2)\n",
-    "        self.layer_3 = Linear(n_layer_2, n_classes)\n",
+    "#         # mnist images are (1, 28, 28) (channels, width, height\n",
+    "#         self.layer_1 = Linear(28 * 28, n_layer_1)\n",
+    "#         self.layer_2 = Linear(n_layer_1, n_layer_2)\n",
+    "#         self.layer_3 = Linear(n_layer_2, n_classes)\n",
     "\n",
-    "        # loss\n",
-    "        self.loss = CrossEntropyLoss()\n",
+    "#         # loss\n",
+    "#         self.loss = CrossEntropyLoss()\n",
     "\n",
-    "        # optimizer parameters\n",
-    "        self.lr = lr\n",
+    "#         # optimizer parameters\n",
+    "#         self.lr = lr\n",
     "\n",
-    "        # save hyper-parameters to self.hparams (auto-logged by W&B)\n",
-    "        self.save_hyperparameters() \n",
+    "#         # save hyper-parameters to self.hparams (auto-logged by W&B)\n",
+    "#         self.save_hyperparameters() \n",
     "\n",
-    "    def forward(self, x):\n",
-    "        '''method used for inference input -> output'''\n",
+    "#     def forward(self, x):\n",
+    "#         '''method used for inference input -> output'''\n",
     "\n",
-    "        batch_size, channels, width, height = x.size()\n",
+    "#         batch_size, channels, width, height = x.size()\n",
     "\n",
-    "        # (b, 1, 28, 28) -> (b, 1*28*28)\n",
-    "        x = x.view(batch_size, -1)\n",
+    "#         # (b, 1, 28, 28) -> (b, 1*28*28)\n",
+    "#         x = x.view(batch_size, -1)\n",
     "\n",
-    "        # let's do 3 x (linear + relu)\n",
-    "        x = self.layer_1(x)\n",
-    "        x = F.relu(x)\n",
-    "        x = self.layer_2(x)\n",
-    "        x = F.relu(x)\n",
-    "        x = self.layer_3(x)\n",
+    "#         # let's do 3 x (linear + relu)\n",
+    "#         x = self.layer_1(x)\n",
+    "#         x = F.relu(x)\n",
+    "#         x = self.layer_2(x)\n",
+    "#         x = F.relu(x)\n",
+    "#         x = self.layer_3(x)\n",
     "\n",
-    "        return x\n",
+    "#         return x\n",
     "\n",
-    "    def training_step(self, batch, batch_idx):\n",
-    "        '''needs to return a loss from a single batch'''\n",
-    "        _, loss, acc = self._get_preds_loss_accuracy(batch)\n",
+    "#     def training_step(self, batch, batch_idx):\n",
+    "#         '''needs to return a loss from a single batch'''\n",
+    "#         _, loss, acc = self._get_preds_loss_accuracy(batch)\n",
     "\n",
-    "        # Log loss and metric\n",
-    "        self.log('train_loss', loss)\n",
-    "        self.log('train_accuracy', acc)\n",
+    "#         # Log loss and metric\n",
+    "#         self.log('train_loss', loss)\n",
+    "#         self.log('train_accuracy', acc)\n",
     "\n",
-    "        return loss\n",
+    "#         return loss\n",
     "\n",
-    "    def validation_step(self, batch, batch_idx):\n",
-    "        '''used for logging metrics'''\n",
-    "        preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
+    "#     def validation_step(self, batch, batch_idx):\n",
+    "#         '''used for logging metrics'''\n",
+    "#         preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
     "\n",
-    "        # Log loss and metric\n",
-    "        self.log('val_loss', loss)\n",
-    "        self.log('val_accuracy', acc)\n",
+    "#         # Log loss and metric\n",
+    "#         self.log('val_loss', loss)\n",
+    "#         self.log('val_accuracy', acc)\n",
     "\n",
-    "        # Let's return preds to use it in a custom callback\n",
-    "        return preds\n",
+    "#         # Let's return preds to use it in a custom callback\n",
+    "#         return preds\n",
     "\n",
-    "    def test_step(self, batch, batch_idx):\n",
-    "        '''used for logging metrics'''\n",
-    "        _, loss, acc = self._get_preds_loss_accuracy(batch)\n",
+    "#     def test_step(self, batch, batch_idx):\n",
+    "#         '''used for logging metrics'''\n",
+    "#         _, loss, acc = self._get_preds_loss_accuracy(batch)\n",
     "\n",
-    "        # Log loss and metric\n",
-    "        self.log('test_loss', loss)\n",
-    "        self.log('test_accuracy', acc)\n",
+    "#         # Log loss and metric\n",
+    "#         self.log('test_loss', loss)\n",
+    "#         self.log('test_accuracy', acc)\n",
     "    \n",
-    "    def configure_optimizers(self):\n",
-    "        '''defines model optimizer'''\n",
-    "        return Adam(self.parameters(), lr=self.lr)\n",
+    "#     def configure_optimizers(self):\n",
+    "#         '''defines model optimizer'''\n",
+    "#         return Adam(self.parameters(), lr=self.lr)\n",
     "    \n",
-    "    def _get_preds_loss_accuracy(self, batch):\n",
-    "        '''convenience function since train/valid/test steps are similar'''\n",
-    "        x, y = batch\n",
-    "        logits = self(x)\n",
-    "        preds = torch.argmax(logits, dim=1)\n",
-    "        loss = self.loss(logits, y)\n",
-    "        acc = accuracy(preds, y, 'multiclass', num_classes=10)\n",
-    "        return preds, loss, acc"
+    "#     def _get_preds_loss_accuracy(self, batch):\n",
+    "#         '''convenience function since train/valid/test steps are similar'''\n",
+    "#         x, y = batch\n",
+    "#         logits = self(x)\n",
+    "#         preds = torch.argmax(logits, dim=1)\n",
+    "#         loss = self.loss(logits, y)\n",
+    "#         acc = accuracy(preds, y, 'multiclass', num_classes=10)\n",
+    "#         return preds, loss, acc"
    ]
   },
   {
@@ -504,11 +504,11 @@
    "id": "188ce4ef-e6b7-4320-8e5d-ceeb616bf7d1",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-03T03:11:07.243567Z",
-     "iopub.status.busy": "2023-03-03T03:11:07.243069Z",
-     "iopub.status.idle": "2023-03-03T03:11:07.319086Z",
-     "shell.execute_reply": "2023-03-03T03:11:07.318084Z",
-     "shell.execute_reply.started": "2023-03-03T03:11:07.243567Z"
+     "iopub.execute_input": "2023-03-06T17:27:40.296728Z",
+     "iopub.status.busy": "2023-03-06T17:27:40.296228Z",
+     "iopub.status.idle": "2023-03-06T17:27:40.418431Z",
+     "shell.execute_reply": "2023-03-06T17:27:40.417428Z",
+     "shell.execute_reply.started": "2023-03-06T17:27:40.296728Z"
     },
     "tags": []
    },
@@ -549,11 +549,11 @@
    "id": "762279ca-26d9-4310-992f-b6f8912da7fe",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-03T03:11:07.321087Z",
-     "iopub.status.busy": "2023-03-03T03:11:07.320586Z",
-     "iopub.status.idle": "2023-03-03T03:11:17.703497Z",
-     "shell.execute_reply": "2023-03-03T03:11:17.697999Z",
-     "shell.execute_reply.started": "2023-03-03T03:11:07.321087Z"
+     "iopub.execute_input": "2023-03-06T17:27:40.420429Z",
+     "iopub.status.busy": "2023-03-06T17:27:40.419929Z",
+     "iopub.status.idle": "2023-03-06T17:30:42.528877Z",
+     "shell.execute_reply": "2023-03-06T17:30:42.527376Z",
+     "shell.execute_reply.started": "2023-03-06T17:27:40.420429Z"
     },
     "tags": []
    },
@@ -565,6 +565,20 @@
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristopher-marais\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
      ]
     },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "b71eed9c2fb04f69806303e7da6d40b2",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0â€¦"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
     {
      "data": {
       "text/html": [
@@ -580,7 +594,7 @@
     {
      "data": {
       "text/html": [
-       "Run data is saved locally in <code>.\\wandb\\run-20230302_221110-qyxg8y6m</code>"
+       "Run data is saved locally in <code>.\\wandb\\run-20230306_122743-6251b24p</code>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -592,7 +606,7 @@
     {
      "data": {
       "text/html": [
-       "Syncing run <strong><a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/qyxg8y6m' target=\"_blank\">avid-feather-18</a></strong> to <a href='https://wandb.ai/christopher-marais/computer_vision_test_single' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
+       "Syncing run <strong><a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/6251b24p' target=\"_blank\">lively-violet-19</a></strong> to <a href='https://wandb.ai/christopher-marais/computer_vision_test_single' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -616,7 +630,7 @@
     {
      "data": {
       "text/html": [
-       " View run at <a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/qyxg8y6m' target=\"_blank\">https://wandb.ai/christopher-marais/computer_vision_test_single/runs/qyxg8y6m</a>"
+       " View run at <a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/6251b24p' target=\"_blank\">https://wandb.ai/christopher-marais/computer_vision_test_single/runs/6251b24p</a>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -635,23 +649,30 @@
       "HPU available: False, using: 0 HPUs\n",
       "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
       "\n",
-      "  | Name    | Type             | Params\n",
-      "---------------------------------------------\n",
-      "0 | layer_1 | Linear           | 100 K \n",
-      "1 | layer_2 | Linear           | 33.0 K\n",
-      "2 | layer_3 | Linear           | 2.6 K \n",
-      "3 | loss    | CrossEntropyLoss | 0     \n",
-      "---------------------------------------------\n",
-      "136 K     Trainable params\n",
+      "   | Name     | Type               | Params\n",
+      "-------------------------------------------------\n",
+      "0  | layer_1  | Conv2d             | 30    \n",
+      "1  | layer_2  | Conv2d             | 168   \n",
+      "2  | layer_3  | Conv2d             | 660   \n",
+      "3  | pool     | MaxPool2d          | 0     \n",
+      "4  | layer_5  | Linear             | 30.0 M\n",
+      "5  | layer_6  | Linear             | 100 K \n",
+      "6  | layer_7  | Linear             | 5.0 K \n",
+      "7  | layer_8  | Linear             | 510   \n",
+      "8  | layer_9  | Linear             | 110   \n",
+      "9  | accuracy | MulticlassAccuracy | 0     \n",
+      "10 | loss     | CrossEntropyLoss   | 0     \n",
+      "-------------------------------------------------\n",
+      "30.1 M    Trainable params\n",
       "0         Non-trainable params\n",
-      "136 K     Total params\n",
-      "0.544     Total estimated model params size (MB)\n"
+      "30.1 M    Total params\n",
+      "120.431   Total estimated model params size (MB)\n"
      ]
     },
     {
      "data": {
       "application/vnd.jupyter.widget-view+json": {
-       "model_id": "00626ec5319d435cbc59512c050540b4",
+       "model_id": "",
        "version_major": 2,
        "version_minor": 0
       },
@@ -673,34 +694,329 @@
      ]
     },
     {
-     "ename": "RuntimeError",
-     "evalue": "mat1 and mat2 shapes cannot be multiplied (10x2500 and 784x128)",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
-      "Cell \u001b[1;32mIn[9], line 21\u001b[0m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m MyModel(n_classes\u001b[38;5;241m=\u001b[39mnum_of_classes)\n\u001b[0;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     14\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     15\u001b[0m     devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;66;03m# use all GPU's (-1)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m            \u001b[38;5;66;03m# number of epochs\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     )\n\u001b[1;32m---> 21\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtest(model, datamodule\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m     25\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
-      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Trainer.fit()` requires a `LightningModule`, got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m--> 608\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
-      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     41\u001b[0m     trainer\u001b[38;5;241m.\u001b[39m_call_teardown_hook()\n",
-      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    643\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_set_ckpt_path(\n\u001b[0;32m    645\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    646\u001b[0m     ckpt_path,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    647\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    648\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    649\u001b[0m )\n\u001b[1;32m--> 650\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
-      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1103\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[1;32m-> 1103\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
-      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1182\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[1;32m-> 1182\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
-      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1195\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_training_routine()\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1195\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[38;5;66;03m# enable train mode\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
-      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1267\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m-> 1267\u001b[0m     \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
-      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
-      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\dataloader\\evaluation_loop.py:152\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_dataloaders \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    151\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dataloader_idx\n\u001b[1;32m--> 152\u001b[0m dl_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_max_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# store batch level output per dataloader\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs\u001b[38;5;241m.\u001b[39mappend(dl_outputs)\n",
-      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
-      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:137\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[1;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# lightning module methods\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step_end(output)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n",
-      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:234\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"The evaluation step (validation_step or test_step depending on the trainer's state).\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124;03m    the outputs of the step\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    233\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 234\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
-      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1485\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1485\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m   1488\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
-      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:390\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mval_step_context():\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, ValidationStep)\n\u001b[1;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mvalidation_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
-      "Cell \u001b[1;32mIn[7], line 50\u001b[0m, in \u001b[0;36mMyModel.validation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;124;03m'''used for logging metrics'''\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     preds, loss, acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_preds_loss_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# Log loss and metric\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, loss)\n",
-      "Cell \u001b[1;32mIn[7], line 74\u001b[0m, in \u001b[0;36mMyModel._get_preds_loss_accuracy\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m'''convenience function since train/valid/test steps are similar'''\u001b[39;00m\n\u001b[0;32m     73\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m---> 74\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     76\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(logits, y)\n",
-      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
-      "Cell \u001b[1;32mIn[7], line 30\u001b[0m, in \u001b[0;36mMyModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# let's do 3 x (linear + relu)\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_2(x)\n",
-      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
-      "File \u001b[1;32m~\\anaconda3\\envs\\BC_310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
-      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10x2500 and 784x128)"
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "C:\\Users\\GCM\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
+      "  rank_zero_warn(\n",
+      "C:\\Users\\GCM\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1600: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
+      "  rank_zero_warn(\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "bbfda825a0654156bfa53cd86736a73c",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "Training: 0it [00:00, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([10, 30000])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "Validation: 0it [00:00, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "Validation: 0it [00:00, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "Validation: 0it [00:00, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "Validation: 0it [00:00, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "Validation: 0it [00:00, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "Validation: 0it [00:00, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "Validation: 0it [00:00, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "Validation: 0it [00:00, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "Validation: 0it [00:00, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "Validation: 0it [00:00, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([10, 30000])\n",
+      "torch.Size([10, 30000])\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
+      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
+      "C:\\Users\\GCM\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:488: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
+      "  rank_zero_warn(\n",
+      "C:\\Users\\GCM\\anaconda3\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
+      "  rank_zero_warn(\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "eb7425746e8e4358beb7da3683044dab",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "Testing: 0it [00:00, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([10, 30000])\n",
+      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
+      "       Test metric             DataLoader 0\n",
+      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
+      "        test_acc            0.10000000149011612\n",
+      "        test_loss           2.7611680030822754\n",
+      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n"
      ]
     }
    ],
@@ -734,18 +1050,28 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 10,
    "id": "3b58022d-6961-41b0-a4e1-60bbc1c09791",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-03T03:11:17.704998Z",
-     "iopub.status.idle": "2023-03-03T03:11:17.705497Z",
-     "shell.execute_reply": "2023-03-03T03:11:17.704998Z",
-     "shell.execute_reply.started": "2023-03-03T03:11:17.704998Z"
+     "iopub.execute_input": "2023-03-06T17:30:42.530878Z",
+     "iopub.status.busy": "2023-03-06T17:30:42.530378Z",
+     "iopub.status.idle": "2023-03-06T17:30:42.559878Z",
+     "shell.execute_reply": "2023-03-06T17:30:42.542882Z",
+     "shell.execute_reply.started": "2023-03-06T17:30:42.530878Z"
     },
     "tags": []
    },
-   "outputs": [],
+   "outputs": [
+    {
+     "ename": "SyntaxError",
+     "evalue": "unterminated string literal (detected at line 1) (2442771434.py, line 1)",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    d'd\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
+     ]
+    }
+   ],
    "source": [
     "d'd"
    ]
@@ -764,10 +1090,10 @@
    "id": "ebde1018-ddfa-43f2-b9c6-f2c1d4b19736",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-03T03:11:17.707495Z",
-     "iopub.status.idle": "2023-03-03T03:11:17.707995Z",
-     "shell.execute_reply": "2023-03-03T03:11:17.707495Z",
-     "shell.execute_reply.started": "2023-03-03T03:11:17.707495Z"
+     "iopub.status.busy": "2023-03-06T17:30:42.561379Z",
+     "iopub.status.idle": "2023-03-06T17:30:42.562380Z",
+     "shell.execute_reply": "2023-03-06T17:30:42.561880Z",
+     "shell.execute_reply.started": "2023-03-06T17:30:42.561880Z"
     },
     "tags": []
    },
@@ -810,10 +1136,10 @@
    "id": "91aeb8a0-9ffd-4439-808c-2951d1f74b36",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-03T03:11:17.709497Z",
-     "iopub.status.idle": "2023-03-03T03:11:17.709995Z",
-     "shell.execute_reply": "2023-03-03T03:11:17.709995Z",
-     "shell.execute_reply.started": "2023-03-03T03:11:17.709995Z"
+     "iopub.status.busy": "2023-03-06T17:30:42.564380Z",
+     "iopub.status.idle": "2023-03-06T17:30:42.565380Z",
+     "shell.execute_reply": "2023-03-06T17:30:42.565380Z",
+     "shell.execute_reply.started": "2023-03-06T17:30:42.565380Z"
     },
     "tags": []
    },
@@ -853,10 +1179,10 @@
    "id": "869b0393-21cf-4fba-8efd-7678a852b697",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-03T03:11:17.711497Z",
-     "iopub.status.idle": "2023-03-03T03:11:17.711995Z",
-     "shell.execute_reply": "2023-03-03T03:11:17.711497Z",
-     "shell.execute_reply.started": "2023-03-03T03:11:17.711497Z"
+     "iopub.status.busy": "2023-03-06T17:30:42.567879Z",
+     "iopub.status.idle": "2023-03-06T17:30:42.568881Z",
+     "shell.execute_reply": "2023-03-06T17:30:42.568881Z",
+     "shell.execute_reply.started": "2023-03-06T17:30:42.568881Z"
     },
     "tags": []
    },
diff --git a/Train/wandb/debug-cli.GCM.log b/Train/wandb/debug-cli.GCM.log
index 9f31a87..eccfa7f 100644
--- a/Train/wandb/debug-cli.GCM.log
+++ b/Train/wandb/debug-cli.GCM.log
@@ -1,121 +1,123 @@
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:53 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:53 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:29:53 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:17 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:17 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:05 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:05 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:05 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-03-02 21:28:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-03-02 21:28:11 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-03-02 21:28:50 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-03-02 21:28:56 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-03-02 21:33:34 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-03-02 21:35:11 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-03-02 21:35:17 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-03-02 21:56:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-03-02 22:03:11 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
-2023-03-02 22:03:17 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:52 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:53 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:53 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:29:53 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:16 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:17 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:17 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:30:41 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:05 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:05 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:05 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 15:31:30 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:10:46 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:09 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:11:35 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:27 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-02-28 23:12:55 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-03-02 21:28:06 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-03-02 21:28:11 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-03-02 21:28:50 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-03-02 21:28:56 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-03-02 21:33:34 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-03-02 21:35:11 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-03-02 21:35:17 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-03-02 21:56:01 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-03-02 22:03:11 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-03-02 22:03:17 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-03-06 12:27:59 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
+2023-03-06 12:28:04 WARNING Connection pool is full, discarding connection: storage.googleapis.com. Connection pool size: 10
