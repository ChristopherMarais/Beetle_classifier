diff --git a/Train/.ipynb_checkpoints/PyLi_wanb_sweep_CoatNet-checkpoint.ipynb b/Train/.ipynb_checkpoints/PyLi_wanb_sweep_CoatNet-checkpoint.ipynb
index b3f7aa6..2adb1c5 100644
--- a/Train/.ipynb_checkpoints/PyLi_wanb_sweep_CoatNet-checkpoint.ipynb
+++ b/Train/.ipynb_checkpoints/PyLi_wanb_sweep_CoatNet-checkpoint.ipynb
@@ -6,11 +6,11 @@
    "id": "c7b471f1-f5fa-4eb1-b9ae-2d67ed8838df",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:21.824252Z",
-     "iopub.status.busy": "2023-03-08T17:10:21.824252Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.893295Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.892300Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:21.824252Z"
+     "iopub.execute_input": "2023-03-08T17:15:40.207524Z",
+     "iopub.status.busy": "2023-03-08T17:15:40.207524Z",
+     "iopub.status.idle": "2023-03-08T17:15:44.676312Z",
+     "shell.execute_reply": "2023-03-08T17:15:44.675307Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:40.207524Z"
     },
     "tags": []
    },
@@ -74,11 +74,11 @@
    "id": "01c28e3c-850d-48b6-8db9-3a8804e0c9ae",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.896303Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.895302Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.924332Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.923339Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.895302Z"
+     "iopub.execute_input": "2023-03-08T17:15:44.678324Z",
+     "iopub.status.busy": "2023-03-08T17:15:44.677308Z",
+     "iopub.status.idle": "2023-03-08T17:15:44.692321Z",
+     "shell.execute_reply": "2023-03-08T17:15:44.691326Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:44.678324Z"
     },
     "tags": []
    },
@@ -141,11 +141,11 @@
    "id": "8b9e722b-cda4-4956-a0c1-8eb31023f765",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.926331Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.926331Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.939867Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.938864Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.926331Z"
+     "iopub.execute_input": "2023-03-08T17:15:44.694320Z",
+     "iopub.status.busy": "2023-03-08T17:15:44.694320Z",
+     "iopub.status.idle": "2023-03-08T17:15:44.708320Z",
+     "shell.execute_reply": "2023-03-08T17:15:44.707323Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:44.694320Z"
     },
     "tags": []
    },
@@ -189,11 +189,11 @@
    "id": "9dbe4b19-9805-40b4-a513-ea35715a0c64",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.940865Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.940865Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.953853Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.953853Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.940865Z"
+     "iopub.execute_input": "2023-03-08T17:15:44.711324Z",
+     "iopub.status.busy": "2023-03-08T17:15:44.710325Z",
+     "iopub.status.idle": "2023-03-08T17:15:44.724319Z",
+     "shell.execute_reply": "2023-03-08T17:15:44.723328Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:44.711324Z"
     },
     "tags": []
    },
@@ -225,11 +225,11 @@
    "id": "7539d3a5-ca4f-4ba3-a462-05875d4b9a90",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.956852Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.955851Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.970854Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.969851Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.956852Z"
+     "iopub.execute_input": "2023-03-08T17:15:44.726325Z",
+     "iopub.status.busy": "2023-03-08T17:15:44.725319Z",
+     "iopub.status.idle": "2023-03-08T17:15:44.740310Z",
+     "shell.execute_reply": "2023-03-08T17:15:44.739312Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:44.726325Z"
     },
     "tags": []
    },
@@ -271,146 +271,17 @@
     "Repalce layers with linear part of other model, then repalce with pretrained model"
    ]
   },
-  {
-   "cell_type": "code",
-   "execution_count": 6,
-   "id": "deb34aed-792a-4022-a878-f8d6c4ffa97c",
-   "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.972851Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.971852Z",
-     "iopub.status.idle": "2023-03-08T17:10:27.000852Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.999851Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.972851Z"
-    },
-    "tags": []
-   },
-   "outputs": [],
-   "source": [
-    "class MyModel(LightningModule):\n",
-    "\n",
-    "    def __init__(self, classes_lst, n_classes=10, acc_task=\"multiclass\", lr=1e-3):\n",
-    "        super().__init__()\n",
-    "        \n",
-    "        \n",
-    "        \"\"\"\n",
-    "        The convolutions are arranged in such a way that the image maintain the x and y dimensions. only the channels change\n",
-    "        \"\"\"\n",
-    "        self.layer_1 = nn.Conv2d(in_channels = 1,out_channels = 3,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "        self.layer_2 = nn.Conv2d(in_channels = 3,out_channels = 6,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "        self.layer_3 = nn.Conv2d(in_channels = 6,out_channels = 12,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "        self.pool = nn.MaxPool2d(kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "        self.layer_5 = nn.Linear(12*50*50,1000)#the input dimensions are (Number of dimensions * height * width)\n",
-    "        self.layer_6 = nn.Linear(1000,100)\n",
-    "        self.layer_7 = nn.Linear(100,50)\n",
-    "        self.layer_8 = nn.Linear(50,10)\n",
-    "        self.layer_9 = nn.Linear(10,10)\n",
-    "        \n",
-    "        \n",
-    "        \n",
-    "        # metrics\n",
-    "        self.acc_task = acc_task\n",
-    "        self.lr = lr\n",
-    "        self.n_classes = n_classes\n",
-    "        self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.n_classes)\n",
-    "        self.class_names = classes_lst\n",
-    "        self.loss = CrossEntropyLoss()\n",
-    "\n",
-    "        # optional - save hyper-parameters to self.hparams\n",
-    "        # they will also be automatically logged as config parameters in W&B\n",
-    "        self.save_hyperparameters()\n",
-    "\n",
-    "    def forward(self,x):\n",
-    "        \"\"\"\n",
-    "        x is the input data\n",
-    "        \"\"\"\n",
-    "        x = self.layer_1(x)\n",
-    "        x = self.pool(x)\n",
-    "        x = self.layer_2(x)\n",
-    "        x = self.pool(x)\n",
-    "        x = self.layer_3(x)\n",
-    "        x = self.pool(x)\n",
-    "        x = x.view(x.size(0),-1)\n",
-    "        print(x.size())\n",
-    "        x = self.layer_5(x)\n",
-    "        x = self.layer_6(x)\n",
-    "        x = self.layer_7(x)\n",
-    "        x = self.layer_8(x)\n",
-    "        x = self.layer_9(x)\n",
-    "        return x\n",
-    "\n",
-    "    def configure_optimizers(self):\n",
-    "        optimizer = torch.optim.Adam(self.parameters(),lr = self.lr)\n",
-    "        return optimizer\n",
-    "\n",
-    "# The Pytorch-Lightning module handles all the iterations of the epoch\n",
-    "\n",
-    "    def training_step(self,batch,batch_idx):\n",
-    "        x,y = batch\n",
-    "        y_pred = self(x)\n",
-    "        loss = F.cross_entropy(y_pred,y)\n",
-    "        # Log training loss\n",
-    "        self.log('train_loss', loss)\n",
-    "        # Log metrics\n",
-    "        self.log('train_acc', self.accuracy(y_pred, y))\n",
-    "        return loss\n",
-    "\n",
-    "    def validation_step(self,batch,batch_idx):\n",
-    "        preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
-    "        # Log loss and metric\n",
-    "        self.log('val_loss_alt', loss)\n",
-    "        self.log('val_accuracy_alt', acc)\n",
-    "        \n",
-    "        x,y = batch\n",
-    "        y_pred = self(x)\n",
-    "        loss = F.cross_entropy(y_pred,y)\n",
-    "        # Log training loss\n",
-    "        self.log('val_loss', loss)\n",
-    "        # Log metrics\n",
-    "        self.log('val_acc', self.accuracy(y_pred, y))\n",
-    "        self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
-    "        self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
-    "        wandb.log({\"val_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
-    "                        y_true=self.cpu_y, preds=None,\n",
-    "                        class_names=self.class_names)})\n",
-    "        return preds\n",
-    "\n",
-    "    def test_step(self,batch,batch_idx):\n",
-    "        x,y = batch\n",
-    "        y_pred = self(x)\n",
-    "        loss = F.cross_entropy(y_pred,y)\n",
-    "        # Log training loss\n",
-    "        self.log('test_loss', loss)\n",
-    "        # Log metrics\n",
-    "        self.log('test_acc', self.accuracy(y_pred, y))\n",
-    "        self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
-    "        self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
-    "        wandb.log({\"test_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
-    "                        y_true=self.cpu_y, preds=None,\n",
-    "                        class_names=self.class_names)})\n",
-    "        return loss\n",
-    "    \n",
-    "    def _get_preds_loss_accuracy(self, batch):\n",
-    "        '''convenience function since train/valid/test steps are similar'''\n",
-    "        x, y = batch\n",
-    "        logits = self(x)\n",
-    "        preds = torch.argmax(logits, dim=1)\n",
-    "        loss = self.loss(logits, y)\n",
-    "        acc = accuracy(preds, y, self.acc_task, num_classes=10)\n",
-    "        return preds, loss, acc"
-   ]
-  },
   {
    "cell_type": "code",
    "execution_count": 7,
    "id": "1816bdd2-4846-4dee-a595-190697564b38",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:27.002857Z",
-     "iopub.status.busy": "2023-03-08T17:10:27.001851Z",
-     "iopub.status.idle": "2023-03-08T17:10:27.032396Z",
-     "shell.execute_reply": "2023-03-08T17:10:27.031390Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:27.002857Z"
+     "iopub.execute_input": "2023-03-08T17:15:44.757892Z",
+     "iopub.status.busy": "2023-03-08T17:15:44.757892Z",
+     "iopub.status.idle": "2023-03-08T17:15:44.787873Z",
+     "shell.execute_reply": "2023-03-08T17:15:44.786862Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:44.757892Z"
     },
     "tags": []
    },
@@ -418,14 +289,14 @@
    "source": [
     "class MyModel(LightningModule):\n",
     "\n",
-    "    def __init__(self, classes_lst, input_shape=(1,224,224), n_classes=10, acc_task=\"multiclass\", lr=1e-3, transfer=False): #input_shape=(3,224,224) image shape\n",
+    "    def __init__(self, classes_lst, input_shape=(1,224,224), num_classes=10, acc_task=\"multiclass\", lr=1e-3, transfer=False): #input_shape=(3,224,224) image shape\n",
     "        super().__init__()\n",
     "        \n",
     "        # metrics\n",
     "        self.acc_task = acc_task\n",
     "        self.lr = lr\n",
-    "        self.n_classes = n_classes\n",
-    "        self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.n_classes)\n",
+    "        self.num_classes = num_classes\n",
+    "        self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.num_classes)\n",
     "        self.class_names = classes_lst\n",
     "        self.loss = CrossEntropyLoss()\n",
     "        \n",
@@ -528,118 +399,6 @@
     "        return preds, loss, acc"
    ]
   },
-  {
-   "cell_type": "code",
-   "execution_count": 8,
-   "id": "f87009dd-3c3a-409c-ada8-3f991d17d0c1",
-   "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:27.034398Z",
-     "iopub.status.busy": "2023-03-08T17:10:27.033399Z",
-     "iopub.status.idle": "2023-03-08T17:10:27.049387Z",
-     "shell.execute_reply": "2023-03-08T17:10:27.047400Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:27.034398Z"
-    }
-   },
-   "outputs": [],
-   "source": [
-    "# class MyModel(pl.LightningModule):\n",
-    "#     def __init__(self, input_shape, n_classes=10, lr=2e-4, transfer=False):\n",
-    "#         super().__init__()\n",
-    "        \n",
-    "#         # log hyperparameters\n",
-    "#         self.save_hyperparameters()\n",
-    "#         self.learning_rate = lr\n",
-    "#         self.dim = input_shape\n",
-    "#         self.num_classes = num_classes\n",
-    "        \n",
-    "#         # transfer learning if pretrained=True\n",
-    "#         self.feature_extractor = models.resnet18(pretrained=transfer)\n",
-    "\n",
-    "#         if transfer:\n",
-    "#             # layers are frozen by using eval()\n",
-    "#             self.feature_extractor.eval()\n",
-    "#             # freeze params\n",
-    "#             for param in self.feature_extractor.parameters():\n",
-    "#                 param.requires_grad = False\n",
-    "        \n",
-    "#         n_sizes = self._get_conv_output(input_shape)\n",
-    "\n",
-    "#         self.classifier = nn.Linear(n_sizes, num_classes)\n",
-    "\n",
-    "#         self.criterion = nn.CrossEntropyLoss()\n",
-    "#         self.accuracy = Accuracy()\n",
-    "  \n",
-    "#     # returns the size of the output tensor going into the Linear layer from the conv block.\n",
-    "#     def _get_conv_output(self, shape):\n",
-    "#         batch_size = 1\n",
-    "#         tmp_input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
-    "\n",
-    "#         output_feat = self._forward_features(tmp_input) \n",
-    "#         n_size = output_feat.data.view(batch_size, -1).size(1)\n",
-    "#         return n_size\n",
-    "        \n",
-    "#     # returns the feature tensor from the conv block\n",
-    "#     def _forward_features(self, x):\n",
-    "#         x = self.feature_extractor(x)\n",
-    "#         return x\n",
-    "    \n",
-    "#     # will be used during inference\n",
-    "#     def forward(self, x):\n",
-    "#         x = self._forward_features(x)\n",
-    "#         x = x.view(x.size(0), -1)\n",
-    "#         x = self.classifier(x)\n",
-    "\n",
-    "#         return x\n",
-    "    \n",
-    "#     def training_step(self, batch):\n",
-    "#         batch, gt = batch[0], batch[1]\n",
-    "#         out = self.forward(batch)\n",
-    "#         loss = self.criterion(out, gt)\n",
-    "\n",
-    "#         acc = self.accuracy(out, gt)\n",
-    "\n",
-    "#         self.log(\"train/loss\", loss)\n",
-    "#         self.log(\"train/acc\", acc)\n",
-    "\n",
-    "#         return loss\n",
-    "    \n",
-    "#     def validation_step(self, batch, batch_idx):\n",
-    "#         batch, gt = batch[0], batch[1]\n",
-    "#         out = self.forward(batch)\n",
-    "#         loss = self.criterion(out, gt)\n",
-    "\n",
-    "#         self.log(\"val/loss\", loss)\n",
-    "\n",
-    "#         acc = self.accuracy(out, gt)\n",
-    "#         self.log(\"val/acc\", acc)\n",
-    "\n",
-    "#         return loss\n",
-    "    \n",
-    "#     def test_step(self, batch, batch_idx):\n",
-    "#         batch, gt = batch[0], batch[1]\n",
-    "#         out = self.forward(batch)\n",
-    "#         loss = self.criterion(out, gt)\n",
-    "        \n",
-    "#         return {\"loss\": loss, \"outputs\": out, \"gt\": gt}\n",
-    "    \n",
-    "#     def test_epoch_end(self, outputs):\n",
-    "#         loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
-    "#         output = torch.cat([x['outputs'] for x in outputs], dim=0)\n",
-    "        \n",
-    "#         gts = torch.cat([x['gt'] for x in outputs], dim=0)\n",
-    "        \n",
-    "#         self.log(\"test/loss\", loss)\n",
-    "#         acc = self.accuracy(output, gts)\n",
-    "#         self.log(\"test/acc\", acc)\n",
-    "        \n",
-    "#         self.test_gts = gts\n",
-    "#         self.test_output = output\n",
-    "    \n",
-    "#     def configure_optimizers(self):\n",
-    "#         return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
-   ]
-  },
   {
    "cell_type": "markdown",
    "id": "f561a2e3-1272-4e67-9322-dd9b7534fed3",
@@ -654,11 +413,11 @@
    "id": "188ce4ef-e6b7-4320-8e5d-ceeb616bf7d1",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:27.051399Z",
-     "iopub.status.busy": "2023-03-08T17:10:27.050393Z",
-     "iopub.status.idle": "2023-03-08T17:10:27.063388Z",
-     "shell.execute_reply": "2023-03-08T17:10:27.062386Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:27.051399Z"
+     "iopub.execute_input": "2023-03-08T17:15:44.805869Z",
+     "iopub.status.busy": "2023-03-08T17:15:44.805869Z",
+     "iopub.status.idle": "2023-03-08T17:15:44.818878Z",
+     "shell.execute_reply": "2023-03-08T17:15:44.817859Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:44.805869Z"
     },
     "tags": []
    },
@@ -699,11 +458,11 @@
    "id": "762279ca-26d9-4310-992f-b6f8912da7fe",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:27.065390Z",
-     "iopub.status.busy": "2023-03-08T17:10:27.064390Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.633996Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.631459Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:27.065390Z"
+     "iopub.execute_input": "2023-03-08T17:15:44.820879Z",
+     "iopub.status.busy": "2023-03-08T17:15:44.820879Z",
+     "iopub.status.idle": "2023-03-08T17:15:51.639994Z",
+     "shell.execute_reply": "2023-03-08T17:15:51.638991Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:44.820879Z"
     },
     "tags": []
    },
@@ -715,6 +474,20 @@
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristopher-marais\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
      ]
     },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "d9b7c391f6c64ea391c29b2a946763d5",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0â€¦"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
     {
      "data": {
       "text/html": [
@@ -743,7 +516,7 @@
     {
      "data": {
       "text/html": [
-       "Run data is saved locally in <code>.\\wandb\\run-20230308_121030-fq5x8q4o</code>"
+       "Run data is saved locally in <code>.\\wandb\\run-20230308_121547-ccerfkmr</code>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -755,7 +528,7 @@
     {
      "data": {
       "text/html": [
-       "Syncing run <strong><a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/fq5x8q4o' target=\"_blank\">fallen-shadow-43</a></strong> to <a href='https://wandb.ai/christopher-marais/computer_vision_test_single' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
+       "Syncing run <strong><a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/ccerfkmr' target=\"_blank\">wild-salad-47</a></strong> to <a href='https://wandb.ai/christopher-marais/computer_vision_test_single' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -779,7 +552,7 @@
     {
      "data": {
       "text/html": [
-       " View run at <a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/fq5x8q4o' target=\"_blank\">https://wandb.ai/christopher-marais/computer_vision_test_single/runs/fq5x8q4o</a>"
+       " View run at <a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/ccerfkmr' target=\"_blank\">https://wandb.ai/christopher-marais/computer_vision_test_single/runs/ccerfkmr</a>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -789,15 +562,17 @@
      "output_type": "display_data"
     },
     {
-     "ename": "NameError",
-     "evalue": "name 'models' is not defined",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
-      "Cell \u001b[1;32mIn[10], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m DataModule()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# setup model - choose different hyperparameters per experiment\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMyModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclasses_lst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses_lst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_of_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     14\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     15\u001b[0m     devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;66;03m# use all GPU's (-1)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m            \u001b[38;5;66;03m# number of epochs\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     )\n",
-      "Cell \u001b[1;32mIn[7], line 15\u001b[0m, in \u001b[0;36mMyModel.__init__\u001b[1;34m(self, classes_lst, input_shape, n_classes, acc_task, lr, transfer)\u001b[0m\n\u001b[0;32m     12\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# transfer learning if pretrained=True\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241m.\u001b[39mresnet18(pretrained\u001b[38;5;241m=\u001b[39mtransfer)\n\u001b[0;32m     17\u001b[0m  \u001b[38;5;28;01mif\u001b[39;00m transfer:\n\u001b[0;32m     18\u001b[0m      \u001b[38;5;66;03m# layers are frozen by using eval()\u001b[39;00m\n\u001b[0;32m     19\u001b[0m      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor\u001b[38;5;241m.\u001b[39meval()\n",
-      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "C:\\Users\\gcmar\\.conda\\envs\\BC_310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
+      "  warnings.warn(\n",
+      "C:\\Users\\gcmar\\.conda\\envs\\BC_310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
+      "  warnings.warn(msg)\n",
+      "GPU available: True (cuda), used: True\n",
+      "TPU available: False, using: 0 TPU cores\n",
+      "IPU available: False, using: 0 IPUs\n",
+      "HPU available: False, using: 0 HPUs\n"
      ]
     }
    ],
@@ -811,7 +586,7 @@
     "data = DataModule()\n",
     "\n",
     "# setup model - choose different hyperparameters per experiment\n",
-    "model = MyModel(classes_lst=classes_lst, n_classes=num_of_classes, input_shape=(3,224,224))\n",
+    "model = MyModel(classes_lst=classes_lst, num_classes=num_of_classes, input_shape=(3,224,224))\n",
     "\n",
     "\n",
     "trainer = Trainer(\n",
@@ -825,17 +600,98 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 11,
    "id": "05c5995d-f9be-4377-bfc0-ea1298711b12",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.635025Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.636024Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.635025Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.635025Z"
+     "iopub.execute_input": "2023-03-08T17:15:51.642994Z",
+     "iopub.status.busy": "2023-03-08T17:15:51.641997Z",
+     "iopub.status.idle": "2023-03-08T17:15:54.800696Z",
+     "shell.execute_reply": "2023-03-08T17:15:54.797716Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:51.642994Z"
     }
    },
-   "outputs": [],
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
+      "\n",
+      "  | Name              | Type               | Params\n",
+      "---------------------------------------------------------\n",
+      "0 | accuracy          | MulticlassAccuracy | 0     \n",
+      "1 | loss              | CrossEntropyLoss   | 0     \n",
+      "2 | feature_extractor | ResNet             | 11.7 M\n",
+      "3 | classifier        | Linear             | 10.0 K\n",
+      "---------------------------------------------------------\n",
+      "11.7 M    Trainable params\n",
+      "0         Non-trainable params\n",
+      "11.7 M    Total params\n",
+      "46.798    Total estimated model params size (MB)\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "deeadcfa05e34e28a0039a29f5117cb7",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "Sanity Checking: 0it [00:00, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "C:\\Users\\gcmar\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
+      "  rank_zero_warn(\n",
+      "C:\\Users\\gcmar\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
+      "  rank_zero_warn(\n"
+     ]
+    },
+    {
+     "ename": "RuntimeError",
+     "evalue": "Given groups=1, weight of size [64, 3, 7, 7], expected input[10, 1, 50, 50] to have 3 channels, but got 1 channels instead",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
+      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    606\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m--> 608\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     41\u001b[0m     trainer\u001b[38;5;241m.\u001b[39m_call_teardown_hook()\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    643\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_set_ckpt_path(\n\u001b[0;32m    645\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    646\u001b[0m     ckpt_path,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    647\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    648\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    649\u001b[0m )\n\u001b[1;32m--> 650\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1112\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[1;32m-> 1112\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1114\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1191\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[0;32m   1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1204\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_training_routine()\n\u001b[0;32m   1203\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;66;03m# enable train mode\u001b[39;00m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1276\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m-> 1276\u001b[0m     \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\dataloader\\evaluation_loop.py:152\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_dataloaders \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    151\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dataloader_idx\n\u001b[1;32m--> 152\u001b[0m dl_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_max_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# store batch level output per dataloader\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs\u001b[38;5;241m.\u001b[39mappend(dl_outputs)\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:137\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[1;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# lightning module methods\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step_end(output)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:234\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The evaluation step (validation_step or test_step depending on the trainer's state).\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124;03m    the outputs of the step\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    233\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 234\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1494\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1494\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:390\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mval_step_context():\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, ValidationStep)\n\u001b[1;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mvalidation_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
+      "Cell \u001b[1;32mIn[7], line 69\u001b[0m, in \u001b[0;36mMyModel.validation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m,batch,batch_idx):\n\u001b[1;32m---> 69\u001b[0m     preds, loss, acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_preds_loss_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# Log loss and metric\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss_alt\u001b[39m\u001b[38;5;124m'\u001b[39m, loss)\n",
+      "Cell \u001b[1;32mIn[7], line 106\u001b[0m, in \u001b[0;36mMyModel._get_preds_loss_accuracy\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''convenience function since train/valid/test steps are similar'''\u001b[39;00m\n\u001b[0;32m    105\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m--> 106\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    108\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(logits, y)\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
+      "Cell \u001b[1;32mIn[7], line 46\u001b[0m, in \u001b[0;36mMyModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 46\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     48\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(x)\n",
+      "Cell \u001b[1;32mIn[7], line 40\u001b[0m, in \u001b[0;36mMyModel._forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 40\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\torchvision\\models\\resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[0;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
+      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 7, 7], expected input[10, 1, 50, 50] to have 3 channels, but got 1 channels instead"
+     ]
+    }
+   ],
    "source": [
     "trainer.fit(model, data)"
    ]
@@ -846,10 +702,10 @@
    "id": "28625e66-e2a3-4a91-acce-e2948485412b",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.637021Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.638026Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.637021Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.637021Z"
+     "iopub.status.busy": "2023-03-08T17:15:54.801695Z",
+     "iopub.status.idle": "2023-03-08T17:15:54.802697Z",
+     "shell.execute_reply": "2023-03-08T17:15:54.801695Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:54.801695Z"
     }
    },
    "outputs": [],
@@ -863,10 +719,10 @@
    "id": "378d95e1-4e29-4c7f-bd8c-eaa16677a063",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.639013Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.639013Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.639013Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.639013Z"
+     "iopub.status.busy": "2023-03-08T17:15:54.803697Z",
+     "iopub.status.idle": "2023-03-08T17:15:54.804705Z",
+     "shell.execute_reply": "2023-03-08T17:15:54.804705Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:54.804705Z"
     },
     "tags": []
    },
@@ -881,10 +737,10 @@
    "id": "91967e96-f127-4758-b427-c996a9fcb4dc",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.641013Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.642013Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.642013Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.642013Z"
+     "iopub.status.busy": "2023-03-08T17:15:54.806694Z",
+     "iopub.status.idle": "2023-03-08T17:15:54.807694Z",
+     "shell.execute_reply": "2023-03-08T17:15:54.807694Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:54.807694Z"
     }
    },
    "outputs": [],
@@ -898,7 +754,11 @@
    "id": "f04c136e-5986-4628-88b7-38a8b433f654",
    "metadata": {},
    "outputs": [],
-   "source": []
+   "source": [
+    "data = train_iterator.dataset.data \n",
+    "shape = train_iterator.dataset.data.shape  \n",
+    "datatype = train_iterator.dataset.data.dtype"
+   ]
   },
   {
    "cell_type": "code",
@@ -906,10 +766,10 @@
    "id": "3b58022d-6961-41b0-a4e1-60bbc1c09791",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.643011Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.644008Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.644008Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.644008Z"
+     "iopub.status.busy": "2023-03-08T17:15:54.809701Z",
+     "iopub.status.idle": "2023-03-08T17:15:54.809701Z",
+     "shell.execute_reply": "2023-03-08T17:15:54.809701Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:54.809701Z"
     },
     "tags": []
    },
@@ -932,10 +792,10 @@
    "id": "ebde1018-ddfa-43f2-b9c6-f2c1d4b19736",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.645011Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.646017Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.646017Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.646017Z"
+     "iopub.status.busy": "2023-03-08T17:15:54.811693Z",
+     "iopub.status.idle": "2023-03-08T17:15:54.811693Z",
+     "shell.execute_reply": "2023-03-08T17:15:54.811693Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:54.811693Z"
     },
     "tags": []
    },
@@ -978,10 +838,10 @@
    "id": "91aeb8a0-9ffd-4439-808c-2951d1f74b36",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.648016Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.649014Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.649014Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.649014Z"
+     "iopub.status.busy": "2023-03-08T17:15:54.814696Z",
+     "iopub.status.idle": "2023-03-08T17:15:54.815699Z",
+     "shell.execute_reply": "2023-03-08T17:15:54.815699Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:54.815699Z"
     },
     "tags": []
    },
@@ -1002,7 +862,7 @@
     "    #     n_layer_2=wandb.config.n_layer_2,\n",
     "    #     lr=wandb.config.lr\n",
     "    # )\n",
-    "    model = MyModel(lr=wandb.config.lr, n_classes=num_of_classes)\n",
+    "    model = MyModel(lr=wandb.config.lr, num_classes=num_of_classes)\n",
     "\n",
     "    # setup Trainer\n",
     "    trainer = Trainer(\n",
@@ -1021,10 +881,10 @@
    "id": "869b0393-21cf-4fba-8efd-7678a852b697",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.650013Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.651012Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.651012Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.651012Z"
+     "iopub.status.busy": "2023-03-08T17:15:54.816693Z",
+     "iopub.status.idle": "2023-03-08T17:15:54.817694Z",
+     "shell.execute_reply": "2023-03-08T17:15:54.816693Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:54.816693Z"
     },
     "tags": []
    },
@@ -1041,6 +901,248 @@
    "metadata": {},
    "outputs": [],
    "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 8,
+   "id": "f87009dd-3c3a-409c-ada8-3f991d17d0c1",
+   "metadata": {
+    "execution": {
+     "iopub.execute_input": "2023-03-08T17:15:44.788860Z",
+     "iopub.status.busy": "2023-03-08T17:15:44.788860Z",
+     "iopub.status.idle": "2023-03-08T17:15:44.803868Z",
+     "shell.execute_reply": "2023-03-08T17:15:44.802865Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:44.788860Z"
+    },
+    "tags": []
+   },
+   "outputs": [],
+   "source": [
+    "# class MyModel(pl.LightningModule):\n",
+    "#     def __init__(self, input_shape, num_classes=10, lr=2e-4, transfer=False):\n",
+    "#         super().__init__()\n",
+    "        \n",
+    "#         # log hyperparameters\n",
+    "#         self.save_hyperparameters()\n",
+    "#         self.learning_rate = lr\n",
+    "#         self.dim = input_shape\n",
+    "#         self.num_classes = num_classes\n",
+    "        \n",
+    "#         # transfer learning if pretrained=True\n",
+    "#         self.feature_extractor = models.resnet18(pretrained=transfer)\n",
+    "\n",
+    "#         if transfer:\n",
+    "#             # layers are frozen by using eval()\n",
+    "#             self.feature_extractor.eval()\n",
+    "#             # freeze params\n",
+    "#             for param in self.feature_extractor.parameters():\n",
+    "#                 param.requires_grad = False\n",
+    "        \n",
+    "#         n_sizes = self._get_conv_output(input_shape)\n",
+    "\n",
+    "#         self.classifier = nn.Linear(n_sizes, num_classes)\n",
+    "\n",
+    "#         self.criterion = nn.CrossEntropyLoss()\n",
+    "#         self.accuracy = Accuracy()\n",
+    "  \n",
+    "#     # returns the size of the output tensor going into the Linear layer from the conv block.\n",
+    "#     def _get_conv_output(self, shape):\n",
+    "#         batch_size = 1\n",
+    "#         tmp_input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
+    "\n",
+    "#         output_feat = self._forward_features(tmp_input) \n",
+    "#         n_size = output_feat.data.view(batch_size, -1).size(1)\n",
+    "#         return n_size\n",
+    "        \n",
+    "#     # returns the feature tensor from the conv block\n",
+    "#     def _forward_features(self, x):\n",
+    "#         x = self.feature_extractor(x)\n",
+    "#         return x\n",
+    "    \n",
+    "#     # will be used during inference\n",
+    "#     def forward(self, x):\n",
+    "#         x = self._forward_features(x)\n",
+    "#         x = x.view(x.size(0), -1)\n",
+    "#         x = self.classifier(x)\n",
+    "\n",
+    "#         return x\n",
+    "    \n",
+    "#     def training_step(self, batch):\n",
+    "#         batch, gt = batch[0], batch[1]\n",
+    "#         out = self.forward(batch)\n",
+    "#         loss = self.criterion(out, gt)\n",
+    "\n",
+    "#         acc = self.accuracy(out, gt)\n",
+    "\n",
+    "#         self.log(\"train/loss\", loss)\n",
+    "#         self.log(\"train/acc\", acc)\n",
+    "\n",
+    "#         return loss\n",
+    "    \n",
+    "#     def validation_step(self, batch, batch_idx):\n",
+    "#         batch, gt = batch[0], batch[1]\n",
+    "#         out = self.forward(batch)\n",
+    "#         loss = self.criterion(out, gt)\n",
+    "\n",
+    "#         self.log(\"val/loss\", loss)\n",
+    "\n",
+    "#         acc = self.accuracy(out, gt)\n",
+    "#         self.log(\"val/acc\", acc)\n",
+    "\n",
+    "#         return loss\n",
+    "    \n",
+    "#     def test_step(self, batch, batch_idx):\n",
+    "#         batch, gt = batch[0], batch[1]\n",
+    "#         out = self.forward(batch)\n",
+    "#         loss = self.criterion(out, gt)\n",
+    "        \n",
+    "#         return {\"loss\": loss, \"outputs\": out, \"gt\": gt}\n",
+    "    \n",
+    "#     def test_epoch_end(self, outputs):\n",
+    "#         loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
+    "#         output = torch.cat([x['outputs'] for x in outputs], dim=0)\n",
+    "        \n",
+    "#         gts = torch.cat([x['gt'] for x in outputs], dim=0)\n",
+    "        \n",
+    "#         self.log(\"test/loss\", loss)\n",
+    "#         acc = self.accuracy(output, gts)\n",
+    "#         self.log(\"test/acc\", acc)\n",
+    "        \n",
+    "#         self.test_gts = gts\n",
+    "#         self.test_output = output\n",
+    "    \n",
+    "#     def configure_optimizers(self):\n",
+    "#         return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 6,
+   "id": "deb34aed-792a-4022-a878-f8d6c4ffa97c",
+   "metadata": {
+    "execution": {
+     "iopub.execute_input": "2023-03-08T17:15:44.743323Z",
+     "iopub.status.busy": "2023-03-08T17:15:44.742328Z",
+     "iopub.status.idle": "2023-03-08T17:15:44.755852Z",
+     "shell.execute_reply": "2023-03-08T17:15:44.755331Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:44.743323Z"
+    },
+    "tags": []
+   },
+   "outputs": [],
+   "source": [
+    "# class MyModel(LightningModule):\n",
+    "\n",
+    "#     def __init__(self, classes_lst, num_classes=10, acc_task=\"multiclass\", lr=1e-3):\n",
+    "#         super().__init__()\n",
+    "        \n",
+    "        \n",
+    "#         \"\"\"\n",
+    "#         The convolutions are arranged in such a way that the image maintain the x and y dimensions. only the channels change\n",
+    "#         \"\"\"\n",
+    "#         self.layer_1 = nn.Conv2d(in_channels = 1,out_channels = 3,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "#         self.layer_2 = nn.Conv2d(in_channels = 3,out_channels = 6,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "#         self.layer_3 = nn.Conv2d(in_channels = 6,out_channels = 12,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "#         self.pool = nn.MaxPool2d(kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "#         self.layer_5 = nn.Linear(12*50*50,1000)#the input dimensions are (Number of dimensions * height * width)\n",
+    "#         self.layer_6 = nn.Linear(1000,100)\n",
+    "#         self.layer_7 = nn.Linear(100,50)\n",
+    "#         self.layer_8 = nn.Linear(50,10)\n",
+    "#         self.layer_9 = nn.Linear(10,10)\n",
+    "        \n",
+    "        \n",
+    "        \n",
+    "#         # metrics\n",
+    "#         self.acc_task = acc_task\n",
+    "#         self.lr = lr\n",
+    "#         self.num_classes = num_classes\n",
+    "#         self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.num_classes)\n",
+    "#         self.class_names = classes_lst\n",
+    "#         self.loss = CrossEntropyLoss()\n",
+    "\n",
+    "#         # optional - save hyper-parameters to self.hparams\n",
+    "#         # they will also be automatically logged as config parameters in W&B\n",
+    "#         self.save_hyperparameters()\n",
+    "\n",
+    "#     def forward(self,x):\n",
+    "#         \"\"\"\n",
+    "#         x is the input data\n",
+    "#         \"\"\"\n",
+    "#         x = self.layer_1(x)\n",
+    "#         x = self.pool(x)\n",
+    "#         x = self.layer_2(x)\n",
+    "#         x = self.pool(x)\n",
+    "#         x = self.layer_3(x)\n",
+    "#         x = self.pool(x)\n",
+    "#         x = x.view(x.size(0),-1)\n",
+    "#         print(x.size())\n",
+    "#         x = self.layer_5(x)\n",
+    "#         x = self.layer_6(x)\n",
+    "#         x = self.layer_7(x)\n",
+    "#         x = self.layer_8(x)\n",
+    "#         x = self.layer_9(x)\n",
+    "#         return x\n",
+    "\n",
+    "#     def configure_optimizers(self):\n",
+    "#         optimizer = torch.optim.Adam(self.parameters(),lr = self.lr)\n",
+    "#         return optimizer\n",
+    "\n",
+    "# # The Pytorch-Lightning module handles all the iterations of the epoch\n",
+    "\n",
+    "#     def training_step(self,batch,batch_idx):\n",
+    "#         x,y = batch\n",
+    "#         y_pred = self(x)\n",
+    "#         loss = F.cross_entropy(y_pred,y)\n",
+    "#         # Log training loss\n",
+    "#         self.log('train_loss', loss)\n",
+    "#         # Log metrics\n",
+    "#         self.log('train_acc', self.accuracy(y_pred, y))\n",
+    "#         return loss\n",
+    "\n",
+    "#     def validation_step(self,batch,batch_idx):\n",
+    "#         preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
+    "#         # Log loss and metric\n",
+    "#         self.log('val_loss_alt', loss)\n",
+    "#         self.log('val_accuracy_alt', acc)\n",
+    "        \n",
+    "#         x,y = batch\n",
+    "#         y_pred = self(x)\n",
+    "#         loss = F.cross_entropy(y_pred,y)\n",
+    "#         # Log training loss\n",
+    "#         self.log('val_loss', loss)\n",
+    "#         # Log metrics\n",
+    "#         self.log('val_acc', self.accuracy(y_pred, y))\n",
+    "#         self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
+    "#         self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
+    "#         wandb.log({\"val_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
+    "#                         y_true=self.cpu_y, preds=None,\n",
+    "#                         class_names=self.class_names)})\n",
+    "#         return preds\n",
+    "\n",
+    "#     def test_step(self,batch,batch_idx):\n",
+    "#         x,y = batch\n",
+    "#         y_pred = self(x)\n",
+    "#         loss = F.cross_entropy(y_pred,y)\n",
+    "#         # Log training loss\n",
+    "#         self.log('test_loss', loss)\n",
+    "#         # Log metrics\n",
+    "#         self.log('test_acc', self.accuracy(y_pred, y))\n",
+    "#         self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
+    "#         self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
+    "#         wandb.log({\"test_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
+    "#                         y_true=self.cpu_y, preds=None,\n",
+    "#                         class_names=self.class_names)})\n",
+    "#         return loss\n",
+    "    \n",
+    "#     def _get_preds_loss_accuracy(self, batch):\n",
+    "#         '''convenience function since train/valid/test steps are similar'''\n",
+    "#         x, y = batch\n",
+    "#         logits = self(x)\n",
+    "#         preds = torch.argmax(logits, dim=1)\n",
+    "#         loss = self.loss(logits, y)\n",
+    "#         acc = accuracy(preds, y, self.acc_task, num_classes=10)\n",
+    "#         return preds, loss, acc"
+   ]
   }
  ],
  "metadata": {
diff --git a/Train/PyLi_wanb_sweep_CoatNet.ipynb b/Train/PyLi_wanb_sweep_CoatNet.ipynb
index b3f7aa6..2adb1c5 100644
--- a/Train/PyLi_wanb_sweep_CoatNet.ipynb
+++ b/Train/PyLi_wanb_sweep_CoatNet.ipynb
@@ -6,11 +6,11 @@
    "id": "c7b471f1-f5fa-4eb1-b9ae-2d67ed8838df",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:21.824252Z",
-     "iopub.status.busy": "2023-03-08T17:10:21.824252Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.893295Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.892300Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:21.824252Z"
+     "iopub.execute_input": "2023-03-08T17:15:40.207524Z",
+     "iopub.status.busy": "2023-03-08T17:15:40.207524Z",
+     "iopub.status.idle": "2023-03-08T17:15:44.676312Z",
+     "shell.execute_reply": "2023-03-08T17:15:44.675307Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:40.207524Z"
     },
     "tags": []
    },
@@ -74,11 +74,11 @@
    "id": "01c28e3c-850d-48b6-8db9-3a8804e0c9ae",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.896303Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.895302Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.924332Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.923339Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.895302Z"
+     "iopub.execute_input": "2023-03-08T17:15:44.678324Z",
+     "iopub.status.busy": "2023-03-08T17:15:44.677308Z",
+     "iopub.status.idle": "2023-03-08T17:15:44.692321Z",
+     "shell.execute_reply": "2023-03-08T17:15:44.691326Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:44.678324Z"
     },
     "tags": []
    },
@@ -141,11 +141,11 @@
    "id": "8b9e722b-cda4-4956-a0c1-8eb31023f765",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.926331Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.926331Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.939867Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.938864Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.926331Z"
+     "iopub.execute_input": "2023-03-08T17:15:44.694320Z",
+     "iopub.status.busy": "2023-03-08T17:15:44.694320Z",
+     "iopub.status.idle": "2023-03-08T17:15:44.708320Z",
+     "shell.execute_reply": "2023-03-08T17:15:44.707323Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:44.694320Z"
     },
     "tags": []
    },
@@ -189,11 +189,11 @@
    "id": "9dbe4b19-9805-40b4-a513-ea35715a0c64",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.940865Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.940865Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.953853Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.953853Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.940865Z"
+     "iopub.execute_input": "2023-03-08T17:15:44.711324Z",
+     "iopub.status.busy": "2023-03-08T17:15:44.710325Z",
+     "iopub.status.idle": "2023-03-08T17:15:44.724319Z",
+     "shell.execute_reply": "2023-03-08T17:15:44.723328Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:44.711324Z"
     },
     "tags": []
    },
@@ -225,11 +225,11 @@
    "id": "7539d3a5-ca4f-4ba3-a462-05875d4b9a90",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.956852Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.955851Z",
-     "iopub.status.idle": "2023-03-08T17:10:26.970854Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.969851Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.956852Z"
+     "iopub.execute_input": "2023-03-08T17:15:44.726325Z",
+     "iopub.status.busy": "2023-03-08T17:15:44.725319Z",
+     "iopub.status.idle": "2023-03-08T17:15:44.740310Z",
+     "shell.execute_reply": "2023-03-08T17:15:44.739312Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:44.726325Z"
     },
     "tags": []
    },
@@ -271,146 +271,17 @@
     "Repalce layers with linear part of other model, then repalce with pretrained model"
    ]
   },
-  {
-   "cell_type": "code",
-   "execution_count": 6,
-   "id": "deb34aed-792a-4022-a878-f8d6c4ffa97c",
-   "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:26.972851Z",
-     "iopub.status.busy": "2023-03-08T17:10:26.971852Z",
-     "iopub.status.idle": "2023-03-08T17:10:27.000852Z",
-     "shell.execute_reply": "2023-03-08T17:10:26.999851Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:26.972851Z"
-    },
-    "tags": []
-   },
-   "outputs": [],
-   "source": [
-    "class MyModel(LightningModule):\n",
-    "\n",
-    "    def __init__(self, classes_lst, n_classes=10, acc_task=\"multiclass\", lr=1e-3):\n",
-    "        super().__init__()\n",
-    "        \n",
-    "        \n",
-    "        \"\"\"\n",
-    "        The convolutions are arranged in such a way that the image maintain the x and y dimensions. only the channels change\n",
-    "        \"\"\"\n",
-    "        self.layer_1 = nn.Conv2d(in_channels = 1,out_channels = 3,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "        self.layer_2 = nn.Conv2d(in_channels = 3,out_channels = 6,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "        self.layer_3 = nn.Conv2d(in_channels = 6,out_channels = 12,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "        self.pool = nn.MaxPool2d(kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
-    "        self.layer_5 = nn.Linear(12*50*50,1000)#the input dimensions are (Number of dimensions * height * width)\n",
-    "        self.layer_6 = nn.Linear(1000,100)\n",
-    "        self.layer_7 = nn.Linear(100,50)\n",
-    "        self.layer_8 = nn.Linear(50,10)\n",
-    "        self.layer_9 = nn.Linear(10,10)\n",
-    "        \n",
-    "        \n",
-    "        \n",
-    "        # metrics\n",
-    "        self.acc_task = acc_task\n",
-    "        self.lr = lr\n",
-    "        self.n_classes = n_classes\n",
-    "        self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.n_classes)\n",
-    "        self.class_names = classes_lst\n",
-    "        self.loss = CrossEntropyLoss()\n",
-    "\n",
-    "        # optional - save hyper-parameters to self.hparams\n",
-    "        # they will also be automatically logged as config parameters in W&B\n",
-    "        self.save_hyperparameters()\n",
-    "\n",
-    "    def forward(self,x):\n",
-    "        \"\"\"\n",
-    "        x is the input data\n",
-    "        \"\"\"\n",
-    "        x = self.layer_1(x)\n",
-    "        x = self.pool(x)\n",
-    "        x = self.layer_2(x)\n",
-    "        x = self.pool(x)\n",
-    "        x = self.layer_3(x)\n",
-    "        x = self.pool(x)\n",
-    "        x = x.view(x.size(0),-1)\n",
-    "        print(x.size())\n",
-    "        x = self.layer_5(x)\n",
-    "        x = self.layer_6(x)\n",
-    "        x = self.layer_7(x)\n",
-    "        x = self.layer_8(x)\n",
-    "        x = self.layer_9(x)\n",
-    "        return x\n",
-    "\n",
-    "    def configure_optimizers(self):\n",
-    "        optimizer = torch.optim.Adam(self.parameters(),lr = self.lr)\n",
-    "        return optimizer\n",
-    "\n",
-    "# The Pytorch-Lightning module handles all the iterations of the epoch\n",
-    "\n",
-    "    def training_step(self,batch,batch_idx):\n",
-    "        x,y = batch\n",
-    "        y_pred = self(x)\n",
-    "        loss = F.cross_entropy(y_pred,y)\n",
-    "        # Log training loss\n",
-    "        self.log('train_loss', loss)\n",
-    "        # Log metrics\n",
-    "        self.log('train_acc', self.accuracy(y_pred, y))\n",
-    "        return loss\n",
-    "\n",
-    "    def validation_step(self,batch,batch_idx):\n",
-    "        preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
-    "        # Log loss and metric\n",
-    "        self.log('val_loss_alt', loss)\n",
-    "        self.log('val_accuracy_alt', acc)\n",
-    "        \n",
-    "        x,y = batch\n",
-    "        y_pred = self(x)\n",
-    "        loss = F.cross_entropy(y_pred,y)\n",
-    "        # Log training loss\n",
-    "        self.log('val_loss', loss)\n",
-    "        # Log metrics\n",
-    "        self.log('val_acc', self.accuracy(y_pred, y))\n",
-    "        self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
-    "        self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
-    "        wandb.log({\"val_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
-    "                        y_true=self.cpu_y, preds=None,\n",
-    "                        class_names=self.class_names)})\n",
-    "        return preds\n",
-    "\n",
-    "    def test_step(self,batch,batch_idx):\n",
-    "        x,y = batch\n",
-    "        y_pred = self(x)\n",
-    "        loss = F.cross_entropy(y_pred,y)\n",
-    "        # Log training loss\n",
-    "        self.log('test_loss', loss)\n",
-    "        # Log metrics\n",
-    "        self.log('test_acc', self.accuracy(y_pred, y))\n",
-    "        self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
-    "        self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
-    "        wandb.log({\"test_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
-    "                        y_true=self.cpu_y, preds=None,\n",
-    "                        class_names=self.class_names)})\n",
-    "        return loss\n",
-    "    \n",
-    "    def _get_preds_loss_accuracy(self, batch):\n",
-    "        '''convenience function since train/valid/test steps are similar'''\n",
-    "        x, y = batch\n",
-    "        logits = self(x)\n",
-    "        preds = torch.argmax(logits, dim=1)\n",
-    "        loss = self.loss(logits, y)\n",
-    "        acc = accuracy(preds, y, self.acc_task, num_classes=10)\n",
-    "        return preds, loss, acc"
-   ]
-  },
   {
    "cell_type": "code",
    "execution_count": 7,
    "id": "1816bdd2-4846-4dee-a595-190697564b38",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:27.002857Z",
-     "iopub.status.busy": "2023-03-08T17:10:27.001851Z",
-     "iopub.status.idle": "2023-03-08T17:10:27.032396Z",
-     "shell.execute_reply": "2023-03-08T17:10:27.031390Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:27.002857Z"
+     "iopub.execute_input": "2023-03-08T17:15:44.757892Z",
+     "iopub.status.busy": "2023-03-08T17:15:44.757892Z",
+     "iopub.status.idle": "2023-03-08T17:15:44.787873Z",
+     "shell.execute_reply": "2023-03-08T17:15:44.786862Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:44.757892Z"
     },
     "tags": []
    },
@@ -418,14 +289,14 @@
    "source": [
     "class MyModel(LightningModule):\n",
     "\n",
-    "    def __init__(self, classes_lst, input_shape=(1,224,224), n_classes=10, acc_task=\"multiclass\", lr=1e-3, transfer=False): #input_shape=(3,224,224) image shape\n",
+    "    def __init__(self, classes_lst, input_shape=(1,224,224), num_classes=10, acc_task=\"multiclass\", lr=1e-3, transfer=False): #input_shape=(3,224,224) image shape\n",
     "        super().__init__()\n",
     "        \n",
     "        # metrics\n",
     "        self.acc_task = acc_task\n",
     "        self.lr = lr\n",
-    "        self.n_classes = n_classes\n",
-    "        self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.n_classes)\n",
+    "        self.num_classes = num_classes\n",
+    "        self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.num_classes)\n",
     "        self.class_names = classes_lst\n",
     "        self.loss = CrossEntropyLoss()\n",
     "        \n",
@@ -528,118 +399,6 @@
     "        return preds, loss, acc"
    ]
   },
-  {
-   "cell_type": "code",
-   "execution_count": 8,
-   "id": "f87009dd-3c3a-409c-ada8-3f991d17d0c1",
-   "metadata": {
-    "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:27.034398Z",
-     "iopub.status.busy": "2023-03-08T17:10:27.033399Z",
-     "iopub.status.idle": "2023-03-08T17:10:27.049387Z",
-     "shell.execute_reply": "2023-03-08T17:10:27.047400Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:27.034398Z"
-    }
-   },
-   "outputs": [],
-   "source": [
-    "# class MyModel(pl.LightningModule):\n",
-    "#     def __init__(self, input_shape, n_classes=10, lr=2e-4, transfer=False):\n",
-    "#         super().__init__()\n",
-    "        \n",
-    "#         # log hyperparameters\n",
-    "#         self.save_hyperparameters()\n",
-    "#         self.learning_rate = lr\n",
-    "#         self.dim = input_shape\n",
-    "#         self.num_classes = num_classes\n",
-    "        \n",
-    "#         # transfer learning if pretrained=True\n",
-    "#         self.feature_extractor = models.resnet18(pretrained=transfer)\n",
-    "\n",
-    "#         if transfer:\n",
-    "#             # layers are frozen by using eval()\n",
-    "#             self.feature_extractor.eval()\n",
-    "#             # freeze params\n",
-    "#             for param in self.feature_extractor.parameters():\n",
-    "#                 param.requires_grad = False\n",
-    "        \n",
-    "#         n_sizes = self._get_conv_output(input_shape)\n",
-    "\n",
-    "#         self.classifier = nn.Linear(n_sizes, num_classes)\n",
-    "\n",
-    "#         self.criterion = nn.CrossEntropyLoss()\n",
-    "#         self.accuracy = Accuracy()\n",
-    "  \n",
-    "#     # returns the size of the output tensor going into the Linear layer from the conv block.\n",
-    "#     def _get_conv_output(self, shape):\n",
-    "#         batch_size = 1\n",
-    "#         tmp_input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
-    "\n",
-    "#         output_feat = self._forward_features(tmp_input) \n",
-    "#         n_size = output_feat.data.view(batch_size, -1).size(1)\n",
-    "#         return n_size\n",
-    "        \n",
-    "#     # returns the feature tensor from the conv block\n",
-    "#     def _forward_features(self, x):\n",
-    "#         x = self.feature_extractor(x)\n",
-    "#         return x\n",
-    "    \n",
-    "#     # will be used during inference\n",
-    "#     def forward(self, x):\n",
-    "#         x = self._forward_features(x)\n",
-    "#         x = x.view(x.size(0), -1)\n",
-    "#         x = self.classifier(x)\n",
-    "\n",
-    "#         return x\n",
-    "    \n",
-    "#     def training_step(self, batch):\n",
-    "#         batch, gt = batch[0], batch[1]\n",
-    "#         out = self.forward(batch)\n",
-    "#         loss = self.criterion(out, gt)\n",
-    "\n",
-    "#         acc = self.accuracy(out, gt)\n",
-    "\n",
-    "#         self.log(\"train/loss\", loss)\n",
-    "#         self.log(\"train/acc\", acc)\n",
-    "\n",
-    "#         return loss\n",
-    "    \n",
-    "#     def validation_step(self, batch, batch_idx):\n",
-    "#         batch, gt = batch[0], batch[1]\n",
-    "#         out = self.forward(batch)\n",
-    "#         loss = self.criterion(out, gt)\n",
-    "\n",
-    "#         self.log(\"val/loss\", loss)\n",
-    "\n",
-    "#         acc = self.accuracy(out, gt)\n",
-    "#         self.log(\"val/acc\", acc)\n",
-    "\n",
-    "#         return loss\n",
-    "    \n",
-    "#     def test_step(self, batch, batch_idx):\n",
-    "#         batch, gt = batch[0], batch[1]\n",
-    "#         out = self.forward(batch)\n",
-    "#         loss = self.criterion(out, gt)\n",
-    "        \n",
-    "#         return {\"loss\": loss, \"outputs\": out, \"gt\": gt}\n",
-    "    \n",
-    "#     def test_epoch_end(self, outputs):\n",
-    "#         loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
-    "#         output = torch.cat([x['outputs'] for x in outputs], dim=0)\n",
-    "        \n",
-    "#         gts = torch.cat([x['gt'] for x in outputs], dim=0)\n",
-    "        \n",
-    "#         self.log(\"test/loss\", loss)\n",
-    "#         acc = self.accuracy(output, gts)\n",
-    "#         self.log(\"test/acc\", acc)\n",
-    "        \n",
-    "#         self.test_gts = gts\n",
-    "#         self.test_output = output\n",
-    "    \n",
-    "#     def configure_optimizers(self):\n",
-    "#         return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
-   ]
-  },
   {
    "cell_type": "markdown",
    "id": "f561a2e3-1272-4e67-9322-dd9b7534fed3",
@@ -654,11 +413,11 @@
    "id": "188ce4ef-e6b7-4320-8e5d-ceeb616bf7d1",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:27.051399Z",
-     "iopub.status.busy": "2023-03-08T17:10:27.050393Z",
-     "iopub.status.idle": "2023-03-08T17:10:27.063388Z",
-     "shell.execute_reply": "2023-03-08T17:10:27.062386Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:27.051399Z"
+     "iopub.execute_input": "2023-03-08T17:15:44.805869Z",
+     "iopub.status.busy": "2023-03-08T17:15:44.805869Z",
+     "iopub.status.idle": "2023-03-08T17:15:44.818878Z",
+     "shell.execute_reply": "2023-03-08T17:15:44.817859Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:44.805869Z"
     },
     "tags": []
    },
@@ -699,11 +458,11 @@
    "id": "762279ca-26d9-4310-992f-b6f8912da7fe",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-08T17:10:27.065390Z",
-     "iopub.status.busy": "2023-03-08T17:10:27.064390Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.633996Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.631459Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:27.065390Z"
+     "iopub.execute_input": "2023-03-08T17:15:44.820879Z",
+     "iopub.status.busy": "2023-03-08T17:15:44.820879Z",
+     "iopub.status.idle": "2023-03-08T17:15:51.639994Z",
+     "shell.execute_reply": "2023-03-08T17:15:51.638991Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:44.820879Z"
     },
     "tags": []
    },
@@ -715,6 +474,20 @@
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristopher-marais\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
      ]
     },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "d9b7c391f6c64ea391c29b2a946763d5",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0â€¦"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
     {
      "data": {
       "text/html": [
@@ -743,7 +516,7 @@
     {
      "data": {
       "text/html": [
-       "Run data is saved locally in <code>.\\wandb\\run-20230308_121030-fq5x8q4o</code>"
+       "Run data is saved locally in <code>.\\wandb\\run-20230308_121547-ccerfkmr</code>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -755,7 +528,7 @@
     {
      "data": {
       "text/html": [
-       "Syncing run <strong><a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/fq5x8q4o' target=\"_blank\">fallen-shadow-43</a></strong> to <a href='https://wandb.ai/christopher-marais/computer_vision_test_single' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
+       "Syncing run <strong><a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/ccerfkmr' target=\"_blank\">wild-salad-47</a></strong> to <a href='https://wandb.ai/christopher-marais/computer_vision_test_single' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -779,7 +552,7 @@
     {
      "data": {
       "text/html": [
-       " View run at <a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/fq5x8q4o' target=\"_blank\">https://wandb.ai/christopher-marais/computer_vision_test_single/runs/fq5x8q4o</a>"
+       " View run at <a href='https://wandb.ai/christopher-marais/computer_vision_test_single/runs/ccerfkmr' target=\"_blank\">https://wandb.ai/christopher-marais/computer_vision_test_single/runs/ccerfkmr</a>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -789,15 +562,17 @@
      "output_type": "display_data"
     },
     {
-     "ename": "NameError",
-     "evalue": "name 'models' is not defined",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
-      "Cell \u001b[1;32mIn[10], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m DataModule()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# setup model - choose different hyperparameters per experiment\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMyModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclasses_lst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses_lst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_of_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     14\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     15\u001b[0m     devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;66;03m# use all GPU's (-1)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m            \u001b[38;5;66;03m# number of epochs\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     )\n",
-      "Cell \u001b[1;32mIn[7], line 15\u001b[0m, in \u001b[0;36mMyModel.__init__\u001b[1;34m(self, classes_lst, input_shape, n_classes, acc_task, lr, transfer)\u001b[0m\n\u001b[0;32m     12\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# transfer learning if pretrained=True\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241m.\u001b[39mresnet18(pretrained\u001b[38;5;241m=\u001b[39mtransfer)\n\u001b[0;32m     17\u001b[0m  \u001b[38;5;28;01mif\u001b[39;00m transfer:\n\u001b[0;32m     18\u001b[0m      \u001b[38;5;66;03m# layers are frozen by using eval()\u001b[39;00m\n\u001b[0;32m     19\u001b[0m      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor\u001b[38;5;241m.\u001b[39meval()\n",
-      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "C:\\Users\\gcmar\\.conda\\envs\\BC_310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
+      "  warnings.warn(\n",
+      "C:\\Users\\gcmar\\.conda\\envs\\BC_310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
+      "  warnings.warn(msg)\n",
+      "GPU available: True (cuda), used: True\n",
+      "TPU available: False, using: 0 TPU cores\n",
+      "IPU available: False, using: 0 IPUs\n",
+      "HPU available: False, using: 0 HPUs\n"
      ]
     }
    ],
@@ -811,7 +586,7 @@
     "data = DataModule()\n",
     "\n",
     "# setup model - choose different hyperparameters per experiment\n",
-    "model = MyModel(classes_lst=classes_lst, n_classes=num_of_classes, input_shape=(3,224,224))\n",
+    "model = MyModel(classes_lst=classes_lst, num_classes=num_of_classes, input_shape=(3,224,224))\n",
     "\n",
     "\n",
     "trainer = Trainer(\n",
@@ -825,17 +600,98 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 11,
    "id": "05c5995d-f9be-4377-bfc0-ea1298711b12",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.635025Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.636024Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.635025Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.635025Z"
+     "iopub.execute_input": "2023-03-08T17:15:51.642994Z",
+     "iopub.status.busy": "2023-03-08T17:15:51.641997Z",
+     "iopub.status.idle": "2023-03-08T17:15:54.800696Z",
+     "shell.execute_reply": "2023-03-08T17:15:54.797716Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:51.642994Z"
     }
    },
-   "outputs": [],
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
+      "\n",
+      "  | Name              | Type               | Params\n",
+      "---------------------------------------------------------\n",
+      "0 | accuracy          | MulticlassAccuracy | 0     \n",
+      "1 | loss              | CrossEntropyLoss   | 0     \n",
+      "2 | feature_extractor | ResNet             | 11.7 M\n",
+      "3 | classifier        | Linear             | 10.0 K\n",
+      "---------------------------------------------------------\n",
+      "11.7 M    Trainable params\n",
+      "0         Non-trainable params\n",
+      "11.7 M    Total params\n",
+      "46.798    Total estimated model params size (MB)\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "deeadcfa05e34e28a0039a29f5117cb7",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "Sanity Checking: 0it [00:00, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "C:\\Users\\gcmar\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
+      "  rank_zero_warn(\n",
+      "C:\\Users\\gcmar\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
+      "  rank_zero_warn(\n"
+     ]
+    },
+    {
+     "ename": "RuntimeError",
+     "evalue": "Given groups=1, weight of size [64, 3, 7, 7], expected input[10, 1, 50, 50] to have 3 channels, but got 1 channels instead",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
+      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    606\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m--> 608\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     41\u001b[0m     trainer\u001b[38;5;241m.\u001b[39m_call_teardown_hook()\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    643\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_set_ckpt_path(\n\u001b[0;32m    645\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    646\u001b[0m     ckpt_path,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    647\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    648\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    649\u001b[0m )\n\u001b[1;32m--> 650\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1112\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[1;32m-> 1112\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1114\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1191\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[0;32m   1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1204\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_training_routine()\n\u001b[0;32m   1203\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;66;03m# enable train mode\u001b[39;00m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1276\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m-> 1276\u001b[0m     \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\dataloader\\evaluation_loop.py:152\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_dataloaders \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    151\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dataloader_idx\n\u001b[1;32m--> 152\u001b[0m dl_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_max_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# store batch level output per dataloader\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs\u001b[38;5;241m.\u001b[39mappend(dl_outputs)\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:137\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[1;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# lightning module methods\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step_end(output)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:234\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The evaluation step (validation_step or test_step depending on the trainer's state).\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124;03m    the outputs of the step\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    233\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 234\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1494\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1494\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:390\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mval_step_context():\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, ValidationStep)\n\u001b[1;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mvalidation_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
+      "Cell \u001b[1;32mIn[7], line 69\u001b[0m, in \u001b[0;36mMyModel.validation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m,batch,batch_idx):\n\u001b[1;32m---> 69\u001b[0m     preds, loss, acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_preds_loss_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# Log loss and metric\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss_alt\u001b[39m\u001b[38;5;124m'\u001b[39m, loss)\n",
+      "Cell \u001b[1;32mIn[7], line 106\u001b[0m, in \u001b[0;36mMyModel._get_preds_loss_accuracy\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''convenience function since train/valid/test steps are similar'''\u001b[39;00m\n\u001b[0;32m    105\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m--> 106\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    108\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(logits, y)\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
+      "Cell \u001b[1;32mIn[7], line 46\u001b[0m, in \u001b[0;36mMyModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 46\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     48\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(x)\n",
+      "Cell \u001b[1;32mIn[7], line 40\u001b[0m, in \u001b[0;36mMyModel._forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 40\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\torchvision\\models\\resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[0;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[1;32m~\\.conda\\envs\\BC_310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
+      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 7, 7], expected input[10, 1, 50, 50] to have 3 channels, but got 1 channels instead"
+     ]
+    }
+   ],
    "source": [
     "trainer.fit(model, data)"
    ]
@@ -846,10 +702,10 @@
    "id": "28625e66-e2a3-4a91-acce-e2948485412b",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.637021Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.638026Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.637021Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.637021Z"
+     "iopub.status.busy": "2023-03-08T17:15:54.801695Z",
+     "iopub.status.idle": "2023-03-08T17:15:54.802697Z",
+     "shell.execute_reply": "2023-03-08T17:15:54.801695Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:54.801695Z"
     }
    },
    "outputs": [],
@@ -863,10 +719,10 @@
    "id": "378d95e1-4e29-4c7f-bd8c-eaa16677a063",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.639013Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.639013Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.639013Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.639013Z"
+     "iopub.status.busy": "2023-03-08T17:15:54.803697Z",
+     "iopub.status.idle": "2023-03-08T17:15:54.804705Z",
+     "shell.execute_reply": "2023-03-08T17:15:54.804705Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:54.804705Z"
     },
     "tags": []
    },
@@ -881,10 +737,10 @@
    "id": "91967e96-f127-4758-b427-c996a9fcb4dc",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.641013Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.642013Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.642013Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.642013Z"
+     "iopub.status.busy": "2023-03-08T17:15:54.806694Z",
+     "iopub.status.idle": "2023-03-08T17:15:54.807694Z",
+     "shell.execute_reply": "2023-03-08T17:15:54.807694Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:54.807694Z"
     }
    },
    "outputs": [],
@@ -898,7 +754,11 @@
    "id": "f04c136e-5986-4628-88b7-38a8b433f654",
    "metadata": {},
    "outputs": [],
-   "source": []
+   "source": [
+    "data = train_iterator.dataset.data \n",
+    "shape = train_iterator.dataset.data.shape  \n",
+    "datatype = train_iterator.dataset.data.dtype"
+   ]
   },
   {
    "cell_type": "code",
@@ -906,10 +766,10 @@
    "id": "3b58022d-6961-41b0-a4e1-60bbc1c09791",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.643011Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.644008Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.644008Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.644008Z"
+     "iopub.status.busy": "2023-03-08T17:15:54.809701Z",
+     "iopub.status.idle": "2023-03-08T17:15:54.809701Z",
+     "shell.execute_reply": "2023-03-08T17:15:54.809701Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:54.809701Z"
     },
     "tags": []
    },
@@ -932,10 +792,10 @@
    "id": "ebde1018-ddfa-43f2-b9c6-f2c1d4b19736",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.645011Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.646017Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.646017Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.646017Z"
+     "iopub.status.busy": "2023-03-08T17:15:54.811693Z",
+     "iopub.status.idle": "2023-03-08T17:15:54.811693Z",
+     "shell.execute_reply": "2023-03-08T17:15:54.811693Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:54.811693Z"
     },
     "tags": []
    },
@@ -978,10 +838,10 @@
    "id": "91aeb8a0-9ffd-4439-808c-2951d1f74b36",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.648016Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.649014Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.649014Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.649014Z"
+     "iopub.status.busy": "2023-03-08T17:15:54.814696Z",
+     "iopub.status.idle": "2023-03-08T17:15:54.815699Z",
+     "shell.execute_reply": "2023-03-08T17:15:54.815699Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:54.815699Z"
     },
     "tags": []
    },
@@ -1002,7 +862,7 @@
     "    #     n_layer_2=wandb.config.n_layer_2,\n",
     "    #     lr=wandb.config.lr\n",
     "    # )\n",
-    "    model = MyModel(lr=wandb.config.lr, n_classes=num_of_classes)\n",
+    "    model = MyModel(lr=wandb.config.lr, num_classes=num_of_classes)\n",
     "\n",
     "    # setup Trainer\n",
     "    trainer = Trainer(\n",
@@ -1021,10 +881,10 @@
    "id": "869b0393-21cf-4fba-8efd-7678a852b697",
    "metadata": {
     "execution": {
-     "iopub.status.busy": "2023-03-08T17:10:32.650013Z",
-     "iopub.status.idle": "2023-03-08T17:10:32.651012Z",
-     "shell.execute_reply": "2023-03-08T17:10:32.651012Z",
-     "shell.execute_reply.started": "2023-03-08T17:10:32.651012Z"
+     "iopub.status.busy": "2023-03-08T17:15:54.816693Z",
+     "iopub.status.idle": "2023-03-08T17:15:54.817694Z",
+     "shell.execute_reply": "2023-03-08T17:15:54.816693Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:54.816693Z"
     },
     "tags": []
    },
@@ -1041,6 +901,248 @@
    "metadata": {},
    "outputs": [],
    "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 8,
+   "id": "f87009dd-3c3a-409c-ada8-3f991d17d0c1",
+   "metadata": {
+    "execution": {
+     "iopub.execute_input": "2023-03-08T17:15:44.788860Z",
+     "iopub.status.busy": "2023-03-08T17:15:44.788860Z",
+     "iopub.status.idle": "2023-03-08T17:15:44.803868Z",
+     "shell.execute_reply": "2023-03-08T17:15:44.802865Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:44.788860Z"
+    },
+    "tags": []
+   },
+   "outputs": [],
+   "source": [
+    "# class MyModel(pl.LightningModule):\n",
+    "#     def __init__(self, input_shape, num_classes=10, lr=2e-4, transfer=False):\n",
+    "#         super().__init__()\n",
+    "        \n",
+    "#         # log hyperparameters\n",
+    "#         self.save_hyperparameters()\n",
+    "#         self.learning_rate = lr\n",
+    "#         self.dim = input_shape\n",
+    "#         self.num_classes = num_classes\n",
+    "        \n",
+    "#         # transfer learning if pretrained=True\n",
+    "#         self.feature_extractor = models.resnet18(pretrained=transfer)\n",
+    "\n",
+    "#         if transfer:\n",
+    "#             # layers are frozen by using eval()\n",
+    "#             self.feature_extractor.eval()\n",
+    "#             # freeze params\n",
+    "#             for param in self.feature_extractor.parameters():\n",
+    "#                 param.requires_grad = False\n",
+    "        \n",
+    "#         n_sizes = self._get_conv_output(input_shape)\n",
+    "\n",
+    "#         self.classifier = nn.Linear(n_sizes, num_classes)\n",
+    "\n",
+    "#         self.criterion = nn.CrossEntropyLoss()\n",
+    "#         self.accuracy = Accuracy()\n",
+    "  \n",
+    "#     # returns the size of the output tensor going into the Linear layer from the conv block.\n",
+    "#     def _get_conv_output(self, shape):\n",
+    "#         batch_size = 1\n",
+    "#         tmp_input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
+    "\n",
+    "#         output_feat = self._forward_features(tmp_input) \n",
+    "#         n_size = output_feat.data.view(batch_size, -1).size(1)\n",
+    "#         return n_size\n",
+    "        \n",
+    "#     # returns the feature tensor from the conv block\n",
+    "#     def _forward_features(self, x):\n",
+    "#         x = self.feature_extractor(x)\n",
+    "#         return x\n",
+    "    \n",
+    "#     # will be used during inference\n",
+    "#     def forward(self, x):\n",
+    "#         x = self._forward_features(x)\n",
+    "#         x = x.view(x.size(0), -1)\n",
+    "#         x = self.classifier(x)\n",
+    "\n",
+    "#         return x\n",
+    "    \n",
+    "#     def training_step(self, batch):\n",
+    "#         batch, gt = batch[0], batch[1]\n",
+    "#         out = self.forward(batch)\n",
+    "#         loss = self.criterion(out, gt)\n",
+    "\n",
+    "#         acc = self.accuracy(out, gt)\n",
+    "\n",
+    "#         self.log(\"train/loss\", loss)\n",
+    "#         self.log(\"train/acc\", acc)\n",
+    "\n",
+    "#         return loss\n",
+    "    \n",
+    "#     def validation_step(self, batch, batch_idx):\n",
+    "#         batch, gt = batch[0], batch[1]\n",
+    "#         out = self.forward(batch)\n",
+    "#         loss = self.criterion(out, gt)\n",
+    "\n",
+    "#         self.log(\"val/loss\", loss)\n",
+    "\n",
+    "#         acc = self.accuracy(out, gt)\n",
+    "#         self.log(\"val/acc\", acc)\n",
+    "\n",
+    "#         return loss\n",
+    "    \n",
+    "#     def test_step(self, batch, batch_idx):\n",
+    "#         batch, gt = batch[0], batch[1]\n",
+    "#         out = self.forward(batch)\n",
+    "#         loss = self.criterion(out, gt)\n",
+    "        \n",
+    "#         return {\"loss\": loss, \"outputs\": out, \"gt\": gt}\n",
+    "    \n",
+    "#     def test_epoch_end(self, outputs):\n",
+    "#         loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
+    "#         output = torch.cat([x['outputs'] for x in outputs], dim=0)\n",
+    "        \n",
+    "#         gts = torch.cat([x['gt'] for x in outputs], dim=0)\n",
+    "        \n",
+    "#         self.log(\"test/loss\", loss)\n",
+    "#         acc = self.accuracy(output, gts)\n",
+    "#         self.log(\"test/acc\", acc)\n",
+    "        \n",
+    "#         self.test_gts = gts\n",
+    "#         self.test_output = output\n",
+    "    \n",
+    "#     def configure_optimizers(self):\n",
+    "#         return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 6,
+   "id": "deb34aed-792a-4022-a878-f8d6c4ffa97c",
+   "metadata": {
+    "execution": {
+     "iopub.execute_input": "2023-03-08T17:15:44.743323Z",
+     "iopub.status.busy": "2023-03-08T17:15:44.742328Z",
+     "iopub.status.idle": "2023-03-08T17:15:44.755852Z",
+     "shell.execute_reply": "2023-03-08T17:15:44.755331Z",
+     "shell.execute_reply.started": "2023-03-08T17:15:44.743323Z"
+    },
+    "tags": []
+   },
+   "outputs": [],
+   "source": [
+    "# class MyModel(LightningModule):\n",
+    "\n",
+    "#     def __init__(self, classes_lst, num_classes=10, acc_task=\"multiclass\", lr=1e-3):\n",
+    "#         super().__init__()\n",
+    "        \n",
+    "        \n",
+    "#         \"\"\"\n",
+    "#         The convolutions are arranged in such a way that the image maintain the x and y dimensions. only the channels change\n",
+    "#         \"\"\"\n",
+    "#         self.layer_1 = nn.Conv2d(in_channels = 1,out_channels = 3,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "#         self.layer_2 = nn.Conv2d(in_channels = 3,out_channels = 6,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "#         self.layer_3 = nn.Conv2d(in_channels = 6,out_channels = 12,kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "#         self.pool = nn.MaxPool2d(kernel_size = (3,3),padding = (1,1),stride = (1,1))\n",
+    "#         self.layer_5 = nn.Linear(12*50*50,1000)#the input dimensions are (Number of dimensions * height * width)\n",
+    "#         self.layer_6 = nn.Linear(1000,100)\n",
+    "#         self.layer_7 = nn.Linear(100,50)\n",
+    "#         self.layer_8 = nn.Linear(50,10)\n",
+    "#         self.layer_9 = nn.Linear(10,10)\n",
+    "        \n",
+    "        \n",
+    "        \n",
+    "#         # metrics\n",
+    "#         self.acc_task = acc_task\n",
+    "#         self.lr = lr\n",
+    "#         self.num_classes = num_classes\n",
+    "#         self.accuracy = torchmetrics.Accuracy(task=self.acc_task, num_classes=self.num_classes)\n",
+    "#         self.class_names = classes_lst\n",
+    "#         self.loss = CrossEntropyLoss()\n",
+    "\n",
+    "#         # optional - save hyper-parameters to self.hparams\n",
+    "#         # they will also be automatically logged as config parameters in W&B\n",
+    "#         self.save_hyperparameters()\n",
+    "\n",
+    "#     def forward(self,x):\n",
+    "#         \"\"\"\n",
+    "#         x is the input data\n",
+    "#         \"\"\"\n",
+    "#         x = self.layer_1(x)\n",
+    "#         x = self.pool(x)\n",
+    "#         x = self.layer_2(x)\n",
+    "#         x = self.pool(x)\n",
+    "#         x = self.layer_3(x)\n",
+    "#         x = self.pool(x)\n",
+    "#         x = x.view(x.size(0),-1)\n",
+    "#         print(x.size())\n",
+    "#         x = self.layer_5(x)\n",
+    "#         x = self.layer_6(x)\n",
+    "#         x = self.layer_7(x)\n",
+    "#         x = self.layer_8(x)\n",
+    "#         x = self.layer_9(x)\n",
+    "#         return x\n",
+    "\n",
+    "#     def configure_optimizers(self):\n",
+    "#         optimizer = torch.optim.Adam(self.parameters(),lr = self.lr)\n",
+    "#         return optimizer\n",
+    "\n",
+    "# # The Pytorch-Lightning module handles all the iterations of the epoch\n",
+    "\n",
+    "#     def training_step(self,batch,batch_idx):\n",
+    "#         x,y = batch\n",
+    "#         y_pred = self(x)\n",
+    "#         loss = F.cross_entropy(y_pred,y)\n",
+    "#         # Log training loss\n",
+    "#         self.log('train_loss', loss)\n",
+    "#         # Log metrics\n",
+    "#         self.log('train_acc', self.accuracy(y_pred, y))\n",
+    "#         return loss\n",
+    "\n",
+    "#     def validation_step(self,batch,batch_idx):\n",
+    "#         preds, loss, acc = self._get_preds_loss_accuracy(batch)\n",
+    "#         # Log loss and metric\n",
+    "#         self.log('val_loss_alt', loss)\n",
+    "#         self.log('val_accuracy_alt', acc)\n",
+    "        \n",
+    "#         x,y = batch\n",
+    "#         y_pred = self(x)\n",
+    "#         loss = F.cross_entropy(y_pred,y)\n",
+    "#         # Log training loss\n",
+    "#         self.log('val_loss', loss)\n",
+    "#         # Log metrics\n",
+    "#         self.log('val_acc', self.accuracy(y_pred, y))\n",
+    "#         self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
+    "#         self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
+    "#         wandb.log({\"val_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
+    "#                         y_true=self.cpu_y, preds=None,\n",
+    "#                         class_names=self.class_names)})\n",
+    "#         return preds\n",
+    "\n",
+    "#     def test_step(self,batch,batch_idx):\n",
+    "#         x,y = batch\n",
+    "#         y_pred = self(x)\n",
+    "#         loss = F.cross_entropy(y_pred,y)\n",
+    "#         # Log training loss\n",
+    "#         self.log('test_loss', loss)\n",
+    "#         # Log metrics\n",
+    "#         self.log('test_acc', self.accuracy(y_pred, y))\n",
+    "#         self.cpu_pred = y_pred.to(\"cpu\").detach().numpy()\n",
+    "#         self.cpu_y = y.to(\"cpu\").detach().numpy()\n",
+    "#         wandb.log({\"test_conf_mat\" : wandb.plot.confusion_matrix(probs=self.cpu_pred,\n",
+    "#                         y_true=self.cpu_y, preds=None,\n",
+    "#                         class_names=self.class_names)})\n",
+    "#         return loss\n",
+    "    \n",
+    "#     def _get_preds_loss_accuracy(self, batch):\n",
+    "#         '''convenience function since train/valid/test steps are similar'''\n",
+    "#         x, y = batch\n",
+    "#         logits = self(x)\n",
+    "#         preds = torch.argmax(logits, dim=1)\n",
+    "#         loss = self.loss(logits, y)\n",
+    "#         acc = accuracy(preds, y, self.acc_task, num_classes=10)\n",
+    "#         return preds, loss, acc"
+   ]
   }
  ],
  "metadata": {
