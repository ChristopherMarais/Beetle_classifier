{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c001309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import wandb\n",
    "import fastai\n",
    "import dill\n",
    "import re\n",
    "import numpy as np\n",
    "from fastai.callback.wandb import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.core import *\n",
    "from fastai.text.core import RegexLabeller\n",
    "from fastai.vision.utils import get_image_files\n",
    "from fastai.data.block import DataBlock\n",
    "from fastai.data.core import *\n",
    "from fastai.tabular.all import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import notebook_login, push_to_hub_fastai, from_pretrained_fastai\n",
    "from torchvision.transforms import GaussianBlur\n",
    "# os.environ['WANDB_WATCH'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9de40be",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SimpleNamespace(\n",
    "    batch_size=8,  #16, #256,\n",
    "    epochs=5,\n",
    "    lr=2e-3,\n",
    "    img_size=256, # 224\n",
    "    seed=42,\n",
    "    pretrained=True,\n",
    "    top_k_losses=5,\n",
    "    model_name=\"maxvit_nano_rw_256.sw_in1k\",# \"maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k\",# try with maxvit_nano_rw_256.sw_in1k # regnetx_040 coatnet_bn_0_rw_224.sw_in1k\n",
    "    wandb_project=\"Beetle_classifier\", \n",
    "    wandb_group=\"ambrosia_symbiosis\",\n",
    "    job_type=\"training\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b51e9b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(dataset_path, batch_size, img_size, seed, subfolders=('train','valid')):\n",
    "    \"The beetles dataset\"\n",
    "    files = get_image_files(path=dataset_path, recurse=True, folders=subfolders)\n",
    "    transforms = aug_transforms(    # transformatiosn that are only applied ot training and not inference\n",
    "                           batch=False,\n",
    "                           pad_mode='zeros',\n",
    "                           size=img_size,\n",
    "                           p_affine=0.8,\n",
    "                           p_lighting=0.8,\n",
    "                           max_rotate=360.0,\n",
    "                           mult=1.0, \n",
    "                           do_flip=True, \n",
    "                           flip_vert=False,\n",
    "                           min_zoom=1.0,\n",
    "                           max_zoom=1.1, \n",
    "                           max_lighting=0.2,\n",
    "                           max_warp=0.2, \n",
    "                           mode='bilinear', \n",
    "                           align_corners=True,\n",
    "                           blur=True,\n",
    "                           min_scale=1.0)\n",
    "    transforms.append(RandomApply([GaussianBlur(kernel_size=5)], p=0.8))\n",
    "    dblock = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "                       get_items = get_image_files,\n",
    "                       splitter = GrandparentSplitter(train_name=subfolders[0], valid_name=subfolders[1]),\n",
    "                       get_y = parent_label,\n",
    "                       item_tfms = Resize(img_size, ResizeMethod.Pad, pad_mode='zeros'), # resize trasnformation is applied during inference too                                    \n",
    "                       batch_tfms = transforms)\n",
    "    dls = dblock.dataloaders(dataset_path, bs = batch_size)\n",
    "    return dls\n",
    "\n",
    "def train(config, dataset_path, subfolders=('train','valid')):\n",
    "    \"Train the model using the supplied config\"\n",
    "    dls = get_images(dataset_path=dataset_path, batch_size=config.batch_size, img_size=config.img_size, seed=config.seed, subfolders=subfolders)\n",
    "    labels = np.array([re.split(r'/|\\\\', str(x))[-2] for x in dls.items])\n",
    "    classes = np.unique(labels)\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=labels)\n",
    "    class_weights = {c: w for c, w in zip(classes, weights)}\n",
    "    weights = tensor([class_weights[c] for c in dls.vocab]).to(dls.device)\n",
    "    # wandb.init(project=config.wandb_project, group=config.wandb_group, job_type=config.job_type, config=config) # it is a good idea to keep these functions out of the training function due to some exporting issues\n",
    "    cbs = [MixedPrecision(), ShowGraphCallback(), SaveModelCallback(), WandbCallback(log='gradients')] # (all, parameters, gradients or None) parameters and all does nto work currently wandb needs to be updated\n",
    "    learn = vision_learner(dls, \n",
    "                           config.model_name, \n",
    "                           loss_func=LabelSmoothingCrossEntropy(weight=weights), # this fucntion is used for class imbalance it is a regularization technique # LabelSmoothingCrossEntropyFlat is used for multi dimensional data\n",
    "                           metrics=[error_rate, \n",
    "                                    accuracy, \n",
    "                                    top_k_accuracy], \n",
    "                           cbs=cbs, \n",
    "                           pretrained=config.pretrained)\n",
    "    learn.fine_tune(config.epochs, base_lr=config.lr)\n",
    "    interp = ClassificationInterpretation.from_learner(learn)\n",
    "    interp.plot_confusion_matrix()\n",
    "    interp.plot_top_losses(config.top_k_losses, nrows=config.top_k_losses)\n",
    "    # wandb.finish() # it is a good idea to keep these functions out of the training function due to some exporting issues\n",
    "    return learn\n",
    "\n",
    "# this function only describes how much a singular value in al ist stands out.\n",
    "# if all values in the lsit are high or low this is 1\n",
    "# the smaller the proportiopn of number of disimilar vlaues are to other more similar values the lower this number\n",
    "# the larger the gap between the dissimilar numbers and the simialr number the smaller this number\n",
    "# only able to interpret probabilities or values between 0 and 1\n",
    "# this function outputs an estimate an inverse of the classification confidence based on the probabilities of all the classes.\n",
    "# the wedge threshold splits the data on a threshold with a magnitude of a positive int to force a ledge/peak in the data\n",
    "def unkown_prob_calc(probs, wedge_threshold, wedge_magnitude=1, wedge='strict'):\n",
    "    if wedge =='strict':\n",
    "        increase_var = (1/(wedge_magnitude))\n",
    "        decrease_var = (wedge_magnitude)\n",
    "    if wedge =='dynamic': # this allows pointsthat are furhter from the threshold ot be moved less and points clsoer to be moved more\n",
    "        increase_var = (1/(wedge_magnitude*((1-np.abs(probs-wedge_threshold)))))\n",
    "        decrease_var = (wedge_magnitude*((1-np.abs(probs-wedge_threshold))))\n",
    "    # else:\n",
    "    #     print(\"Error: use 'strict' (default) or 'dynamic' as options for the wedge parameter!\")\n",
    "    probs = np.where(probs>=wedge_threshold , probs**increase_var, probs)\n",
    "    probs = np.where(probs<=wedge_threshold , probs**decrease_var, probs)\n",
    "    diff_matrix = np.abs(probs[:, np.newaxis] - probs)\n",
    "    diff_matrix_sum = np.sum(diff_matrix)\n",
    "    probs_sum = np.sum(probs)\n",
    "    class_val = (diff_matrix_sum/probs_sum)\n",
    "    max_class_val = ((len(probs)-1)*2)\n",
    "    kown_prob = class_val/max_class_val\n",
    "    unknown_prob = 1-kown_prob\n",
    "    return(unknown_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f102c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "# dataset_path = r\"/blue/hulcr/gmarais/Beetle_data/selected_images/train_data\"\n",
    "dataset_path = r\"F:\\Beetle_data\\selected_images\\train_data\"\n",
    "wandb.init(project=config.wandb_project, group=config.wandb_group, job_type=config.job_type, config=config)\n",
    "learn = train(config=config, dataset_path=dataset_path)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87275fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(dataset_path, batch_size, img_size, seed, subfolders=('train','valid')):\n",
    "    \"The beetles dataset\"\n",
    "    files = get_image_files(path=dataset_path, recurse=True, folders=subfolders)\n",
    "    transforms = aug_transforms(    # transformatiosn that are only applied ot training and not inference\n",
    "                           batch=False,\n",
    "                           pad_mode='zeros',\n",
    "                           size=img_size,\n",
    "                           p_affine=0.8,\n",
    "                           p_lighting=0.8,\n",
    "                           max_rotate=360.0,\n",
    "                           mult=1.0, \n",
    "                           do_flip=True, \n",
    "                           flip_vert=False,\n",
    "                           min_zoom=1.0,\n",
    "                           max_zoom=1.1, \n",
    "                           max_lighting=0.2,\n",
    "                           max_warp=0.2, \n",
    "                           mode='bilinear', \n",
    "                           align_corners=True,\n",
    "                           min_scale=1.0)\n",
    "    transforms.append(RandomApply([GaussianBlur(kernel_size=5)], p=0.8))\n",
    "    dblock = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "                       get_items = get_image_files,\n",
    "                       splitter = GrandparentSplitter(train_name=subfolders[0], valid_name=subfolders[1]),\n",
    "                       get_y = parent_label,\n",
    "                       item_tfms = Resize(img_size, ResizeMethod.Pad, pad_mode='zeros'), # resize trasnformation is applied during inference too                                    \n",
    "                       batch_tfms = transforms)\n",
    "    dls = dblock.dataloaders(dataset_path, bs = batch_size)\n",
    "    return dls\n",
    "\n",
    "def train(config, dataset_path, subfolders=('train','valid')):\n",
    "    \"Train the model using the supplied config\"\n",
    "    dls = get_images(dataset_path=dataset_path, batch_size=config.batch_size, img_size=config.img_size, seed=config.seed, subfolders=subfolders)\n",
    "    labels = np.array([re.split(r'/|\\\\', str(x))[-2] for x in dls.items])\n",
    "    classes = np.unique(labels)\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=labels)\n",
    "    class_weights = {c: w for c, w in zip(classes, weights)}\n",
    "    weights = tensor([class_weights[c] for c in dls.vocab]).to(dls.device)\n",
    "    # wandb.init(project=config.wandb_project, group=config.wandb_group, job_type=config.job_type, config=config) # it is a good idea to keep these functions out of the training function due to some exporting issues\n",
    "    cbs = [MixedPrecision(), ShowGraphCallback(), SaveModelCallback(), WandbCallback(log='gradients')] # (all, parameters, gradients or None) parameters and all does nto work currently wandb needs to be updated\n",
    "    learn = vision_learner(dls, \n",
    "                           config.model_name, \n",
    "                           loss_func=LabelSmoothingCrossEntropy(weight=weights), # this fucntion is used for class imbalance it is a regularization technique # LabelSmoothingCrossEntropyFlat is used for multi dimensional data\n",
    "                           metrics=[error_rate, \n",
    "                                    accuracy, \n",
    "                                    top_k_accuracy], \n",
    "                           cbs=cbs, \n",
    "                           pretrained=config.pretrained)\n",
    "    learn.fine_tune(config.epochs, base_lr=config.lr)\n",
    "    interp = ClassificationInterpretation.from_learner(learn)\n",
    "    interp.plot_confusion_matrix()\n",
    "    interp.plot_top_losses(config.top_k_losses, nrows=config.top_k_losses)\n",
    "    # wandb.finish() # it is a good idea to keep these functions out of the training function due to some exporting issues\n",
    "    return learn\n",
    "\n",
    "# this function only describes how much a singular value in al ist stands out.\n",
    "# if all values in the lsit are high or low this is 1\n",
    "# the smaller the proportiopn of number of disimilar vlaues are to other more similar values the lower this number\n",
    "# the larger the gap between the dissimilar numbers and the simialr number the smaller this number\n",
    "# only able to interpret probabilities or values between 0 and 1\n",
    "# this function outputs an estimate an inverse of the classification confidence based on the probabilities of all the classes.\n",
    "# the wedge threshold splits the data on a threshold with a magnitude of a positive int to force a ledge/peak in the data\n",
    "def unkown_prob_calc(probs, wedge_threshold, wedge_magnitude=1, wedge='strict'):\n",
    "    if wedge =='strict':\n",
    "        increase_var = (1/(wedge_magnitude))\n",
    "        decrease_var = (wedge_magnitude)\n",
    "    if wedge =='dynamic': # this allows pointsthat are furhter from the threshold ot be moved less and points clsoer to be moved more\n",
    "        increase_var = (1/(wedge_magnitude*((1-np.abs(probs-wedge_threshold)))))\n",
    "        decrease_var = (wedge_magnitude*((1-np.abs(probs-wedge_threshold))))\n",
    "    # else:\n",
    "    #     print(\"Error: use 'strict' (default) or 'dynamic' as options for the wedge parameter!\")\n",
    "    probs = np.where(probs>=wedge_threshold , probs**increase_var, probs)\n",
    "    probs = np.where(probs<=wedge_threshold , probs**decrease_var, probs)\n",
    "    diff_matrix = np.abs(probs[:, np.newaxis] - probs)\n",
    "    diff_matrix_sum = np.sum(diff_matrix)\n",
    "    probs_sum = np.sum(probs)\n",
    "    class_val = (diff_matrix_sum/probs_sum)\n",
    "    max_class_val = ((len(probs)-1)*2)\n",
    "    kown_prob = class_val/max_class_val\n",
    "    unknown_prob = 1-kown_prob\n",
    "    return(unknown_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f1ec27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "# dataset_path = r\"/blue/hulcr/gmarais/Beetle_data/selected_images/train_data\"\n",
    "dataset_path = r\"F:\\Beetle_data\\selected_images\\train_data\"\n",
    "wandb.init(project=config.wandb_project, group=config.wandb_group, job_type=config.job_type, config=config)\n",
    "learn = train(config=config, dataset_path=dataset_path)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aee1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import wandb\n",
    "import fastai\n",
    "import dill\n",
    "import re\n",
    "import numpy as np\n",
    "from fastai.callback.wandb import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.core import *\n",
    "from fastai.text.core import RegexLabeller\n",
    "from fastai.vision.utils import get_image_files\n",
    "from fastai.data.block import DataBlock\n",
    "from fastai.data.core import *\n",
    "from fastai.tabular.all import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import notebook_login, push_to_hub_fastai, from_pretrained_fastai\n",
    "from torchvision.transforms import GaussianBlur, RandomApply\n",
    "# os.environ['WANDB_WATCH'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1e257e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:6k2oxcmb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dfb39697d72436c8d257748b215f047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.114 MB of 4.119 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.998812…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cosmic-sunset-30</strong> at: <a href='https://wandb.ai/christopher-marais/Beetle_classifier/runs/6k2oxcmb' target=\"_blank\">https://wandb.ai/christopher-marais/Beetle_classifier/runs/6k2oxcmb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230417_233910-6k2oxcmb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:6k2oxcmb). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37fffa7b120b404388e9ad41feb225cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333333145128, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>E:\\GIT_REPOS\\Beetle_classifier\\Train\\wandb\\run-20230417_234221-3q2aejg6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/christopher-marais/Beetle_classifier/runs/3q2aejg6' target=\"_blank\">polar-water-31</a></strong> to <a href='https://wandb.ai/christopher-marais/Beetle_classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/christopher-marais/Beetle_classifier' target=\"_blank\">https://wandb.ai/christopher-marais/Beetle_classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/christopher-marais/Beetle_classifier/runs/3q2aejg6' target=\"_blank\">https://wandb.ai/christopher-marais/Beetle_classifier/runs/3q2aejg6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train Model\n",
    "# dataset_path = r\"/blue/hulcr/gmarais/Beetle_data/selected_images/train_data\"\n",
    "dataset_path = r\"F:\\Beetle_data\\selected_images\\train_data\"\n",
    "wandb.init(project=config.wandb_project, group=config.wandb_group, job_type=config.job_type, config=config)\n",
    "learn = train(config=config, dataset_path=dataset_path)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "058b75c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTransform(Transform):\n",
    "    def __init__(self, tfms, p=0.5):\n",
    "        self.tfms = tfms\n",
    "        self.p = p\n",
    "\n",
    "    def encodes(self, x: PIL.Image.Image):\n",
    "        if random.random() < self.p:\n",
    "            for t in self.tfms:\n",
    "                x = t(x)\n",
    "        return x\n",
    "\n",
    "def get_images(dataset_path, batch_size, img_size, seed, subfolders=('train','valid')):\n",
    "    \"The beetles dataset\"\n",
    "    files = get_image_files(path=dataset_path, recurse=True, folders=subfolders)\n",
    "    transforms = aug_transforms(    # transformatiosn that are only applied ot training and not inference\n",
    "                           batch=False,\n",
    "                           pad_mode='zeros',\n",
    "                           size=img_size,\n",
    "                           p_affine=0.8,\n",
    "                           p_lighting=0.8,\n",
    "                           max_rotate=360.0,\n",
    "                           mult=1.0, \n",
    "                           do_flip=True, \n",
    "                           flip_vert=False,\n",
    "                           min_zoom=1.0,\n",
    "                           max_zoom=1.1, \n",
    "                           max_lighting=0.2,\n",
    "                           max_warp=0.2, \n",
    "                           mode='bilinear', \n",
    "                           align_corners=True,\n",
    "                           min_scale=1.0)\n",
    "    my_tfms = MyTransform([GaussianBlur(kernel_size=5)], p=0.8)\n",
    "    transforms.append(my_tfms)\n",
    "    dblock = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "                       get_items = get_image_files,\n",
    "                       splitter = GrandparentSplitter(train_name=subfolders[0], valid_name=subfolders[1]),\n",
    "                       get_y = parent_label,\n",
    "                       item_tfms = Resize(img_size, ResizeMethod.Pad, pad_mode='zeros'), # resize trasnformation is applied during inference too                                    \n",
    "                       batch_tfms = transforms)\n",
    "    dls = dblock.dataloaders(dataset_path, bs = batch_size)\n",
    "    return dls\n",
    "\n",
    "def train(config, dataset_path, subfolders=('train','valid')):\n",
    "    \"Train the model using the supplied config\"\n",
    "    dls = get_images(dataset_path=dataset_path, batch_size=config.batch_size, img_size=config.img_size, seed=config.seed, subfolders=subfolders)\n",
    "    labels = np.array([re.split(r'/|\\\\', str(x))[-2] for x in dls.items])\n",
    "    classes = np.unique(labels)\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=labels)\n",
    "    class_weights = {c: w for c, w in zip(classes, weights)}\n",
    "    weights = tensor([class_weights[c] for c in dls.vocab]).to(dls.device)\n",
    "    # wandb.init(project=config.wandb_project, group=config.wandb_group, job_type=config.job_type, config=config) # it is a good idea to keep these functions out of the training function due to some exporting issues\n",
    "    cbs = [MixedPrecision(), ShowGraphCallback(), SaveModelCallback(), WandbCallback(log='gradients')] # (all, parameters, gradients or None) parameters and all does nto work currently wandb needs to be updated\n",
    "    learn = vision_learner(dls, \n",
    "                           config.model_name, \n",
    "                           loss_func=LabelSmoothingCrossEntropy(weight=weights), # this fucntion is used for class imbalance it is a regularization technique # LabelSmoothingCrossEntropyFlat is used for multi dimensional data\n",
    "                           metrics=[error_rate, \n",
    "                                    accuracy, \n",
    "                                    top_k_accuracy], \n",
    "                           cbs=cbs, \n",
    "                           pretrained=config.pretrained)\n",
    "    learn.fine_tune(config.epochs, base_lr=config.lr)\n",
    "    interp = ClassificationInterpretation.from_learner(learn)\n",
    "    interp.plot_confusion_matrix()\n",
    "    interp.plot_top_losses(config.top_k_losses, nrows=config.top_k_losses)\n",
    "    # wandb.finish() # it is a good idea to keep these functions out of the training function due to some exporting issues\n",
    "    return learn\n",
    "\n",
    "# this function only describes how much a singular value in al ist stands out.\n",
    "# if all values in the lsit are high or low this is 1\n",
    "# the smaller the proportiopn of number of disimilar vlaues are to other more similar values the lower this number\n",
    "# the larger the gap between the dissimilar numbers and the simialr number the smaller this number\n",
    "# only able to interpret probabilities or values between 0 and 1\n",
    "# this function outputs an estimate an inverse of the classification confidence based on the probabilities of all the classes.\n",
    "# the wedge threshold splits the data on a threshold with a magnitude of a positive int to force a ledge/peak in the data\n",
    "def unkown_prob_calc(probs, wedge_threshold, wedge_magnitude=1, wedge='strict'):\n",
    "    if wedge =='strict':\n",
    "        increase_var = (1/(wedge_magnitude))\n",
    "        decrease_var = (wedge_magnitude)\n",
    "    if wedge =='dynamic': # this allows pointsthat are furhter from the threshold ot be moved less and points clsoer to be moved more\n",
    "        increase_var = (1/(wedge_magnitude*((1-np.abs(probs-wedge_threshold)))))\n",
    "        decrease_var = (wedge_magnitude*((1-np.abs(probs-wedge_threshold))))\n",
    "    # else:\n",
    "    #     print(\"Error: use 'strict' (default) or 'dynamic' as options for the wedge parameter!\")\n",
    "    probs = np.where(probs>=wedge_threshold , probs**increase_var, probs)\n",
    "    probs = np.where(probs<=wedge_threshold , probs**decrease_var, probs)\n",
    "    diff_matrix = np.abs(probs[:, np.newaxis] - probs)\n",
    "    diff_matrix_sum = np.sum(diff_matrix)\n",
    "    probs_sum = np.sum(probs)\n",
    "    class_val = (diff_matrix_sum/probs_sum)\n",
    "    max_class_val = ((len(probs)-1)*2)\n",
    "    kown_prob = class_val/max_class_val\n",
    "    unknown_prob = 1-kown_prob\n",
    "    return(unknown_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d51ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import wandb\n",
    "import fastai\n",
    "import dill\n",
    "import re\n",
    "import PIL\n",
    "import numpy as np\n",
    "from fastai.callback.wandb import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.core import *\n",
    "from fastai.text.core import RegexLabeller\n",
    "from fastai.vision.utils import get_image_files\n",
    "from fastai.data.block import DataBlock\n",
    "from fastai.data.core import *\n",
    "from fastai.tabular.all import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import notebook_login, push_to_hub_fastai, from_pretrained_fastai\n",
    "from torchvision.transforms import GaussianBlur, RandomApply\n",
    "# os.environ['WANDB_WATCH'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf11b231",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTransform(Transform):\n",
    "    def __init__(self, tfms, p=0.5):\n",
    "        self.tfms = tfms\n",
    "        self.p = p\n",
    "\n",
    "    def encodes(self, x: PIL.Image.Image):\n",
    "        if random.random() < self.p:\n",
    "            for t in self.tfms:\n",
    "                x = t(x)\n",
    "        return x\n",
    "\n",
    "def get_images(dataset_path, batch_size, img_size, seed, subfolders=('train','valid')):\n",
    "    \"The beetles dataset\"\n",
    "    files = get_image_files(path=dataset_path, recurse=True, folders=subfolders)\n",
    "    transforms = aug_transforms(    # transformatiosn that are only applied ot training and not inference\n",
    "                           batch=False,\n",
    "                           pad_mode='zeros',\n",
    "                           size=img_size,\n",
    "                           p_affine=0.8,\n",
    "                           p_lighting=0.8,\n",
    "                           max_rotate=360.0,\n",
    "                           mult=1.0, \n",
    "                           do_flip=True, \n",
    "                           flip_vert=False,\n",
    "                           min_zoom=1.0,\n",
    "                           max_zoom=1.1, \n",
    "                           max_lighting=0.2,\n",
    "                           max_warp=0.2, \n",
    "                           mode='bilinear', \n",
    "                           align_corners=True,\n",
    "                           min_scale=1.0)\n",
    "    my_tfms = MyTransform([GaussianBlur(kernel_size=5)], p=0.8)\n",
    "    transforms.append(my_tfms)\n",
    "    dblock = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "                       get_items = get_image_files,\n",
    "                       splitter = GrandparentSplitter(train_name=subfolders[0], valid_name=subfolders[1]),\n",
    "                       get_y = parent_label,\n",
    "                       item_tfms = Resize(img_size, ResizeMethod.Pad, pad_mode='zeros'), # resize trasnformation is applied during inference too                                    \n",
    "                       batch_tfms = transforms)\n",
    "    dls = dblock.dataloaders(dataset_path, bs = batch_size)\n",
    "    return dls\n",
    "\n",
    "def train(config, dataset_path, subfolders=('train','valid')):\n",
    "    \"Train the model using the supplied config\"\n",
    "    dls = get_images(dataset_path=dataset_path, batch_size=config.batch_size, img_size=config.img_size, seed=config.seed, subfolders=subfolders)\n",
    "    labels = np.array([re.split(r'/|\\\\', str(x))[-2] for x in dls.items])\n",
    "    classes = np.unique(labels)\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=labels)\n",
    "    class_weights = {c: w for c, w in zip(classes, weights)}\n",
    "    weights = tensor([class_weights[c] for c in dls.vocab]).to(dls.device)\n",
    "    # wandb.init(project=config.wandb_project, group=config.wandb_group, job_type=config.job_type, config=config) # it is a good idea to keep these functions out of the training function due to some exporting issues\n",
    "    cbs = [MixedPrecision(), ShowGraphCallback(), SaveModelCallback(), WandbCallback(log='gradients')] # (all, parameters, gradients or None) parameters and all does nto work currently wandb needs to be updated\n",
    "    learn = vision_learner(dls, \n",
    "                           config.model_name, \n",
    "                           loss_func=LabelSmoothingCrossEntropy(weight=weights), # this fucntion is used for class imbalance it is a regularization technique # LabelSmoothingCrossEntropyFlat is used for multi dimensional data\n",
    "                           metrics=[error_rate, \n",
    "                                    accuracy, \n",
    "                                    top_k_accuracy], \n",
    "                           cbs=cbs, \n",
    "                           pretrained=config.pretrained)\n",
    "    learn.fine_tune(config.epochs, base_lr=config.lr)\n",
    "    interp = ClassificationInterpretation.from_learner(learn)\n",
    "    interp.plot_confusion_matrix()\n",
    "    interp.plot_top_losses(config.top_k_losses, nrows=config.top_k_losses)\n",
    "    # wandb.finish() # it is a good idea to keep these functions out of the training function due to some exporting issues\n",
    "    return learn\n",
    "\n",
    "# this function only describes how much a singular value in al ist stands out.\n",
    "# if all values in the lsit are high or low this is 1\n",
    "# the smaller the proportiopn of number of disimilar vlaues are to other more similar values the lower this number\n",
    "# the larger the gap between the dissimilar numbers and the simialr number the smaller this number\n",
    "# only able to interpret probabilities or values between 0 and 1\n",
    "# this function outputs an estimate an inverse of the classification confidence based on the probabilities of all the classes.\n",
    "# the wedge threshold splits the data on a threshold with a magnitude of a positive int to force a ledge/peak in the data\n",
    "def unkown_prob_calc(probs, wedge_threshold, wedge_magnitude=1, wedge='strict'):\n",
    "    if wedge =='strict':\n",
    "        increase_var = (1/(wedge_magnitude))\n",
    "        decrease_var = (wedge_magnitude)\n",
    "    if wedge =='dynamic': # this allows pointsthat are furhter from the threshold ot be moved less and points clsoer to be moved more\n",
    "        increase_var = (1/(wedge_magnitude*((1-np.abs(probs-wedge_threshold)))))\n",
    "        decrease_var = (wedge_magnitude*((1-np.abs(probs-wedge_threshold))))\n",
    "    # else:\n",
    "    #     print(\"Error: use 'strict' (default) or 'dynamic' as options for the wedge parameter!\")\n",
    "    probs = np.where(probs>=wedge_threshold , probs**increase_var, probs)\n",
    "    probs = np.where(probs<=wedge_threshold , probs**decrease_var, probs)\n",
    "    diff_matrix = np.abs(probs[:, np.newaxis] - probs)\n",
    "    diff_matrix_sum = np.sum(diff_matrix)\n",
    "    probs_sum = np.sum(probs)\n",
    "    class_val = (diff_matrix_sum/probs_sum)\n",
    "    max_class_val = ((len(probs)-1)*2)\n",
    "    kown_prob = class_val/max_class_val\n",
    "    unknown_prob = 1-kown_prob\n",
    "    return(unknown_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a4fca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "# dataset_path = r\"/blue/hulcr/gmarais/Beetle_data/selected_images/train_data\"\n",
    "dataset_path = r\"F:\\Beetle_data\\selected_images\\train_data\"\n",
    "wandb.init(project=config.wandb_project, group=config.wandb_group, job_type=config.job_type, config=config)\n",
    "learn = train(config=config, dataset_path=dataset_path)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
