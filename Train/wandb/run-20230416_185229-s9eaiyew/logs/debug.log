2023-04-16 18:52:29,138 INFO    Thread-25 (_run_job):50181 [wandb_setup.py:_flush():76] Configure stats pid to 50181
2023-04-16 18:52:29,139 INFO    Thread-25 (_run_job):50181 [wandb_setup.py:_flush():76] Loading settings from /home/gmarais/.config/wandb/settings
2023-04-16 18:52:29,139 INFO    Thread-25 (_run_job):50181 [wandb_setup.py:_flush():76] Loading settings from /blue/hulcr/gmarais/Beetle_classifier/Train/wandb/settings
2023-04-16 18:52:29,139 INFO    Thread-25 (_run_job):50181 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'notebook_name': 'Parameter_Optimization_Sweep.ipynb', 'project': 'Ambrosia_Symbiosis', 'entity': 'christopher-marais', 'root_dir': '/blue/hulcr/gmarais/Beetle_classifier/Train', 'run_id': 's9eaiyew', 'sweep_param_path': '/blue/hulcr/gmarais/Beetle_classifier/Train/wandb/sweep-soz6xxoq/config-s9eaiyew.yaml', 'sweep_id': 'soz6xxoq'}
2023-04-16 18:52:29,139 INFO    Thread-25 (_run_job):50181 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-04-16 18:52:29,139 INFO    Thread-25 (_run_job):50181 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-04-16 18:52:29,139 INFO    Thread-25 (_run_job):50181 [wandb_init.py:_log_setup():506] Logging user logs to /blue/hulcr/gmarais/Beetle_classifier/Train/wandb/run-20230416_185229-s9eaiyew/logs/debug.log
2023-04-16 18:52:29,139 INFO    Thread-25 (_run_job):50181 [wandb_init.py:_log_setup():507] Logging internal logs to /blue/hulcr/gmarais/Beetle_classifier/Train/wandb/run-20230416_185229-s9eaiyew/logs/debug-internal.log
2023-04-16 18:52:29,139 INFO    Thread-25 (_run_job):50181 [wandb_init.py:_jupyter_setup():452] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x2b8cde97bfd0>
2023-04-16 18:52:29,139 INFO    Thread-25 (_run_job):50181 [wandb_init.py:init():546] calling init triggers
2023-04-16 18:52:29,139 INFO    Thread-25 (_run_job):50181 [wandb_init.py:init():552] wandb.init called with sweep_config: {'batch_size': 128, 'epochs': 3, 'model_name': 'maxvit_rmlp_small_rw_224.sw_in1k', 'pretrained': True}
config: {}
2023-04-16 18:52:29,139 INFO    Thread-25 (_run_job):50181 [wandb_init.py:init():602] starting backend
2023-04-16 18:52:29,139 INFO    Thread-25 (_run_job):50181 [wandb_init.py:init():606] setting up manager
2023-04-16 18:52:29,145 INFO    Thread-25 (_run_job):50181 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-04-16 18:52:29,151 INFO    Thread-25 (_run_job):50181 [wandb_init.py:init():613] backend started and connected
2023-04-16 18:52:29,161 INFO    Thread-25 (_run_job):50181 [wandb_run.py:_config_callback():1251] config_cb None None {'batch_size': 128, 'epochs': 3, 'model_name': 'maxvit_rmlp_small_rw_224.sw_in1k', 'pretrained': True}
2023-04-16 18:52:29,163 INFO    Thread-25 (_run_job):50181 [wandb_run.py:_label_probe_notebook():1204] probe notebook
2023-04-16 18:52:29,163 INFO    Thread-25 (_run_job):50181 [wandb_run.py:_label_probe_notebook():1214] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-04-16 18:52:29,163 INFO    Thread-25 (_run_job):50181 [wandb_init.py:init():701] updated telemetry
2023-04-16 18:52:29,175 INFO    Thread-25 (_run_job):50181 [wandb_init.py:init():741] communicating run to backend with 60.0 second timeout
2023-04-16 18:52:29,437 INFO    Thread-25 (_run_job):50181 [wandb_run.py:_on_init():2133] communicating current version
2023-04-16 18:52:29,530 INFO    Thread-25 (_run_job):50181 [wandb_run.py:_on_init():2142] got version response upgrade_message: "wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-04-16 18:52:29,530 INFO    Thread-25 (_run_job):50181 [wandb_init.py:init():789] starting run threads in backend
2023-04-16 18:52:30,683 INFO    Thread-25 (_run_job):50181 [wandb_run.py:_console_start():2114] atexit reg
2023-04-16 18:52:30,683 INFO    Thread-25 (_run_job):50181 [wandb_run.py:_redirect():1969] redirect: SettingsConsole.WRAP_RAW
2023-04-16 18:52:30,683 INFO    Thread-25 (_run_job):50181 [wandb_run.py:_redirect():2034] Wrapping output streams.
2023-04-16 18:52:30,684 INFO    Thread-25 (_run_job):50181 [wandb_run.py:_redirect():2059] Redirects installed.
2023-04-16 18:52:30,684 INFO    Thread-25 (_run_job):50181 [wandb_init.py:init():831] run started, returning control to user process
2023-04-16 18:52:37,963 INFO    Thread-25 (_run_job):50181 [wandb_run.py:_config_callback():1251] config_cb None None {'Learner': {'loss_func': {'eps': 0.1, 'weight': [0.6234290599822998, 1.5880335569381714, 2.46276593208313, 0.6430555582046509, 0.6523168683052063, 1.5583395957946777, 1.7479026317596436, 1.24165678024292, 1.3511673212051392, 0.6662935614585876, 1.1912521123886108, 0.8528448343276978], 'reduction': 'mean', '_name': 'LabelSmoothingCrossEntropy()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.vision.learner.default_split', 'metrics': ['fastai.metrics.error_rate', 'fastai.metrics.accuracy', 'fastai.metrics.top_k_accuracy'], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, 'arch': 'maxvit_rmlp_small_rw_224.sw_in1k', 'normalize': True, 'n_out': 12, 'pretrained': True, '_name': '<fastai.learner.Learner object at 0x2b8cdf413a60>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'MixedPrecision': True, 'ShowGraphCallback': True, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': 'all', 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'ParamScheduler': True, 'n_inp': 1, 'input 1 dim 1': 128, 'input 1 dim 2': 3, 'input 1 dim 3': 224, 'input 1 dim 4': 224, 'batch size': 128, 'batch per epoch': 195, 'model parameters': 64922716, 'device': 'cuda', 'frozen': True, 'frozen idx': 1, 'dataset.tfms': "[Pipeline: PILBase.create, Pipeline: parent_label -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}]", 'dls.after_item': "Pipeline: Resize -- {'size': (224, 224), 'method': 'pad', 'pad_mode': 'zeros', 'resamples': (<Resampling.BILINEAR: 2>, <Resampling.NEAREST: 0>), 'p': 1.0} -> ToTensor", 'dls.before_batch': 'Pipeline: ', 'dls.after_batch': "Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.5000]],\n\n         [[0.5000]],\n\n         [[0.5000]]]], device='cuda:0'), 'std': tensor([[[[0.5000]],\n\n         [[0.5000]],\n\n         [[0.5000]]]], device='cuda:0'), 'axes': (0, 2, 3)}"}
2023-04-16 18:54:16,935 INFO    Thread-25 (_run_job):50181 [wandb_run.py:_config_callback():1251] config_cb None None {'Learner': {'loss_func': {'eps': 0.1, 'weight': [0.6234290599822998, 1.5880335569381714, 2.46276593208313, 0.6430555582046509, 0.6523168683052063, 1.5583395957946777, 1.7479026317596436, 1.24165678024292, 1.3511673212051392, 0.6662935614585876, 1.1912521123886108, 0.8528448343276978], 'reduction': 'mean', '_name': {'eps': 0.1, 'weight': [0.6234290599822998, 1.5880335569381714, 2.46276593208313, 0.6430555582046509, 0.6523168683052063, 1.5583395957946777, 1.7479026317596436, 1.24165678024292, 1.3511673212051392, 0.6662935614585876, 1.1912521123886108, 0.8528448343276978], 'reduction': 'mean', '_name': 'LabelSmoothingCrossEntropy()'}}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.vision.learner.default_split', 'metrics': ['fastai.metrics.error_rate', 'fastai.metrics.accuracy', 'fastai.metrics.top_k_accuracy'], 'path': '.', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, 'arch': 'maxvit_rmlp_small_rw_224.sw_in1k', 'normalize': True, 'n_out': 12, 'pretrained': True, '_name': '<fastai.learner.Learner object at 0x2b8cdf413a60>'}, 'TrainEvalCallback': True, 'CastToTensor': True, 'ProgressCallback': True, 'MixedPrecision': True, 'ShowGraphCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'SaveModelCallback': {'fname': 'model', 'every_epoch': False, 'at_end': False, 'with_opt': False}, 'WandbCallback': {'log': 'all', 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'ParamScheduler': True, 'n_inp': 1, 'input 1 dim 1': 128, 'input 1 dim 2': 3, 'input 1 dim 3': 224, 'input 1 dim 4': 224, 'batch size': 128, 'batch per epoch': 195, 'model parameters': 64922716, 'device': 'cuda', 'frozen': False, 'frozen idx': 0, 'dataset.tfms': "[Pipeline: PILBase.create, Pipeline: parent_label -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}]", 'dls.after_item': "Pipeline: Resize -- {'size': (224, 224), 'method': 'pad', 'pad_mode': 'zeros', 'resamples': (<Resampling.BILINEAR: 2>, <Resampling.NEAREST: 0>), 'p': 1.0} -> ToTensor", 'dls.before_batch': 'Pipeline: ', 'dls.after_batch': "Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.5000]],\n\n         [[0.5000]],\n\n         [[0.5000]]]], device='cuda:0'), 'std': tensor([[[[0.5000]],\n\n         [[0.5000]],\n\n         [[0.5000]]]], device='cuda:0'), 'axes': (0, 2, 3)}"}
2023-04-16 19:00:00,671 INFO    Thread-25 (_run_job):50181 [wandb_run.py:_finish():1854] finishing run christopher-marais/Ambrosia_Symbiosis/s9eaiyew
2023-04-16 19:00:01,141 INFO    Thread-25 (_run_job):50181 [jupyter.py:save_history():474] saving 4 cells to _session_history.ipynb
2023-04-16 19:00:01,161 INFO    Thread-25 (_run_job):50181 [wandb_run.py:_config_callback():1251] config_cb ('_wandb', 'session_history') code/_session_history.ipynb None
2023-04-16 19:00:01,350 INFO    Thread-25 (_run_job):50181 [jupyter.py:_save_ipynb():384] looking for notebook: None
2023-04-16 19:00:01,350 INFO    Thread-25 (_run_job):50181 [wandb_init.py:_jupyter_teardown():434] cleaning up jupyter logic
2023-04-16 19:00:01,351 INFO    Thread-25 (_run_job):50181 [wandb_run.py:_atexit_cleanup():2083] got exitcode: 0
2023-04-16 19:00:01,351 INFO    Thread-25 (_run_job):50181 [wandb_run.py:_restore():2066] restore
2023-04-16 19:00:01,351 INFO    Thread-25 (_run_job):50181 [wandb_run.py:_restore():2072] restore done
2023-04-16 19:00:11,494 INFO    Thread-25 (_run_job):50181 [wandb_run.py:_footer_history_summary_info():3422] rendering history
2023-04-16 19:00:11,495 INFO    Thread-25 (_run_job):50181 [wandb_run.py:_footer_history_summary_info():3454] rendering summary
2023-04-16 19:00:11,500 INFO    Thread-25 (_run_job):50181 [wandb_run.py:_footer_sync_info():3380] logging synced files
