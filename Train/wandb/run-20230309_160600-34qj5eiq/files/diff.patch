diff --git a/Train/.ipynb_checkpoints/timm_FastAI_WANDB-checkpoint.ipynb b/Train/.ipynb_checkpoints/timm_FastAI_WANDB-checkpoint.ipynb
index ad480ea..6ecf6f9 100644
--- a/Train/.ipynb_checkpoints/timm_FastAI_WANDB-checkpoint.ipynb
+++ b/Train/.ipynb_checkpoints/timm_FastAI_WANDB-checkpoint.ipynb
@@ -2,15 +2,15 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 12,
    "id": "436f1771-7aa6-45e7-abae-56c8112da143",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-09T17:03:52.351536Z",
-     "iopub.status.busy": "2023-03-09T17:03:52.351536Z",
-     "iopub.status.idle": "2023-03-09T17:03:57.156787Z",
-     "shell.execute_reply": "2023-03-09T17:03:57.155788Z",
-     "shell.execute_reply.started": "2023-03-09T17:03:52.351536Z"
+     "iopub.execute_input": "2023-03-09T21:04:11.839205Z",
+     "iopub.status.busy": "2023-03-09T21:04:11.838205Z",
+     "iopub.status.idle": "2023-03-09T21:04:11.857198Z",
+     "shell.execute_reply": "2023-03-09T21:04:11.856205Z",
+     "shell.execute_reply.started": "2023-03-09T21:04:11.839205Z"
     },
     "tags": []
    },
@@ -18,7 +18,9 @@
    "source": [
     "from urllib.request import urlopen\n",
     "from PIL import Image\n",
-    "import timm"
+    "import timm\n",
+    "import torch\n",
+    "import wandb"
    ]
   },
   {
@@ -53,1936 +55,15 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
-   "id": "ce6dcd5a-212a-4a26-ab87-8ab81952aec4",
-   "metadata": {
-    "collapsed": true,
-    "execution": {
-     "iopub.execute_input": "2023-03-09T17:06:06.091074Z",
-     "iopub.status.busy": "2023-03-09T17:06:06.091074Z",
-     "iopub.status.idle": "2023-03-09T17:37:25.330060Z",
-     "shell.execute_reply": "2023-03-09T17:37:25.329053Z",
-     "shell.execute_reply.started": "2023-03-09T17:06:06.091074Z"
-    },
-    "jupyter": {
-     "outputs_hidden": true
-    },
-    "tags": []
-   },
-   "outputs": [
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "6028ebec30904d63a0b5577fa37e86e5",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "Downloading (â€¦)\"pytorch_model.bin\";:   0%|          | 0.00/1.90G [00:00<?, ?B/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/plain": [
-       "MaxxVit(\n",
-       "  (stem): Stem(\n",
-       "    (conv1): Conv2dSame(3, 192, kernel_size=(3, 3), stride=(2, 2))\n",
-       "    (norm1): BatchNormAct2d(\n",
-       "      192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "      (drop): Identity()\n",
-       "      (act): GELUTanh()\n",
-       "    )\n",
-       "    (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
-       "  )\n",
-       "  (stages): Sequential(\n",
-       "    (0): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Identity()\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(768, 768, kernel_size=(3, 3), stride=(2, 2), groups=768, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "    (1): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(192, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(1536, 1536, kernel_size=(3, 3), stride=(2, 2), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (2): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (3): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (4): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (5): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "    (2): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(3072, 3072, kernel_size=(3, 3), stride=(2, 2), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (2): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (3): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (4): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (5): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (6): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (7): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (8): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (9): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (10): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (11): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (12): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (13): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "    (3): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(6144, 6144, kernel_size=(3, 3), stride=(2, 2), groups=6144, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(6144, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(384, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(1536, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6144, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(6144, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(384, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "  )\n",
-       "  (norm): Identity()\n",
-       "  (head): NormMlpClassifierHead(\n",
-       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
-       "    (norm): LayerNorm2d((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
-       "    (pre_logits): Sequential(\n",
-       "      (fc): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "      (act): Tanh()\n",
-       "    )\n",
-       "    (drop): Dropout(p=0.0, inplace=False)\n",
-       "    (fc): Linear(in_features=1536, out_features=1000, bias=True)\n",
-       "  )\n",
-       ")"
-      ]
-     },
-     "execution_count": 4,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "timm.create_model(\"maxvit_xlarge_tf_512.in21k_ft_in1k\", pretrained=True)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 7,
    "id": "af673a5e-c94b-4ff2-ad5a-af508a10ca18",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-09T17:46:56.585226Z",
-     "iopub.status.busy": "2023-03-09T17:46:56.585226Z"
+     "iopub.execute_input": "2023-03-09T20:58:44.771839Z",
+     "iopub.status.busy": "2023-03-09T20:58:44.771839Z",
+     "iopub.status.idle": "2023-03-09T20:59:08.057797Z",
+     "shell.execute_reply": "2023-03-09T20:59:08.056793Z",
+     "shell.execute_reply.started": "2023-03-09T20:58:44.771839Z"
     },
     "tags": []
    },
@@ -2003,6 +84,36 @@
     "top5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)"
    ]
   },
+  {
+   "cell_type": "code",
+   "execution_count": 9,
+   "id": "84062f31-1f5e-413a-b6ac-06f9a8a03a6e",
+   "metadata": {
+    "execution": {
+     "iopub.execute_input": "2023-03-09T20:59:43.880549Z",
+     "iopub.status.busy": "2023-03-09T20:59:43.879588Z",
+     "iopub.status.idle": "2023-03-09T20:59:43.887561Z",
+     "shell.execute_reply": "2023-03-09T20:59:43.886564Z",
+     "shell.execute_reply.started": "2023-03-09T20:59:43.880549Z"
+    },
+    "tags": []
+   },
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "tensor([[967, 968, 504, 415, 969]])"
+      ]
+     },
+     "execution_count": 9,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "top5_class_indices"
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": 3,
@@ -2067,9 +178,17 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 10,
    "id": "fd1e36e7-6131-4ad7-a7cc-3e825b391108",
-   "metadata": {},
+   "metadata": {
+    "execution": {
+     "iopub.execute_input": "2023-03-09T21:00:07.468450Z",
+     "iopub.status.busy": "2023-03-09T21:00:07.468450Z",
+     "iopub.status.idle": "2023-03-09T21:00:12.641093Z",
+     "shell.execute_reply": "2023-03-09T21:00:12.640112Z",
+     "shell.execute_reply.started": "2023-03-09T21:00:07.468450Z"
+    }
+   },
    "outputs": [],
    "source": [
     "from fastai.vision.all import *\n",
@@ -2090,10 +209,32 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 13,
    "id": "28c79cc5-2685-4d40-8b07-7a79e00ade9c",
-   "metadata": {},
-   "outputs": [],
+   "metadata": {
+    "execution": {
+     "iopub.execute_input": "2023-03-09T21:04:16.284817Z",
+     "iopub.status.busy": "2023-03-09T21:04:16.283806Z",
+     "iopub.status.idle": "2023-03-09T21:04:16.776013Z",
+     "shell.execute_reply": "2023-03-09T21:04:16.775006Z",
+     "shell.execute_reply.started": "2023-03-09T21:04:16.284817Z"
+    },
+    "tags": []
+   },
+   "outputs": [
+    {
+     "ename": "NameError",
+     "evalue": "name 'PROJECT' is not defined",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
+      "Cell \u001b[1;32mIn[13], line 20\u001b[0m\n\u001b[0;32m     15\u001b[0m         learn \u001b[38;5;241m=\u001b[39m vision_learner(dls, config\u001b[38;5;241m.\u001b[39mmodel_name, metrics\u001b[38;5;241m=\u001b[39merror_rate, \n\u001b[0;32m     16\u001b[0m                                cbs\u001b[38;5;241m=\u001b[39mcbs, pretrained\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretrained)\n\u001b[0;32m     17\u001b[0m         learn\u001b[38;5;241m.\u001b[39mfine_tune(config\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
+      "Cell \u001b[1;32mIn[13], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain the model using the supplied config\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m dls \u001b[38;5;241m=\u001b[39m get_pets(config\u001b[38;5;241m.\u001b[39mbatch_size, config\u001b[38;5;241m.\u001b[39mimg_size, config\u001b[38;5;241m.\u001b[39mseed)\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[43mPROJECT\u001b[49m, group\u001b[38;5;241m=\u001b[39mGROUP, job_type\u001b[38;5;241m=\u001b[39mJOB_TYPE, config\u001b[38;5;241m=\u001b[39mconfig):\n\u001b[0;32m     14\u001b[0m     cbs \u001b[38;5;241m=\u001b[39m [MixedPrecision(), WandbCallback(log_preds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[0;32m     15\u001b[0m     learn \u001b[38;5;241m=\u001b[39m vision_learner(dls, config\u001b[38;5;241m.\u001b[39mmodel_name, metrics\u001b[38;5;241m=\u001b[39merror_rate, \n\u001b[0;32m     16\u001b[0m                            cbs\u001b[38;5;241m=\u001b[39mcbs, pretrained\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretrained)\n",
+      "\u001b[1;31mNameError\u001b[0m: name 'PROJECT' is not defined"
+     ]
+    }
+   ],
    "source": [
     "config = SimpleNamespace(\n",
     "    batch_size=64,\n",
@@ -2107,7 +248,7 @@
     "def train(config):\n",
     "    \"Train the model using the supplied config\"\n",
     "    dls = get_pets(config.batch_size, config.img_size, config.seed)\n",
-    "    with wandb.init(project=PROJECT, group=GROUP, job_type=JOB_TYPE, config=config):\n",
+    "    with wandb.init(project=\"PROJECT\", group='', job_type='JOB_TYPE', config=config):\n",
     "        cbs = [MixedPrecision(), WandbCallback(log_preds=False)]\n",
     "        learn = vision_learner(dls, config.model_name, metrics=error_rate, \n",
     "                               cbs=cbs, pretrained=config.pretrained)\n",
diff --git a/Train/timm_FastAI_WANDB.ipynb b/Train/timm_FastAI_WANDB.ipynb
index e6b260f..6ecf6f9 100644
--- a/Train/timm_FastAI_WANDB.ipynb
+++ b/Train/timm_FastAI_WANDB.ipynb
@@ -2,15 +2,15 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 12,
    "id": "436f1771-7aa6-45e7-abae-56c8112da143",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-09T17:03:52.351536Z",
-     "iopub.status.busy": "2023-03-09T17:03:52.351536Z",
-     "iopub.status.idle": "2023-03-09T17:03:57.156787Z",
-     "shell.execute_reply": "2023-03-09T17:03:57.155788Z",
-     "shell.execute_reply.started": "2023-03-09T17:03:52.351536Z"
+     "iopub.execute_input": "2023-03-09T21:04:11.839205Z",
+     "iopub.status.busy": "2023-03-09T21:04:11.838205Z",
+     "iopub.status.idle": "2023-03-09T21:04:11.857198Z",
+     "shell.execute_reply": "2023-03-09T21:04:11.856205Z",
+     "shell.execute_reply.started": "2023-03-09T21:04:11.839205Z"
     },
     "tags": []
    },
@@ -18,7 +18,9 @@
    "source": [
     "from urllib.request import urlopen\n",
     "from PIL import Image\n",
-    "import timm"
+    "import timm\n",
+    "import torch\n",
+    "import wandb"
    ]
   },
   {
@@ -53,1955 +55,19 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
-   "id": "ce6dcd5a-212a-4a26-ab87-8ab81952aec4",
-   "metadata": {
-    "collapsed": true,
-    "execution": {
-     "iopub.execute_input": "2023-03-09T17:06:06.091074Z",
-     "iopub.status.busy": "2023-03-09T17:06:06.091074Z",
-     "iopub.status.idle": "2023-03-09T17:37:25.330060Z",
-     "shell.execute_reply": "2023-03-09T17:37:25.329053Z",
-     "shell.execute_reply.started": "2023-03-09T17:06:06.091074Z"
-    },
-    "jupyter": {
-     "outputs_hidden": true
-    },
-    "tags": []
-   },
-   "outputs": [
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "6028ebec30904d63a0b5577fa37e86e5",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "Downloading (â€¦)\"pytorch_model.bin\";:   0%|          | 0.00/1.90G [00:00<?, ?B/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/plain": [
-       "MaxxVit(\n",
-       "  (stem): Stem(\n",
-       "    (conv1): Conv2dSame(3, 192, kernel_size=(3, 3), stride=(2, 2))\n",
-       "    (norm1): BatchNormAct2d(\n",
-       "      192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "      (drop): Identity()\n",
-       "      (act): GELUTanh()\n",
-       "    )\n",
-       "    (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
-       "  )\n",
-       "  (stages): Sequential(\n",
-       "    (0): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Identity()\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(768, 768, kernel_size=(3, 3), stride=(2, 2), groups=768, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "    (1): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(192, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(1536, 1536, kernel_size=(3, 3), stride=(2, 2), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (2): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (3): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (4): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (5): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "    (2): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(3072, 3072, kernel_size=(3, 3), stride=(2, 2), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (2): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (3): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (4): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (5): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (6): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (7): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (8): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (9): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (10): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (11): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (12): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (13): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "    (3): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(6144, 6144, kernel_size=(3, 3), stride=(2, 2), groups=6144, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(6144, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(384, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(1536, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6144, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(6144, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(384, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "  )\n",
-       "  (norm): Identity()\n",
-       "  (head): NormMlpClassifierHead(\n",
-       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
-       "    (norm): LayerNorm2d((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
-       "    (pre_logits): Sequential(\n",
-       "      (fc): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "      (act): Tanh()\n",
-       "    )\n",
-       "    (drop): Dropout(p=0.0, inplace=False)\n",
-       "    (fc): Linear(in_features=1536, out_features=1000, bias=True)\n",
-       "  )\n",
-       ")"
-      ]
-     },
-     "execution_count": 4,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "timm.create_model(\"maxvit_xlarge_tf_512.in21k_ft_in1k\", pretrained=True)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 7,
    "id": "af673a5e-c94b-4ff2-ad5a-af508a10ca18",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-09T17:46:56.585226Z",
-     "iopub.status.busy": "2023-03-09T17:46:56.585226Z",
-     "iopub.status.idle": "2023-03-09T17:47:24.408985Z",
-     "shell.execute_reply": "2023-03-09T17:47:24.407985Z",
-     "shell.execute_reply.started": "2023-03-09T17:46:56.585226Z"
+     "iopub.execute_input": "2023-03-09T20:58:44.771839Z",
+     "iopub.status.busy": "2023-03-09T20:58:44.771839Z",
+     "iopub.status.idle": "2023-03-09T20:59:08.057797Z",
+     "shell.execute_reply": "2023-03-09T20:59:08.056793Z",
+     "shell.execute_reply.started": "2023-03-09T20:58:44.771839Z"
     },
     "tags": []
    },
-   "outputs": [
-    {
-     "ename": "NameError",
-     "evalue": "name 'torch' is not defined",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
-      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m transforms \u001b[38;5;241m=\u001b[39m timm\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcreate_transform(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata_config, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m output \u001b[38;5;241m=\u001b[39m model(transforms(img)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))  \u001b[38;5;66;03m# unsqueeze single image into batch of 1\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m top5_probabilities, top5_class_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mtopk(output\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
-      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "img = Image.open(\n",
     "    urlopen('https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'))\n",
@@ -2018,6 +84,36 @@
     "top5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)"
    ]
   },
+  {
+   "cell_type": "code",
+   "execution_count": 9,
+   "id": "84062f31-1f5e-413a-b6ac-06f9a8a03a6e",
+   "metadata": {
+    "execution": {
+     "iopub.execute_input": "2023-03-09T20:59:43.880549Z",
+     "iopub.status.busy": "2023-03-09T20:59:43.879588Z",
+     "iopub.status.idle": "2023-03-09T20:59:43.887561Z",
+     "shell.execute_reply": "2023-03-09T20:59:43.886564Z",
+     "shell.execute_reply.started": "2023-03-09T20:59:43.880549Z"
+    },
+    "tags": []
+   },
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "tensor([[967, 968, 504, 415, 969]])"
+      ]
+     },
+     "execution_count": 9,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "top5_class_indices"
+   ]
+  },
   {
    "cell_type": "code",
    "execution_count": 3,
@@ -2082,9 +178,17 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 10,
    "id": "fd1e36e7-6131-4ad7-a7cc-3e825b391108",
-   "metadata": {},
+   "metadata": {
+    "execution": {
+     "iopub.execute_input": "2023-03-09T21:00:07.468450Z",
+     "iopub.status.busy": "2023-03-09T21:00:07.468450Z",
+     "iopub.status.idle": "2023-03-09T21:00:12.641093Z",
+     "shell.execute_reply": "2023-03-09T21:00:12.640112Z",
+     "shell.execute_reply.started": "2023-03-09T21:00:07.468450Z"
+    }
+   },
    "outputs": [],
    "source": [
     "from fastai.vision.all import *\n",
@@ -2105,10 +209,32 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 13,
    "id": "28c79cc5-2685-4d40-8b07-7a79e00ade9c",
-   "metadata": {},
-   "outputs": [],
+   "metadata": {
+    "execution": {
+     "iopub.execute_input": "2023-03-09T21:04:16.284817Z",
+     "iopub.status.busy": "2023-03-09T21:04:16.283806Z",
+     "iopub.status.idle": "2023-03-09T21:04:16.776013Z",
+     "shell.execute_reply": "2023-03-09T21:04:16.775006Z",
+     "shell.execute_reply.started": "2023-03-09T21:04:16.284817Z"
+    },
+    "tags": []
+   },
+   "outputs": [
+    {
+     "ename": "NameError",
+     "evalue": "name 'PROJECT' is not defined",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
+      "Cell \u001b[1;32mIn[13], line 20\u001b[0m\n\u001b[0;32m     15\u001b[0m         learn \u001b[38;5;241m=\u001b[39m vision_learner(dls, config\u001b[38;5;241m.\u001b[39mmodel_name, metrics\u001b[38;5;241m=\u001b[39merror_rate, \n\u001b[0;32m     16\u001b[0m                                cbs\u001b[38;5;241m=\u001b[39mcbs, pretrained\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretrained)\n\u001b[0;32m     17\u001b[0m         learn\u001b[38;5;241m.\u001b[39mfine_tune(config\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
+      "Cell \u001b[1;32mIn[13], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain the model using the supplied config\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m dls \u001b[38;5;241m=\u001b[39m get_pets(config\u001b[38;5;241m.\u001b[39mbatch_size, config\u001b[38;5;241m.\u001b[39mimg_size, config\u001b[38;5;241m.\u001b[39mseed)\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[43mPROJECT\u001b[49m, group\u001b[38;5;241m=\u001b[39mGROUP, job_type\u001b[38;5;241m=\u001b[39mJOB_TYPE, config\u001b[38;5;241m=\u001b[39mconfig):\n\u001b[0;32m     14\u001b[0m     cbs \u001b[38;5;241m=\u001b[39m [MixedPrecision(), WandbCallback(log_preds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[0;32m     15\u001b[0m     learn \u001b[38;5;241m=\u001b[39m vision_learner(dls, config\u001b[38;5;241m.\u001b[39mmodel_name, metrics\u001b[38;5;241m=\u001b[39merror_rate, \n\u001b[0;32m     16\u001b[0m                            cbs\u001b[38;5;241m=\u001b[39mcbs, pretrained\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretrained)\n",
+      "\u001b[1;31mNameError\u001b[0m: name 'PROJECT' is not defined"
+     ]
+    }
+   ],
    "source": [
     "config = SimpleNamespace(\n",
     "    batch_size=64,\n",
@@ -2122,7 +248,7 @@
     "def train(config):\n",
     "    \"Train the model using the supplied config\"\n",
     "    dls = get_pets(config.batch_size, config.img_size, config.seed)\n",
-    "    with wandb.init(project=PROJECT, group=GROUP, job_type=JOB_TYPE, config=config):\n",
+    "    with wandb.init(project=\"PROJECT\", group='', job_type='JOB_TYPE', config=config):\n",
     "        cbs = [MixedPrecision(), WandbCallback(log_preds=False)]\n",
     "        learn = vision_learner(dls, config.model_name, metrics=error_rate, \n",
     "                               cbs=cbs, pretrained=config.pretrained)\n",
