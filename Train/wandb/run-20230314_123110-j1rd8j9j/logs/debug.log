2023-03-14 12:31:10,811 INFO    MainThread:15648 [wandb_setup.py:_flush():68] Configure stats pid to 15648
2023-03-14 12:31:10,811 INFO    MainThread:15648 [wandb_setup.py:_flush():68] Loading settings from C:\Users\GCM\.config\wandb\settings
2023-03-14 12:31:10,811 INFO    MainThread:15648 [wandb_setup.py:_flush():68] Loading settings from E:\GIT_REPOS\Beetle_classifier\Train\wandb\settings
2023-03-14 12:31:10,811 INFO    MainThread:15648 [wandb_setup.py:_flush():68] Loading settings from environment variables: {'_require_service': 'True'}
2023-03-14 12:31:10,811 INFO    MainThread:15648 [wandb_setup.py:_flush():68] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-03-14 12:31:10,812 INFO    MainThread:15648 [wandb_init.py:_log_setup():492] Logging user logs to E:\GIT_REPOS\Beetle_classifier\Train\wandb\run-20230314_123110-j1rd8j9j\logs\debug.log
2023-03-14 12:31:10,812 INFO    MainThread:15648 [wandb_init.py:_log_setup():493] Logging internal logs to E:\GIT_REPOS\Beetle_classifier\Train\wandb\run-20230314_123110-j1rd8j9j\logs\debug-internal.log
2023-03-14 12:31:10,812 INFO    MainThread:15648 [wandb_init.py:_jupyter_setup():438] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x000001F1360AFE20>
2023-03-14 12:31:10,813 INFO    MainThread:15648 [wandb_init.py:init():532] calling init triggers
2023-03-14 12:31:10,813 INFO    MainThread:15648 [wandb_init.py:init():538] wandb.init called with sweep_config: {}
config: {'batch_size': 8, 'img_size': 224, 'seed': 42, 'pretrained': True, 'model_name': 'maxvit_rmlp_small_rw_224.sw_in1k', 'epochs': 3}
2023-03-14 12:31:10,813 INFO    MainThread:15648 [wandb_init.py:init():588] starting backend
2023-03-14 12:31:10,813 INFO    MainThread:15648 [wandb_init.py:init():592] setting up manager
2023-03-14 12:31:10,830 INFO    MainThread:15648 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=spawn, using: spawn
2023-03-14 12:31:10,834 INFO    MainThread:15648 [wandb_init.py:init():599] backend started and connected
2023-03-14 12:31:10,846 INFO    MainThread:15648 [wandb_run.py:_label_probe_notebook():1203] probe notebook
2023-03-14 12:31:10,849 INFO    MainThread:15648 [wandb_run.py:_label_probe_notebook():1213] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-03-14 12:31:10,849 INFO    MainThread:15648 [wandb_init.py:init():687] updated telemetry
2023-03-14 12:31:10,910 INFO    MainThread:15648 [wandb_init.py:init():727] communicating run to backend with 60.0 second timeout
2023-03-14 12:31:11,359 INFO    MainThread:15648 [wandb_run.py:_on_init():2134] communicating current version
2023-03-14 12:31:11,520 INFO    MainThread:15648 [wandb_run.py:_on_init():2143] got version response upgrade_message: "wandb version 0.13.11 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-03-14 12:31:11,520 INFO    MainThread:15648 [wandb_init.py:init():775] starting run threads in backend
2023-03-14 12:31:12,041 INFO    MainThread:15648 [wandb_run.py:_console_start():2114] atexit reg
2023-03-14 12:31:12,041 INFO    MainThread:15648 [wandb_run.py:_redirect():1969] redirect: SettingsConsole.WRAP_RAW
2023-03-14 12:31:12,041 INFO    MainThread:15648 [wandb_run.py:_redirect():2034] Wrapping output streams.
2023-03-14 12:31:12,041 INFO    MainThread:15648 [wandb_run.py:_redirect():2059] Redirects installed.
2023-03-14 12:31:12,042 INFO    MainThread:15648 [wandb_init.py:init():817] run started, returning control to user process
2023-03-14 12:31:14,756 INFO    MainThread:15648 [wandb_run.py:_config_callback():1250] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.vision.learner.default_split', 'metrics': ['fastai.metrics.error_rate', 'fastai.metrics.accuracy'], 'path': 'F:\\selected_images\\train', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, 'arch': 'maxvit_rmlp_small_rw_224.sw_in1k', 'normalize': True, 'n_out': 10, 'pretrained': True, '_name': '<fastai.learner.Learner object at 0x000001F19BAC6CE0>'}, 'TrainEvalCallback': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'CastToTensor': True, 'ProgressCallback': True, 'MixedPrecision': True, 'WandbCallback': {'log': 'all', 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'ParamScheduler': True, 'n_inp': 1, 'input 1 dim 1': 8, 'input 1 dim 2': 3, 'input 1 dim 3': 224, 'input 1 dim 4': 224, 'batch size': 8, 'batch per epoch': 2459, 'model parameters': 64921692, 'device': 'cuda', 'frozen': True, 'frozen idx': 1, 'dataset.tfms': "[Pipeline: PILBase.create, Pipeline: partial -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}]", 'dls.after_item': "Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (<Resampling.BILINEAR: 2>, <Resampling.NEAREST: 0>), 'p': 1.0} -> ToTensor", 'dls.before_batch': 'Pipeline: ', 'dls.after_batch': "Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.5000]],\n\n         [[0.5000]],\n\n         [[0.5000]]]], device='cuda:0'), 'std': tensor([[[[0.5000]],\n\n         [[0.5000]],\n\n         [[0.5000]]]], device='cuda:0'), 'axes': (0, 2, 3)}"}
2023-03-14 12:31:14,759 INFO    MainThread:15648 [wandb_watch.py:watch():51] Watching
2023-03-14 12:45:34,697 INFO    MainThread:15648 [wandb_run.py:_config_callback():1250] config_cb None None {'Learner': {'loss_func': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': {'axis': -1, 'flatten': True, 'floatify': False, 'is_2d': True, '_name': 'FlattenedLoss of CrossEntropyLoss()'}}, 'opt_func': 'fastai.optimizer.Adam', 'lr': 0.001, 'splitter': 'fastai.vision.learner.default_split', 'metrics': ['fastai.metrics.error_rate', 'fastai.metrics.accuracy'], 'path': 'F:\\selected_images\\train', 'model_dir': 'models', 'wd': None, 'wd_bn_bias': False, 'train_bn': True, 'moms': [0.95, 0.85, 0.95], 'default_cbs': True, 'arch': 'maxvit_rmlp_small_rw_224.sw_in1k', 'normalize': True, 'n_out': 10, 'pretrained': True, '_name': '<fastai.learner.Learner object at 0x000001F19BAC6CE0>'}, 'TrainEvalCallback': True, 'CastToTensor': True, 'ProgressCallback': True, 'MixedPrecision': True, 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True}, 'WandbCallback': {'log': 'all', 'log_preds': True, 'log_preds_every_epoch': False, 'log_model': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'valid_dl': None, 'n_preds': 36, 'seed': 12345, 'reorder': True}, 'ParamScheduler': True, 'n_inp': 1, 'input 1 dim 1': 8, 'input 1 dim 2': 3, 'input 1 dim 3': 224, 'input 1 dim 4': 224, 'batch size': 8, 'batch per epoch': 2459, 'model parameters': 64921692, 'device': 'cuda', 'frozen': False, 'frozen idx': 0, 'dataset.tfms': "[Pipeline: PILBase.create, Pipeline: partial -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}]", 'dls.after_item': "Pipeline: Resize -- {'size': (224, 224), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (<Resampling.BILINEAR: 2>, <Resampling.NEAREST: 0>), 'p': 1.0} -> ToTensor", 'dls.before_batch': 'Pipeline: ', 'dls.after_batch': "Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.5000]],\n\n         [[0.5000]],\n\n         [[0.5000]]]], device='cuda:0'), 'std': tensor([[[[0.5000]],\n\n         [[0.5000]],\n\n         [[0.5000]]]], device='cuda:0'), 'axes': (0, 2, 3)}"}
2023-03-14 13:31:10,770 INFO    MainThread:15648 [wandb_run.py:_finish():1854] finishing run christopher-marais/PROJECT/j1rd8j9j
2023-03-14 13:31:14,980 INFO    MainThread:15648 [jupyter.py:_save_ipynb():390] looking for notebook: GIT_REPOS/Beetle_classifier/Train/Train.ipynb
2023-03-14 13:31:14,980 INFO    MainThread:15648 [wandb_init.py:_pause_backend():403] pausing backend
2023-03-14 14:36:25,300 INFO    MainThread:15648 [wandb_init.py:_resume_backend():408] resuming backend
2023-03-14 14:36:25,305 INFO    MainThread:15648 [jupyter.py:_save_ipynb():390] looking for notebook: GIT_REPOS/Beetle_classifier/Train/Train.ipynb
2023-03-14 14:36:25,305 INFO    MainThread:15648 [wandb_init.py:_pause_backend():403] pausing backend
2023-03-14 14:37:30,839 INFO    MainThread:15648 [wandb_init.py:_resume_backend():408] resuming backend
2023-03-14 14:37:30,841 INFO    MainThread:15648 [jupyter.py:_save_ipynb():390] looking for notebook: GIT_REPOS/Beetle_classifier/Train/Train.ipynb
2023-03-14 14:37:30,842 INFO    MainThread:15648 [wandb_init.py:_pause_backend():403] pausing backend
2023-03-14 14:50:08,763 WARNING MsgRouterThr:15648 [router.py:message_loop():77] message_loop has been closed
