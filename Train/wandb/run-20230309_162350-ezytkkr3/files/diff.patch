diff --git a/Train/.ipynb_checkpoints/timm_FastAI_WANDB-checkpoint.ipynb b/Train/.ipynb_checkpoints/timm_FastAI_WANDB-checkpoint.ipynb
index ad480ea..970f9cf 100644
--- a/Train/.ipynb_checkpoints/timm_FastAI_WANDB-checkpoint.ipynb
+++ b/Train/.ipynb_checkpoints/timm_FastAI_WANDB-checkpoint.ipynb
@@ -2,15 +2,15 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 23,
    "id": "436f1771-7aa6-45e7-abae-56c8112da143",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-09T17:03:52.351536Z",
-     "iopub.status.busy": "2023-03-09T17:03:52.351536Z",
-     "iopub.status.idle": "2023-03-09T17:03:57.156787Z",
-     "shell.execute_reply": "2023-03-09T17:03:57.155788Z",
-     "shell.execute_reply.started": "2023-03-09T17:03:52.351536Z"
+     "iopub.execute_input": "2023-03-09T21:22:26.137388Z",
+     "iopub.status.busy": "2023-03-09T21:22:26.137388Z",
+     "iopub.status.idle": "2023-03-09T21:22:26.175369Z",
+     "shell.execute_reply": "2023-03-09T21:22:26.174371Z",
+     "shell.execute_reply.started": "2023-03-09T21:22:26.137388Z"
     },
     "tags": []
    },
@@ -18,20 +18,24 @@
    "source": [
     "from urllib.request import urlopen\n",
     "from PIL import Image\n",
-    "import timm"
+    "import timm\n",
+    "import torch\n",
+    "import wandb\n",
+    "import fastai\n",
+    "from fastai.callback.wandb import WandbCallback"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": 19,
    "id": "5a8980b5-f22c-4e50-bb9f-8ade0c9583cc",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-09T17:03:57.158793Z",
-     "iopub.status.busy": "2023-03-09T17:03:57.158793Z",
-     "iopub.status.idle": "2023-03-09T17:03:57.172789Z",
-     "shell.execute_reply": "2023-03-09T17:03:57.171788Z",
-     "shell.execute_reply.started": "2023-03-09T17:03:57.158793Z"
+     "iopub.execute_input": "2023-03-09T21:19:18.406370Z",
+     "iopub.status.busy": "2023-03-09T21:19:18.405369Z",
+     "iopub.status.idle": "2023-03-09T21:19:18.419374Z",
+     "shell.execute_reply": "2023-03-09T21:19:18.418369Z",
+     "shell.execute_reply.started": "2023-03-09T21:19:18.406370Z"
     },
     "tags": []
    },
@@ -39,1968 +43,47 @@
     {
      "data": {
       "text/plain": [
-       "'0.8.15dev0'"
+       "'2.7.11'"
       ]
      },
-     "execution_count": 2,
+     "execution_count": 19,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
-    "timm.__version__"
+    "fastai.__version__"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
-   "id": "ce6dcd5a-212a-4a26-ab87-8ab81952aec4",
-   "metadata": {
-    "collapsed": true,
-    "execution": {
-     "iopub.execute_input": "2023-03-09T17:06:06.091074Z",
-     "iopub.status.busy": "2023-03-09T17:06:06.091074Z",
-     "iopub.status.idle": "2023-03-09T17:37:25.330060Z",
-     "shell.execute_reply": "2023-03-09T17:37:25.329053Z",
-     "shell.execute_reply.started": "2023-03-09T17:06:06.091074Z"
-    },
-    "jupyter": {
-     "outputs_hidden": true
-    },
-    "tags": []
-   },
-   "outputs": [
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "6028ebec30904d63a0b5577fa37e86e5",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "Downloading (â€¦)\"pytorch_model.bin\";:   0%|          | 0.00/1.90G [00:00<?, ?B/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/plain": [
-       "MaxxVit(\n",
-       "  (stem): Stem(\n",
-       "    (conv1): Conv2dSame(3, 192, kernel_size=(3, 3), stride=(2, 2))\n",
-       "    (norm1): BatchNormAct2d(\n",
-       "      192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "      (drop): Identity()\n",
-       "      (act): GELUTanh()\n",
-       "    )\n",
-       "    (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
-       "  )\n",
-       "  (stages): Sequential(\n",
-       "    (0): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Identity()\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(768, 768, kernel_size=(3, 3), stride=(2, 2), groups=768, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "    (1): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(192, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(1536, 1536, kernel_size=(3, 3), stride=(2, 2), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (2): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (3): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (4): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (5): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "    (2): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(3072, 3072, kernel_size=(3, 3), stride=(2, 2), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (2): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (3): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (4): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (5): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (6): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (7): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (8): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (9): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (10): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (11): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (12): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (13): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "    (3): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(6144, 6144, kernel_size=(3, 3), stride=(2, 2), groups=6144, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(6144, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(384, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(1536, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6144, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(6144, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(384, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "  )\n",
-       "  (norm): Identity()\n",
-       "  (head): NormMlpClassifierHead(\n",
-       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
-       "    (norm): LayerNorm2d((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
-       "    (pre_logits): Sequential(\n",
-       "      (fc): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "      (act): Tanh()\n",
-       "    )\n",
-       "    (drop): Dropout(p=0.0, inplace=False)\n",
-       "    (fc): Linear(in_features=1536, out_features=1000, bias=True)\n",
-       "  )\n",
-       ")"
-      ]
-     },
-     "execution_count": 4,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "timm.create_model(\"maxvit_xlarge_tf_512.in21k_ft_in1k\", pretrained=True)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 7,
    "id": "af673a5e-c94b-4ff2-ad5a-af508a10ca18",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-09T17:46:56.585226Z",
-     "iopub.status.busy": "2023-03-09T17:46:56.585226Z"
+     "iopub.execute_input": "2023-03-09T20:58:44.771839Z",
+     "iopub.status.busy": "2023-03-09T20:58:44.771839Z",
+     "iopub.status.idle": "2023-03-09T20:59:08.057797Z",
+     "shell.execute_reply": "2023-03-09T20:59:08.056793Z",
+     "shell.execute_reply.started": "2023-03-09T20:58:44.771839Z"
     },
     "tags": []
    },
    "outputs": [],
    "source": [
-    "img = Image.open(\n",
-    "    urlopen('https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'))\n",
+    "# img = Image.open(\n",
+    "#     urlopen('https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'))\n",
     "\n",
-    "model = timm.create_model('maxvit_xlarge_tf_512.in21k_ft_in1k', pretrained=True) # hf-hub:timm/\n",
-    "model = model.eval()\n",
+    "# model = timm.create_model('maxvit_xlarge_tf_512.in21k_ft_in1k', pretrained=True) # hf-hub:timm/\n",
+    "# model = model.eval()\n",
     "\n",
-    "# get model specific transforms (normalization, resize)\n",
-    "data_config = timm.data.resolve_model_data_config(model)\n",
-    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
+    "# # get model specific transforms (normalization, resize)\n",
+    "# data_config = timm.data.resolve_model_data_config(model)\n",
+    "# transforms = timm.data.create_transform(**data_config, is_training=False)\n",
     "\n",
-    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
+    "# output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
     "\n",
-    "top5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)"
+    "# top5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)"
    ]
   },
   {
@@ -2067,9 +150,17 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 10,
    "id": "fd1e36e7-6131-4ad7-a7cc-3e825b391108",
-   "metadata": {},
+   "metadata": {
+    "execution": {
+     "iopub.execute_input": "2023-03-09T21:00:07.468450Z",
+     "iopub.status.busy": "2023-03-09T21:00:07.468450Z",
+     "iopub.status.idle": "2023-03-09T21:00:12.641093Z",
+     "shell.execute_reply": "2023-03-09T21:00:12.640112Z",
+     "shell.execute_reply.started": "2023-03-09T21:00:07.468450Z"
+    }
+   },
    "outputs": [],
    "source": [
     "from fastai.vision.all import *\n",
@@ -2090,10 +181,162 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 14,
    "id": "28c79cc5-2685-4d40-8b07-7a79e00ade9c",
-   "metadata": {},
-   "outputs": [],
+   "metadata": {
+    "execution": {
+     "iopub.execute_input": "2023-03-09T21:05:56.104541Z",
+     "iopub.status.busy": "2023-03-09T21:05:56.104541Z",
+     "iopub.status.idle": "2023-03-09T21:06:14.316871Z",
+     "shell.execute_reply": "2023-03-09T21:06:14.315866Z",
+     "shell.execute_reply.started": "2023-03-09T21:05:56.104541Z"
+    },
+    "tags": []
+   },
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristopher-marais\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
+       " $ pip install wandb --upgrade"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Tracking run with wandb version 0.13.10"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Run data is saved locally in <code>C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\LAB\\Beetle_classifier\\Train\\wandb\\run-20230309_160600-34qj5eiq</code>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Syncing run <strong><a href='https://wandb.ai/christopher-marais/PROJECT/runs/34qj5eiq' target=\"_blank\">trim-capybara-1</a></strong> to <a href='https://wandb.ai/christopher-marais/PROJECT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       " View project at <a href='https://wandb.ai/christopher-marais/PROJECT' target=\"_blank\">https://wandb.ai/christopher-marais/PROJECT</a>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       " View run at <a href='https://wandb.ai/christopher-marais/PROJECT/runs/34qj5eiq' target=\"_blank\">https://wandb.ai/christopher-marais/PROJECT/runs/34qj5eiq</a>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "4e956c56f43140e086e12f8c3b0ab648",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "VBox(children=(Label(value='2.810 MB of 11.423 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.24604â€¦"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       " View run <strong style=\"color:#cdcd00\">trim-capybara-1</strong> at: <a href='https://wandb.ai/christopher-marais/PROJECT/runs/34qj5eiq' target=\"_blank\">https://wandb.ai/christopher-marais/PROJECT/runs/34qj5eiq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Find logs at: <code>.\\wandb\\run-20230309_160600-34qj5eiq\\logs</code>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "ename": "NameError",
+     "evalue": "name 'WandbCallback' is not defined",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
+      "Cell \u001b[1;32mIn[14], line 20\u001b[0m\n\u001b[0;32m     15\u001b[0m         learn \u001b[38;5;241m=\u001b[39m vision_learner(dls, config\u001b[38;5;241m.\u001b[39mmodel_name, metrics\u001b[38;5;241m=\u001b[39merror_rate, \n\u001b[0;32m     16\u001b[0m                                cbs\u001b[38;5;241m=\u001b[39mcbs, pretrained\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretrained)\n\u001b[0;32m     17\u001b[0m         learn\u001b[38;5;241m.\u001b[39mfine_tune(config\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
+      "Cell \u001b[1;32mIn[14], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     12\u001b[0m dls \u001b[38;5;241m=\u001b[39m get_pets(config\u001b[38;5;241m.\u001b[39mbatch_size, config\u001b[38;5;241m.\u001b[39mimg_size, config\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROJECT\u001b[39m\u001b[38;5;124m\"\u001b[39m, group\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mambrosia_symbiosis\u001b[39m\u001b[38;5;124m'\u001b[39m, job_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_training\u001b[39m\u001b[38;5;124m'\u001b[39m, config\u001b[38;5;241m=\u001b[39mconfig):\n\u001b[1;32m---> 14\u001b[0m     cbs \u001b[38;5;241m=\u001b[39m [MixedPrecision(), \u001b[43mWandbCallback\u001b[49m(log_preds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[0;32m     15\u001b[0m     learn \u001b[38;5;241m=\u001b[39m vision_learner(dls, config\u001b[38;5;241m.\u001b[39mmodel_name, metrics\u001b[38;5;241m=\u001b[39merror_rate, \n\u001b[0;32m     16\u001b[0m                            cbs\u001b[38;5;241m=\u001b[39mcbs, pretrained\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretrained)\n\u001b[0;32m     17\u001b[0m     learn\u001b[38;5;241m.\u001b[39mfine_tune(config\u001b[38;5;241m.\u001b[39mepochs)\n",
+      "\u001b[1;31mNameError\u001b[0m: name 'WandbCallback' is not defined"
+     ]
+    }
+   ],
    "source": [
     "config = SimpleNamespace(\n",
     "    batch_size=64,\n",
@@ -2107,7 +350,7 @@
     "def train(config):\n",
     "    \"Train the model using the supplied config\"\n",
     "    dls = get_pets(config.batch_size, config.img_size, config.seed)\n",
-    "    with wandb.init(project=PROJECT, group=GROUP, job_type=JOB_TYPE, config=config):\n",
+    "    with wandb.init(project=\"PROJECT\", group='ambrosia_symbiosis', job_type='test_training', config=config):\n",
     "        cbs = [MixedPrecision(), WandbCallback(log_preds=False)]\n",
     "        learn = vision_learner(dls, config.model_name, metrics=error_rate, \n",
     "                               cbs=cbs, pretrained=config.pretrained)\n",
diff --git a/Train/timm_FastAI_WANDB.ipynb b/Train/timm_FastAI_WANDB.ipynb
index e6b260f..970f9cf 100644
--- a/Train/timm_FastAI_WANDB.ipynb
+++ b/Train/timm_FastAI_WANDB.ipynb
@@ -2,15 +2,15 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 23,
    "id": "436f1771-7aa6-45e7-abae-56c8112da143",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-09T17:03:52.351536Z",
-     "iopub.status.busy": "2023-03-09T17:03:52.351536Z",
-     "iopub.status.idle": "2023-03-09T17:03:57.156787Z",
-     "shell.execute_reply": "2023-03-09T17:03:57.155788Z",
-     "shell.execute_reply.started": "2023-03-09T17:03:52.351536Z"
+     "iopub.execute_input": "2023-03-09T21:22:26.137388Z",
+     "iopub.status.busy": "2023-03-09T21:22:26.137388Z",
+     "iopub.status.idle": "2023-03-09T21:22:26.175369Z",
+     "shell.execute_reply": "2023-03-09T21:22:26.174371Z",
+     "shell.execute_reply.started": "2023-03-09T21:22:26.137388Z"
     },
     "tags": []
    },
@@ -18,20 +18,24 @@
    "source": [
     "from urllib.request import urlopen\n",
     "from PIL import Image\n",
-    "import timm"
+    "import timm\n",
+    "import torch\n",
+    "import wandb\n",
+    "import fastai\n",
+    "from fastai.callback.wandb import WandbCallback"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": 19,
    "id": "5a8980b5-f22c-4e50-bb9f-8ade0c9583cc",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-09T17:03:57.158793Z",
-     "iopub.status.busy": "2023-03-09T17:03:57.158793Z",
-     "iopub.status.idle": "2023-03-09T17:03:57.172789Z",
-     "shell.execute_reply": "2023-03-09T17:03:57.171788Z",
-     "shell.execute_reply.started": "2023-03-09T17:03:57.158793Z"
+     "iopub.execute_input": "2023-03-09T21:19:18.406370Z",
+     "iopub.status.busy": "2023-03-09T21:19:18.405369Z",
+     "iopub.status.idle": "2023-03-09T21:19:18.419374Z",
+     "shell.execute_reply": "2023-03-09T21:19:18.418369Z",
+     "shell.execute_reply.started": "2023-03-09T21:19:18.406370Z"
     },
     "tags": []
    },
@@ -39,1983 +43,47 @@
     {
      "data": {
       "text/plain": [
-       "'0.8.15dev0'"
+       "'2.7.11'"
       ]
      },
-     "execution_count": 2,
+     "execution_count": 19,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
-    "timm.__version__"
+    "fastai.__version__"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
-   "id": "ce6dcd5a-212a-4a26-ab87-8ab81952aec4",
-   "metadata": {
-    "collapsed": true,
-    "execution": {
-     "iopub.execute_input": "2023-03-09T17:06:06.091074Z",
-     "iopub.status.busy": "2023-03-09T17:06:06.091074Z",
-     "iopub.status.idle": "2023-03-09T17:37:25.330060Z",
-     "shell.execute_reply": "2023-03-09T17:37:25.329053Z",
-     "shell.execute_reply.started": "2023-03-09T17:06:06.091074Z"
-    },
-    "jupyter": {
-     "outputs_hidden": true
-    },
-    "tags": []
-   },
-   "outputs": [
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "6028ebec30904d63a0b5577fa37e86e5",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "Downloading (â€¦)\"pytorch_model.bin\";:   0%|          | 0.00/1.90G [00:00<?, ?B/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/plain": [
-       "MaxxVit(\n",
-       "  (stem): Stem(\n",
-       "    (conv1): Conv2dSame(3, 192, kernel_size=(3, 3), stride=(2, 2))\n",
-       "    (norm1): BatchNormAct2d(\n",
-       "      192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "      (drop): Identity()\n",
-       "      (act): GELUTanh()\n",
-       "    )\n",
-       "    (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
-       "  )\n",
-       "  (stages): Sequential(\n",
-       "    (0): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Identity()\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(768, 768, kernel_size=(3, 3), stride=(2, 2), groups=768, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "    (1): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(192, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(1536, 1536, kernel_size=(3, 3), stride=(2, 2), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (2): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (3): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (4): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (5): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "    (2): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(3072, 3072, kernel_size=(3, 3), stride=(2, 2), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (2): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (3): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (4): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (5): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (6): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (7): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (8): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (9): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (10): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (11): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (12): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (13): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "    (3): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(6144, 6144, kernel_size=(3, 3), stride=(2, 2), groups=6144, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(6144, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(384, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(1536, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6144, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(6144, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(384, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "  )\n",
-       "  (norm): Identity()\n",
-       "  (head): NormMlpClassifierHead(\n",
-       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
-       "    (norm): LayerNorm2d((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
-       "    (pre_logits): Sequential(\n",
-       "      (fc): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "      (act): Tanh()\n",
-       "    )\n",
-       "    (drop): Dropout(p=0.0, inplace=False)\n",
-       "    (fc): Linear(in_features=1536, out_features=1000, bias=True)\n",
-       "  )\n",
-       ")"
-      ]
-     },
-     "execution_count": 4,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "timm.create_model(\"maxvit_xlarge_tf_512.in21k_ft_in1k\", pretrained=True)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 7,
    "id": "af673a5e-c94b-4ff2-ad5a-af508a10ca18",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-09T17:46:56.585226Z",
-     "iopub.status.busy": "2023-03-09T17:46:56.585226Z",
-     "iopub.status.idle": "2023-03-09T17:47:24.408985Z",
-     "shell.execute_reply": "2023-03-09T17:47:24.407985Z",
-     "shell.execute_reply.started": "2023-03-09T17:46:56.585226Z"
+     "iopub.execute_input": "2023-03-09T20:58:44.771839Z",
+     "iopub.status.busy": "2023-03-09T20:58:44.771839Z",
+     "iopub.status.idle": "2023-03-09T20:59:08.057797Z",
+     "shell.execute_reply": "2023-03-09T20:59:08.056793Z",
+     "shell.execute_reply.started": "2023-03-09T20:58:44.771839Z"
     },
     "tags": []
    },
-   "outputs": [
-    {
-     "ename": "NameError",
-     "evalue": "name 'torch' is not defined",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
-      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m transforms \u001b[38;5;241m=\u001b[39m timm\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcreate_transform(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata_config, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m output \u001b[38;5;241m=\u001b[39m model(transforms(img)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))  \u001b[38;5;66;03m# unsqueeze single image into batch of 1\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m top5_probabilities, top5_class_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mtopk(output\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
-      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
-    "img = Image.open(\n",
-    "    urlopen('https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'))\n",
+    "# img = Image.open(\n",
+    "#     urlopen('https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'))\n",
     "\n",
-    "model = timm.create_model('maxvit_xlarge_tf_512.in21k_ft_in1k', pretrained=True) # hf-hub:timm/\n",
-    "model = model.eval()\n",
+    "# model = timm.create_model('maxvit_xlarge_tf_512.in21k_ft_in1k', pretrained=True) # hf-hub:timm/\n",
+    "# model = model.eval()\n",
     "\n",
-    "# get model specific transforms (normalization, resize)\n",
-    "data_config = timm.data.resolve_model_data_config(model)\n",
-    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
+    "# # get model specific transforms (normalization, resize)\n",
+    "# data_config = timm.data.resolve_model_data_config(model)\n",
+    "# transforms = timm.data.create_transform(**data_config, is_training=False)\n",
     "\n",
-    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
+    "# output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
     "\n",
-    "top5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)"
+    "# top5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)"
    ]
   },
   {
@@ -2082,9 +150,17 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 10,
    "id": "fd1e36e7-6131-4ad7-a7cc-3e825b391108",
-   "metadata": {},
+   "metadata": {
+    "execution": {
+     "iopub.execute_input": "2023-03-09T21:00:07.468450Z",
+     "iopub.status.busy": "2023-03-09T21:00:07.468450Z",
+     "iopub.status.idle": "2023-03-09T21:00:12.641093Z",
+     "shell.execute_reply": "2023-03-09T21:00:12.640112Z",
+     "shell.execute_reply.started": "2023-03-09T21:00:07.468450Z"
+    }
+   },
    "outputs": [],
    "source": [
     "from fastai.vision.all import *\n",
@@ -2105,10 +181,162 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 14,
    "id": "28c79cc5-2685-4d40-8b07-7a79e00ade9c",
-   "metadata": {},
-   "outputs": [],
+   "metadata": {
+    "execution": {
+     "iopub.execute_input": "2023-03-09T21:05:56.104541Z",
+     "iopub.status.busy": "2023-03-09T21:05:56.104541Z",
+     "iopub.status.idle": "2023-03-09T21:06:14.316871Z",
+     "shell.execute_reply": "2023-03-09T21:06:14.315866Z",
+     "shell.execute_reply.started": "2023-03-09T21:05:56.104541Z"
+    },
+    "tags": []
+   },
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristopher-marais\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
+       " $ pip install wandb --upgrade"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Tracking run with wandb version 0.13.10"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Run data is saved locally in <code>C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\LAB\\Beetle_classifier\\Train\\wandb\\run-20230309_160600-34qj5eiq</code>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Syncing run <strong><a href='https://wandb.ai/christopher-marais/PROJECT/runs/34qj5eiq' target=\"_blank\">trim-capybara-1</a></strong> to <a href='https://wandb.ai/christopher-marais/PROJECT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       " View project at <a href='https://wandb.ai/christopher-marais/PROJECT' target=\"_blank\">https://wandb.ai/christopher-marais/PROJECT</a>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       " View run at <a href='https://wandb.ai/christopher-marais/PROJECT/runs/34qj5eiq' target=\"_blank\">https://wandb.ai/christopher-marais/PROJECT/runs/34qj5eiq</a>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "4e956c56f43140e086e12f8c3b0ab648",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "VBox(children=(Label(value='2.810 MB of 11.423 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.24604â€¦"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       " View run <strong style=\"color:#cdcd00\">trim-capybara-1</strong> at: <a href='https://wandb.ai/christopher-marais/PROJECT/runs/34qj5eiq' target=\"_blank\">https://wandb.ai/christopher-marais/PROJECT/runs/34qj5eiq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Find logs at: <code>.\\wandb\\run-20230309_160600-34qj5eiq\\logs</code>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "ename": "NameError",
+     "evalue": "name 'WandbCallback' is not defined",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
+      "Cell \u001b[1;32mIn[14], line 20\u001b[0m\n\u001b[0;32m     15\u001b[0m         learn \u001b[38;5;241m=\u001b[39m vision_learner(dls, config\u001b[38;5;241m.\u001b[39mmodel_name, metrics\u001b[38;5;241m=\u001b[39merror_rate, \n\u001b[0;32m     16\u001b[0m                                cbs\u001b[38;5;241m=\u001b[39mcbs, pretrained\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretrained)\n\u001b[0;32m     17\u001b[0m         learn\u001b[38;5;241m.\u001b[39mfine_tune(config\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
+      "Cell \u001b[1;32mIn[14], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     12\u001b[0m dls \u001b[38;5;241m=\u001b[39m get_pets(config\u001b[38;5;241m.\u001b[39mbatch_size, config\u001b[38;5;241m.\u001b[39mimg_size, config\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROJECT\u001b[39m\u001b[38;5;124m\"\u001b[39m, group\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mambrosia_symbiosis\u001b[39m\u001b[38;5;124m'\u001b[39m, job_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_training\u001b[39m\u001b[38;5;124m'\u001b[39m, config\u001b[38;5;241m=\u001b[39mconfig):\n\u001b[1;32m---> 14\u001b[0m     cbs \u001b[38;5;241m=\u001b[39m [MixedPrecision(), \u001b[43mWandbCallback\u001b[49m(log_preds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[0;32m     15\u001b[0m     learn \u001b[38;5;241m=\u001b[39m vision_learner(dls, config\u001b[38;5;241m.\u001b[39mmodel_name, metrics\u001b[38;5;241m=\u001b[39merror_rate, \n\u001b[0;32m     16\u001b[0m                            cbs\u001b[38;5;241m=\u001b[39mcbs, pretrained\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretrained)\n\u001b[0;32m     17\u001b[0m     learn\u001b[38;5;241m.\u001b[39mfine_tune(config\u001b[38;5;241m.\u001b[39mepochs)\n",
+      "\u001b[1;31mNameError\u001b[0m: name 'WandbCallback' is not defined"
+     ]
+    }
+   ],
    "source": [
     "config = SimpleNamespace(\n",
     "    batch_size=64,\n",
@@ -2122,7 +350,7 @@
     "def train(config):\n",
     "    \"Train the model using the supplied config\"\n",
     "    dls = get_pets(config.batch_size, config.img_size, config.seed)\n",
-    "    with wandb.init(project=PROJECT, group=GROUP, job_type=JOB_TYPE, config=config):\n",
+    "    with wandb.init(project=\"PROJECT\", group='ambrosia_symbiosis', job_type='test_training', config=config):\n",
     "        cbs = [MixedPrecision(), WandbCallback(log_preds=False)]\n",
     "        learn = vision_learner(dls, config.model_name, metrics=error_rate, \n",
     "                               cbs=cbs, pretrained=config.pretrained)\n",
