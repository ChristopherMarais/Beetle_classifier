diff --git a/Train/.ipynb_checkpoints/timm_FastAI_WANDB-checkpoint.ipynb b/Train/.ipynb_checkpoints/timm_FastAI_WANDB-checkpoint.ipynb
index ad480ea..e5aae72 100644
--- a/Train/.ipynb_checkpoints/timm_FastAI_WANDB-checkpoint.ipynb
+++ b/Train/.ipynb_checkpoints/timm_FastAI_WANDB-checkpoint.ipynb
@@ -6,11 +6,11 @@
    "id": "436f1771-7aa6-45e7-abae-56c8112da143",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-09T17:03:52.351536Z",
-     "iopub.status.busy": "2023-03-09T17:03:52.351536Z",
-     "iopub.status.idle": "2023-03-09T17:03:57.156787Z",
-     "shell.execute_reply": "2023-03-09T17:03:57.155788Z",
-     "shell.execute_reply.started": "2023-03-09T17:03:52.351536Z"
+     "iopub.execute_input": "2023-03-09T21:50:21.229803Z",
+     "iopub.status.busy": "2023-03-09T21:50:21.228802Z",
+     "iopub.status.idle": "2023-03-09T21:50:26.221010Z",
+     "shell.execute_reply": "2023-03-09T21:50:26.220009Z",
+     "shell.execute_reply.started": "2023-03-09T21:50:21.229803Z"
     },
     "tags": []
    },
@@ -18,7 +18,11 @@
    "source": [
     "from urllib.request import urlopen\n",
     "from PIL import Image\n",
-    "import timm"
+    "import timm\n",
+    "import torch\n",
+    "import wandb\n",
+    "import fastai\n",
+    "from fastai.callback.wandb import WandbCallback"
    ]
   },
   {
@@ -27,11 +31,11 @@
    "id": "5a8980b5-f22c-4e50-bb9f-8ade0c9583cc",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-09T17:03:57.158793Z",
-     "iopub.status.busy": "2023-03-09T17:03:57.158793Z",
-     "iopub.status.idle": "2023-03-09T17:03:57.172789Z",
-     "shell.execute_reply": "2023-03-09T17:03:57.171788Z",
-     "shell.execute_reply.started": "2023-03-09T17:03:57.158793Z"
+     "iopub.execute_input": "2023-03-09T21:50:26.222990Z",
+     "iopub.status.busy": "2023-03-09T21:50:26.221976Z",
+     "iopub.status.idle": "2023-03-09T21:50:26.236981Z",
+     "shell.execute_reply": "2023-03-09T21:50:26.236009Z",
+     "shell.execute_reply.started": "2023-03-09T21:50:26.222990Z"
     },
     "tags": []
    },
@@ -39,7 +43,7 @@
     {
      "data": {
       "text/plain": [
-       "'0.8.15dev0'"
+       "'2.7.11'"
       ]
      },
      "execution_count": 2,
@@ -48,1972 +52,51 @@
     }
    ],
    "source": [
-    "timm.__version__"
+    "fastai.__version__"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
-   "id": "ce6dcd5a-212a-4a26-ab87-8ab81952aec4",
-   "metadata": {
-    "collapsed": true,
-    "execution": {
-     "iopub.execute_input": "2023-03-09T17:06:06.091074Z",
-     "iopub.status.busy": "2023-03-09T17:06:06.091074Z",
-     "iopub.status.idle": "2023-03-09T17:37:25.330060Z",
-     "shell.execute_reply": "2023-03-09T17:37:25.329053Z",
-     "shell.execute_reply.started": "2023-03-09T17:06:06.091074Z"
-    },
-    "jupyter": {
-     "outputs_hidden": true
-    },
-    "tags": []
-   },
-   "outputs": [
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "6028ebec30904d63a0b5577fa37e86e5",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "Downloading (â€¦)\"pytorch_model.bin\";:   0%|          | 0.00/1.90G [00:00<?, ?B/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/plain": [
-       "MaxxVit(\n",
-       "  (stem): Stem(\n",
-       "    (conv1): Conv2dSame(3, 192, kernel_size=(3, 3), stride=(2, 2))\n",
-       "    (norm1): BatchNormAct2d(\n",
-       "      192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "      (drop): Identity()\n",
-       "      (act): GELUTanh()\n",
-       "    )\n",
-       "    (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
-       "  )\n",
-       "  (stages): Sequential(\n",
-       "    (0): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Identity()\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(768, 768, kernel_size=(3, 3), stride=(2, 2), groups=768, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "    (1): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(192, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(1536, 1536, kernel_size=(3, 3), stride=(2, 2), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (2): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (3): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (4): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (5): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "    (2): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(3072, 3072, kernel_size=(3, 3), stride=(2, 2), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (2): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (3): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (4): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (5): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (6): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (7): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (8): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (9): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (10): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (11): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (12): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (13): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "    (3): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(6144, 6144, kernel_size=(3, 3), stride=(2, 2), groups=6144, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(6144, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(384, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(1536, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6144, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(6144, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(384, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "  )\n",
-       "  (norm): Identity()\n",
-       "  (head): NormMlpClassifierHead(\n",
-       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
-       "    (norm): LayerNorm2d((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
-       "    (pre_logits): Sequential(\n",
-       "      (fc): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "      (act): Tanh()\n",
-       "    )\n",
-       "    (drop): Dropout(p=0.0, inplace=False)\n",
-       "    (fc): Linear(in_features=1536, out_features=1000, bias=True)\n",
-       "  )\n",
-       ")"
-      ]
-     },
-     "execution_count": 4,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "timm.create_model(\"maxvit_xlarge_tf_512.in21k_ft_in1k\", pretrained=True)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 3,
    "id": "af673a5e-c94b-4ff2-ad5a-af508a10ca18",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-09T17:46:56.585226Z",
-     "iopub.status.busy": "2023-03-09T17:46:56.585226Z"
+     "iopub.execute_input": "2023-03-09T21:50:26.238988Z",
+     "iopub.status.busy": "2023-03-09T21:50:26.238988Z",
+     "iopub.status.idle": "2023-03-09T21:50:26.253010Z",
+     "shell.execute_reply": "2023-03-09T21:50:26.252010Z",
+     "shell.execute_reply.started": "2023-03-09T21:50:26.238988Z"
     },
     "tags": []
    },
    "outputs": [],
    "source": [
-    "img = Image.open(\n",
-    "    urlopen('https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'))\n",
+    "# img = Image.open(\n",
+    "#     urlopen('https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'))\n",
     "\n",
-    "model = timm.create_model('maxvit_xlarge_tf_512.in21k_ft_in1k', pretrained=True) # hf-hub:timm/\n",
-    "model = model.eval()\n",
+    "# model = timm.create_model('maxvit_xlarge_tf_512.in21k_ft_in1k', pretrained=True) # hf-hub:timm/\n",
+    "# model = model.eval()\n",
     "\n",
-    "# get model specific transforms (normalization, resize)\n",
-    "data_config = timm.data.resolve_model_data_config(model)\n",
-    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
+    "# # get model specific transforms (normalization, resize)\n",
+    "# data_config = timm.data.resolve_model_data_config(model)\n",
+    "# transforms = timm.data.create_transform(**data_config, is_training=False)\n",
     "\n",
-    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
+    "# output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
     "\n",
-    "top5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)"
+    "# top5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 4,
    "id": "56818f26-f610-4fe1-89a0-450d6c5e93b0",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-09T17:04:02.134887Z",
-     "iopub.status.busy": "2023-03-09T17:04:02.134887Z",
-     "iopub.status.idle": "2023-03-09T17:04:02.159457Z",
-     "shell.execute_reply": "2023-03-09T17:04:02.158456Z",
-     "shell.execute_reply.started": "2023-03-09T17:04:02.134887Z"
+     "iopub.execute_input": "2023-03-09T21:50:26.253985Z",
+     "iopub.status.busy": "2023-03-09T21:50:26.253985Z",
+     "iopub.status.idle": "2023-03-09T21:50:26.268981Z",
+     "shell.execute_reply": "2023-03-09T21:50:26.267977Z",
+     "shell.execute_reply.started": "2023-03-09T21:50:26.253985Z"
     },
     "tags": []
    },
@@ -2056,7 +139,7 @@
        " 'maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k']"
       ]
      },
-     "execution_count": 3,
+     "execution_count": 4,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -2067,9 +150,17 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 5,
    "id": "fd1e36e7-6131-4ad7-a7cc-3e825b391108",
-   "metadata": {},
+   "metadata": {
+    "execution": {
+     "iopub.execute_input": "2023-03-09T21:50:26.270999Z",
+     "iopub.status.busy": "2023-03-09T21:50:26.270002Z",
+     "iopub.status.idle": "2023-03-09T21:50:26.315819Z",
+     "shell.execute_reply": "2023-03-09T21:50:26.314842Z",
+     "shell.execute_reply.started": "2023-03-09T21:50:26.270999Z"
+    }
+   },
    "outputs": [],
    "source": [
     "from fastai.vision.all import *\n",
@@ -2092,22 +183,230 @@
    "cell_type": "code",
    "execution_count": null,
    "id": "28c79cc5-2685-4d40-8b07-7a79e00ade9c",
-   "metadata": {},
-   "outputs": [],
+   "metadata": {
+    "execution": {
+     "iopub.execute_input": "2023-03-09T21:50:26.317820Z",
+     "iopub.status.busy": "2023-03-09T21:50:26.317820Z"
+    },
+    "tags": []
+   },
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristopher-marais\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
+       " $ pip install wandb --upgrade"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Tracking run with wandb version 0.13.10"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Run data is saved locally in <code>C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\LAB\\Beetle_classifier\\Train\\wandb\\run-20230309_165032-qn04a84o</code>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Syncing run <strong><a href='https://wandb.ai/christopher-marais/PROJECT/runs/qn04a84o' target=\"_blank\">dark-sound-3</a></strong> to <a href='https://wandb.ai/christopher-marais/PROJECT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       " View project at <a href='https://wandb.ai/christopher-marais/PROJECT' target=\"_blank\">https://wandb.ai/christopher-marais/PROJECT</a>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       " View run at <a href='https://wandb.ai/christopher-marais/PROJECT/runs/qn04a84o' target=\"_blank\">https://wandb.ai/christopher-marais/PROJECT/runs/qn04a84o</a>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "<style>\n",
+       "    /* Turns off some styling */\n",
+       "    progress {\n",
+       "        /* gets rid of default border in Firefox and Opera. */\n",
+       "        border: none;\n",
+       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
+       "        background-size: auto;\n",
+       "    }\n",
+       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
+       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
+       "    }\n",
+       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
+       "        background: #F44336;\n",
+       "    }\n",
+       "</style>\n"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "<table border=\"1\" class=\"dataframe\">\n",
+       "  <thead>\n",
+       "    <tr style=\"text-align: left;\">\n",
+       "      <th>epoch</th>\n",
+       "      <th>train_loss</th>\n",
+       "      <th>valid_loss</th>\n",
+       "      <th>error_rate</th>\n",
+       "      <th>time</th>\n",
+       "    </tr>\n",
+       "  </thead>\n",
+       "  <tbody>\n",
+       "    <tr>\n",
+       "      <td>0</td>\n",
+       "      <td>4.461537</td>\n",
+       "      <td>3.594796</td>\n",
+       "      <td>0.903248</td>\n",
+       "      <td>01:18</td>\n",
+       "    </tr>\n",
+       "  </tbody>\n",
+       "</table>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "<style>\n",
+       "    /* Turns off some styling */\n",
+       "    progress {\n",
+       "        /* gets rid of default border in Firefox and Opera. */\n",
+       "        border: none;\n",
+       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
+       "        background-size: auto;\n",
+       "    }\n",
+       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
+       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
+       "    }\n",
+       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
+       "        background: #F44336;\n",
+       "    }\n",
+       "</style>\n"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "    <div>\n",
+       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
+       "      0.00% [0/1 00:00&lt;?]\n",
+       "    </div>\n",
+       "    \n",
+       "<table border=\"1\" class=\"dataframe\">\n",
+       "  <thead>\n",
+       "    <tr style=\"text-align: left;\">\n",
+       "      <th>epoch</th>\n",
+       "      <th>train_loss</th>\n",
+       "      <th>valid_loss</th>\n",
+       "      <th>error_rate</th>\n",
+       "      <th>time</th>\n",
+       "    </tr>\n",
+       "  </thead>\n",
+       "  <tbody>\n",
+       "  </tbody>\n",
+       "</table><p>\n",
+       "\n",
+       "    <div>\n",
+       "      <progress value='68' class='' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
+       "      73.91% [68/92 01:30&lt;00:31 3.9248]\n",
+       "    </div>\n",
+       "    "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    }
+   ],
    "source": [
     "config = SimpleNamespace(\n",
     "    batch_size=64,\n",
     "    img_size=224,\n",
     "    seed=42,\n",
     "    pretrained=False,\n",
-    "    model_name=\"regnetx_040\",\n",
-    "    epochs=5)\n",
+    "    model_name=\"maxvit_nano_rw_256.sw_in1k\", # try with maxvit_nano_rw_256.sw_in1k # regnetx_040\n",
+    "    epochs=1)\n",
     "\n",
     "\n",
     "def train(config):\n",
     "    \"Train the model using the supplied config\"\n",
     "    dls = get_pets(config.batch_size, config.img_size, config.seed)\n",
-    "    with wandb.init(project=PROJECT, group=GROUP, job_type=JOB_TYPE, config=config):\n",
+    "    with wandb.init(project=\"PROJECT\", group='ambrosia_symbiosis', job_type='test_training', config=config):\n",
     "        cbs = [MixedPrecision(), WandbCallback(log_preds=False)]\n",
     "        learn = vision_learner(dls, config.model_name, metrics=error_rate, \n",
     "                               cbs=cbs, pretrained=config.pretrained)\n",
@@ -2121,7 +420,9 @@
    "cell_type": "code",
    "execution_count": null,
    "id": "450bfc9b-6527-41e0-803b-633e82230dea",
-   "metadata": {},
+   "metadata": {
+    "tags": []
+   },
    "outputs": [],
    "source": [
     "def get_planets(batch_size=64, img_size=224, seed=42):\n",
@@ -2137,6 +438,18 @@
     "                                    item_tfms=Resize(img_size))\n",
     "    return dls"
    ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "dff8becf-8e4b-4b07-911c-d030ab8c12dc",
+   "metadata": {
+    "tags": []
+   },
+   "outputs": [],
+   "source": [
+    "get_planets()"
+   ]
   }
  ],
  "metadata": {
diff --git a/Train/timm_FastAI_WANDB.ipynb b/Train/timm_FastAI_WANDB.ipynb
index e6b260f..e5aae72 100644
--- a/Train/timm_FastAI_WANDB.ipynb
+++ b/Train/timm_FastAI_WANDB.ipynb
@@ -6,11 +6,11 @@
    "id": "436f1771-7aa6-45e7-abae-56c8112da143",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-09T17:03:52.351536Z",
-     "iopub.status.busy": "2023-03-09T17:03:52.351536Z",
-     "iopub.status.idle": "2023-03-09T17:03:57.156787Z",
-     "shell.execute_reply": "2023-03-09T17:03:57.155788Z",
-     "shell.execute_reply.started": "2023-03-09T17:03:52.351536Z"
+     "iopub.execute_input": "2023-03-09T21:50:21.229803Z",
+     "iopub.status.busy": "2023-03-09T21:50:21.228802Z",
+     "iopub.status.idle": "2023-03-09T21:50:26.221010Z",
+     "shell.execute_reply": "2023-03-09T21:50:26.220009Z",
+     "shell.execute_reply.started": "2023-03-09T21:50:21.229803Z"
     },
     "tags": []
    },
@@ -18,7 +18,11 @@
    "source": [
     "from urllib.request import urlopen\n",
     "from PIL import Image\n",
-    "import timm"
+    "import timm\n",
+    "import torch\n",
+    "import wandb\n",
+    "import fastai\n",
+    "from fastai.callback.wandb import WandbCallback"
    ]
   },
   {
@@ -27,11 +31,11 @@
    "id": "5a8980b5-f22c-4e50-bb9f-8ade0c9583cc",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-09T17:03:57.158793Z",
-     "iopub.status.busy": "2023-03-09T17:03:57.158793Z",
-     "iopub.status.idle": "2023-03-09T17:03:57.172789Z",
-     "shell.execute_reply": "2023-03-09T17:03:57.171788Z",
-     "shell.execute_reply.started": "2023-03-09T17:03:57.158793Z"
+     "iopub.execute_input": "2023-03-09T21:50:26.222990Z",
+     "iopub.status.busy": "2023-03-09T21:50:26.221976Z",
+     "iopub.status.idle": "2023-03-09T21:50:26.236981Z",
+     "shell.execute_reply": "2023-03-09T21:50:26.236009Z",
+     "shell.execute_reply.started": "2023-03-09T21:50:26.222990Z"
     },
     "tags": []
    },
@@ -39,7 +43,7 @@
     {
      "data": {
       "text/plain": [
-       "'0.8.15dev0'"
+       "'2.7.11'"
       ]
      },
      "execution_count": 2,
@@ -48,1987 +52,51 @@
     }
    ],
    "source": [
-    "timm.__version__"
+    "fastai.__version__"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
-   "id": "ce6dcd5a-212a-4a26-ab87-8ab81952aec4",
-   "metadata": {
-    "collapsed": true,
-    "execution": {
-     "iopub.execute_input": "2023-03-09T17:06:06.091074Z",
-     "iopub.status.busy": "2023-03-09T17:06:06.091074Z",
-     "iopub.status.idle": "2023-03-09T17:37:25.330060Z",
-     "shell.execute_reply": "2023-03-09T17:37:25.329053Z",
-     "shell.execute_reply.started": "2023-03-09T17:06:06.091074Z"
-    },
-    "jupyter": {
-     "outputs_hidden": true
-    },
-    "tags": []
-   },
-   "outputs": [
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "6028ebec30904d63a0b5577fa37e86e5",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "Downloading (â€¦)\"pytorch_model.bin\";:   0%|          | 0.00/1.90G [00:00<?, ?B/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/plain": [
-       "MaxxVit(\n",
-       "  (stem): Stem(\n",
-       "    (conv1): Conv2dSame(3, 192, kernel_size=(3, 3), stride=(2, 2))\n",
-       "    (norm1): BatchNormAct2d(\n",
-       "      192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "      (drop): Identity()\n",
-       "      (act): GELUTanh()\n",
-       "    )\n",
-       "    (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
-       "  )\n",
-       "  (stages): Sequential(\n",
-       "    (0): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Identity()\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(768, 768, kernel_size=(3, 3), stride=(2, 2), groups=768, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "    (1): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(192, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(1536, 1536, kernel_size=(3, 3), stride=(2, 2), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (2): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (3): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (4): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (5): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "    (2): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(384, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(3072, 3072, kernel_size=(3, 3), stride=(2, 2), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (2): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (3): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (4): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (5): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (6): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (7): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (8): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (9): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (10): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (11): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (12): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (13): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "    (3): MaxxVitStage(\n",
-       "      (blocks): Sequential(\n",
-       "        (0): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Downsample2d(\n",
-       "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
-       "              (expand): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            )\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(768, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2dSame(6144, 6144, kernel_size=(3, 3), stride=(2, 2), groups=6144, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(6144, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(384, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "        (1): MaxxVitBlock(\n",
-       "          (conv): MbConvBlock(\n",
-       "            (shortcut): Identity()\n",
-       "            (pre_norm): BatchNormAct2d(\n",
-       "              1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): Identity()\n",
-       "            )\n",
-       "            (down): Identity()\n",
-       "            (conv1_1x1): Conv2d(1536, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
-       "            (norm1): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (conv2_kxk): Conv2d(6144, 6144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6144, bias=False)\n",
-       "            (norm2): BatchNormAct2d(\n",
-       "              6144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
-       "              (drop): Identity()\n",
-       "              (act): GELUTanh()\n",
-       "            )\n",
-       "            (se): SEModule(\n",
-       "              (fc1): Conv2d(6144, 384, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (bn): Identity()\n",
-       "              (act): SiLU(inplace=True)\n",
-       "              (fc2): Conv2d(384, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
-       "              (gate): Sigmoid()\n",
-       "            )\n",
-       "            (conv3_1x1): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
-       "            (drop_path): Identity()\n",
-       "          )\n",
-       "          (attn_block): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "          (attn_grid): PartitionAttentionCl(\n",
-       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (attn): AttentionCl(\n",
-       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
-       "              (rel_pos): RelPosBiasTf()\n",
-       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
-       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls1): Identity()\n",
-       "            (drop_path1): Identity()\n",
-       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "            (mlp): Mlp(\n",
-       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
-       "              (act): GELUTanh()\n",
-       "              (drop1): Dropout(p=0.0, inplace=False)\n",
-       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
-       "              (drop2): Dropout(p=0.0, inplace=False)\n",
-       "            )\n",
-       "            (ls2): Identity()\n",
-       "            (drop_path2): Identity()\n",
-       "          )\n",
-       "        )\n",
-       "      )\n",
-       "    )\n",
-       "  )\n",
-       "  (norm): Identity()\n",
-       "  (head): NormMlpClassifierHead(\n",
-       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
-       "    (norm): LayerNorm2d((1536,), eps=1e-05, elementwise_affine=True)\n",
-       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
-       "    (pre_logits): Sequential(\n",
-       "      (fc): Linear(in_features=1536, out_features=1536, bias=True)\n",
-       "      (act): Tanh()\n",
-       "    )\n",
-       "    (drop): Dropout(p=0.0, inplace=False)\n",
-       "    (fc): Linear(in_features=1536, out_features=1000, bias=True)\n",
-       "  )\n",
-       ")"
-      ]
-     },
-     "execution_count": 4,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "timm.create_model(\"maxvit_xlarge_tf_512.in21k_ft_in1k\", pretrained=True)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 3,
    "id": "af673a5e-c94b-4ff2-ad5a-af508a10ca18",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-09T17:46:56.585226Z",
-     "iopub.status.busy": "2023-03-09T17:46:56.585226Z",
-     "iopub.status.idle": "2023-03-09T17:47:24.408985Z",
-     "shell.execute_reply": "2023-03-09T17:47:24.407985Z",
-     "shell.execute_reply.started": "2023-03-09T17:46:56.585226Z"
+     "iopub.execute_input": "2023-03-09T21:50:26.238988Z",
+     "iopub.status.busy": "2023-03-09T21:50:26.238988Z",
+     "iopub.status.idle": "2023-03-09T21:50:26.253010Z",
+     "shell.execute_reply": "2023-03-09T21:50:26.252010Z",
+     "shell.execute_reply.started": "2023-03-09T21:50:26.238988Z"
     },
     "tags": []
    },
-   "outputs": [
-    {
-     "ename": "NameError",
-     "evalue": "name 'torch' is not defined",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
-      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m transforms \u001b[38;5;241m=\u001b[39m timm\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcreate_transform(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata_config, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m output \u001b[38;5;241m=\u001b[39m model(transforms(img)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))  \u001b[38;5;66;03m# unsqueeze single image into batch of 1\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m top5_probabilities, top5_class_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mtopk(output\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
-      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
-    "img = Image.open(\n",
-    "    urlopen('https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'))\n",
+    "# img = Image.open(\n",
+    "#     urlopen('https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'))\n",
     "\n",
-    "model = timm.create_model('maxvit_xlarge_tf_512.in21k_ft_in1k', pretrained=True) # hf-hub:timm/\n",
-    "model = model.eval()\n",
+    "# model = timm.create_model('maxvit_xlarge_tf_512.in21k_ft_in1k', pretrained=True) # hf-hub:timm/\n",
+    "# model = model.eval()\n",
     "\n",
-    "# get model specific transforms (normalization, resize)\n",
-    "data_config = timm.data.resolve_model_data_config(model)\n",
-    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
+    "# # get model specific transforms (normalization, resize)\n",
+    "# data_config = timm.data.resolve_model_data_config(model)\n",
+    "# transforms = timm.data.create_transform(**data_config, is_training=False)\n",
     "\n",
-    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
+    "# output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
     "\n",
-    "top5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)"
+    "# top5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 4,
    "id": "56818f26-f610-4fe1-89a0-450d6c5e93b0",
    "metadata": {
     "execution": {
-     "iopub.execute_input": "2023-03-09T17:04:02.134887Z",
-     "iopub.status.busy": "2023-03-09T17:04:02.134887Z",
-     "iopub.status.idle": "2023-03-09T17:04:02.159457Z",
-     "shell.execute_reply": "2023-03-09T17:04:02.158456Z",
-     "shell.execute_reply.started": "2023-03-09T17:04:02.134887Z"
+     "iopub.execute_input": "2023-03-09T21:50:26.253985Z",
+     "iopub.status.busy": "2023-03-09T21:50:26.253985Z",
+     "iopub.status.idle": "2023-03-09T21:50:26.268981Z",
+     "shell.execute_reply": "2023-03-09T21:50:26.267977Z",
+     "shell.execute_reply.started": "2023-03-09T21:50:26.253985Z"
     },
     "tags": []
    },
@@ -2071,7 +139,7 @@
        " 'maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k']"
       ]
      },
-     "execution_count": 3,
+     "execution_count": 4,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -2082,9 +150,17 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 5,
    "id": "fd1e36e7-6131-4ad7-a7cc-3e825b391108",
-   "metadata": {},
+   "metadata": {
+    "execution": {
+     "iopub.execute_input": "2023-03-09T21:50:26.270999Z",
+     "iopub.status.busy": "2023-03-09T21:50:26.270002Z",
+     "iopub.status.idle": "2023-03-09T21:50:26.315819Z",
+     "shell.execute_reply": "2023-03-09T21:50:26.314842Z",
+     "shell.execute_reply.started": "2023-03-09T21:50:26.270999Z"
+    }
+   },
    "outputs": [],
    "source": [
     "from fastai.vision.all import *\n",
@@ -2107,22 +183,230 @@
    "cell_type": "code",
    "execution_count": null,
    "id": "28c79cc5-2685-4d40-8b07-7a79e00ade9c",
-   "metadata": {},
-   "outputs": [],
+   "metadata": {
+    "execution": {
+     "iopub.execute_input": "2023-03-09T21:50:26.317820Z",
+     "iopub.status.busy": "2023-03-09T21:50:26.317820Z"
+    },
+    "tags": []
+   },
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristopher-marais\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
+       " $ pip install wandb --upgrade"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Tracking run with wandb version 0.13.10"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Run data is saved locally in <code>C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\LAB\\Beetle_classifier\\Train\\wandb\\run-20230309_165032-qn04a84o</code>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Syncing run <strong><a href='https://wandb.ai/christopher-marais/PROJECT/runs/qn04a84o' target=\"_blank\">dark-sound-3</a></strong> to <a href='https://wandb.ai/christopher-marais/PROJECT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       " View project at <a href='https://wandb.ai/christopher-marais/PROJECT' target=\"_blank\">https://wandb.ai/christopher-marais/PROJECT</a>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       " View run at <a href='https://wandb.ai/christopher-marais/PROJECT/runs/qn04a84o' target=\"_blank\">https://wandb.ai/christopher-marais/PROJECT/runs/qn04a84o</a>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "<style>\n",
+       "    /* Turns off some styling */\n",
+       "    progress {\n",
+       "        /* gets rid of default border in Firefox and Opera. */\n",
+       "        border: none;\n",
+       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
+       "        background-size: auto;\n",
+       "    }\n",
+       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
+       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
+       "    }\n",
+       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
+       "        background: #F44336;\n",
+       "    }\n",
+       "</style>\n"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "<table border=\"1\" class=\"dataframe\">\n",
+       "  <thead>\n",
+       "    <tr style=\"text-align: left;\">\n",
+       "      <th>epoch</th>\n",
+       "      <th>train_loss</th>\n",
+       "      <th>valid_loss</th>\n",
+       "      <th>error_rate</th>\n",
+       "      <th>time</th>\n",
+       "    </tr>\n",
+       "  </thead>\n",
+       "  <tbody>\n",
+       "    <tr>\n",
+       "      <td>0</td>\n",
+       "      <td>4.461537</td>\n",
+       "      <td>3.594796</td>\n",
+       "      <td>0.903248</td>\n",
+       "      <td>01:18</td>\n",
+       "    </tr>\n",
+       "  </tbody>\n",
+       "</table>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "<style>\n",
+       "    /* Turns off some styling */\n",
+       "    progress {\n",
+       "        /* gets rid of default border in Firefox and Opera. */\n",
+       "        border: none;\n",
+       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
+       "        background-size: auto;\n",
+       "    }\n",
+       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
+       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
+       "    }\n",
+       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
+       "        background: #F44336;\n",
+       "    }\n",
+       "</style>\n"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "    <div>\n",
+       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
+       "      0.00% [0/1 00:00&lt;?]\n",
+       "    </div>\n",
+       "    \n",
+       "<table border=\"1\" class=\"dataframe\">\n",
+       "  <thead>\n",
+       "    <tr style=\"text-align: left;\">\n",
+       "      <th>epoch</th>\n",
+       "      <th>train_loss</th>\n",
+       "      <th>valid_loss</th>\n",
+       "      <th>error_rate</th>\n",
+       "      <th>time</th>\n",
+       "    </tr>\n",
+       "  </thead>\n",
+       "  <tbody>\n",
+       "  </tbody>\n",
+       "</table><p>\n",
+       "\n",
+       "    <div>\n",
+       "      <progress value='68' class='' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
+       "      73.91% [68/92 01:30&lt;00:31 3.9248]\n",
+       "    </div>\n",
+       "    "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    }
+   ],
    "source": [
     "config = SimpleNamespace(\n",
     "    batch_size=64,\n",
     "    img_size=224,\n",
     "    seed=42,\n",
     "    pretrained=False,\n",
-    "    model_name=\"regnetx_040\",\n",
-    "    epochs=5)\n",
+    "    model_name=\"maxvit_nano_rw_256.sw_in1k\", # try with maxvit_nano_rw_256.sw_in1k # regnetx_040\n",
+    "    epochs=1)\n",
     "\n",
     "\n",
     "def train(config):\n",
     "    \"Train the model using the supplied config\"\n",
     "    dls = get_pets(config.batch_size, config.img_size, config.seed)\n",
-    "    with wandb.init(project=PROJECT, group=GROUP, job_type=JOB_TYPE, config=config):\n",
+    "    with wandb.init(project=\"PROJECT\", group='ambrosia_symbiosis', job_type='test_training', config=config):\n",
     "        cbs = [MixedPrecision(), WandbCallback(log_preds=False)]\n",
     "        learn = vision_learner(dls, config.model_name, metrics=error_rate, \n",
     "                               cbs=cbs, pretrained=config.pretrained)\n",
@@ -2136,7 +420,9 @@
    "cell_type": "code",
    "execution_count": null,
    "id": "450bfc9b-6527-41e0-803b-633e82230dea",
-   "metadata": {},
+   "metadata": {
+    "tags": []
+   },
    "outputs": [],
    "source": [
     "def get_planets(batch_size=64, img_size=224, seed=42):\n",
@@ -2152,6 +438,18 @@
     "                                    item_tfms=Resize(img_size))\n",
     "    return dls"
    ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "dff8becf-8e4b-4b07-911c-d030ab8c12dc",
+   "metadata": {
+    "tags": []
+   },
+   "outputs": [],
+   "source": [
+    "get_planets()"
+   ]
   }
  ],
  "metadata": {
